The tagger treats dots in POS tag labels as attribute separators.
Each position in the POS tags of a given category corresponds to a feature.
The attributes oc curring at a certain position constitute the value set of the feature.
Our tagger is a HMM tagger which decomposes the context probabilities into a product of attribute probabilities.
The probabilities at the terminal nodes of the decision trees are smoothed with the parent node probabilities (which themselves were smoothed in the same way).
This smoothing strat egy is closely related to Witten-Bell smoothing.
The best tag sequence is computed with theViterbi algorithm.
The main differences of our tag ger to a standard trigram tagger are that the order of the Markov model (the k in equation 1) is not fixed 4 This is the reason why the attribute tests in figure 1 used complex attributes such as ART.Nom rather than Nom.
the tagger also applies a beam-search strategy which prunes allsearch paths whose probability is below the prob ability of the best path times a threshold.
The tagger builds a suf fix trie for each class of unknown words using the known word types from that class.
The maximal length of the suffixes is 7.
The suffix tries are pruned until (i) all suffixeshave a frequency of at least 5 and (ii) the information gain multiplied by the suffix frequency and di 5 p(word|tag) is equal to p(tag|word)p(word)/p(tag) and p(word) is a constant if the tokenization is unambiguous.
Our tagger was first evaluated on data from theGerman Tiger treebank.
The results were com pared to those obtained with the TnT tagger (Brants, 2000) and the SVMTool (Gim?enez andM`arquez, 2004), which is based on support vec tor machines.
The first 80% were used as training data, the first half of the rest as development data, and the last 10% as test data.
The TnT tagger achieves 86.3% accuracy on the default tagset.
The tagset refinement increases the accuracy by about 0.6%, and the ex ternal lexicon by another 3.5%.
The SVMTool is slightly better than the TnTtagger on the default tagset, but shows little im provement from the tagset refinement.
The best results are obtained with a context size of 10.
By far the most frequent tagging error was the confusion of nominative and accusative case.
If 10 726 sentences were better tagged by TnT (i.e. with few errors), 1450 sentences were better tagged by our tagger.
The resulting score of a binomial test is below 0.001.
782 this error is not counted, the tagging accuracy on the development data rises from 92.17% to 94.27%.
The corresponding figures for the test data are.
89.53% for our tagger and 88.88% for the TnT tag ger.
