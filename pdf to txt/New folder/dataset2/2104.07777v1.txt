Work has been done to solve TN by pure encoder-decoder methods particularly Recurrent Neural Networks (Sproat and Jaitly, 2017; Zhang et al., 2019).
The data should represent all the forms a particular token can appear in a given language.
Our approach curtails such errors by breaking down complex entities like dates into multiple tokens by a granular tokenization mechanism and also by limiting which tokens can be accepted into a class.
A way to limit the unacceptable errors in such systems would be to limit the kind of normalizations the network can generate for a token (Sproat and Jaitly, 2017).
On the other hand, solutions based on semiotic classification convert TN into a sequence tagging problem, where each class has associated mechanisms for normalizing the corresponding unnormalized token(s).
It produces verbalizations by first suitably tokenizing the input, then classifying the tokens, and then verbalizing each token according to its corresponding class.
These approaches often have a complex tokenization mechanism which is not easily transferable across languages and also need all the possible classes to be exhaustively defined manually.
We solve both these problems by a granular tokenization mechanism which extends the concept of semiotic classification to a granular level wherein each unique unnormalized token to normalized token mapping can have a class of its own.
Our classes represent whether a particular token is of a certain type and convert unnormalized tokens into their normalized form.
The solution is divided into 4 stages: i) Tokenization of unnormalized data, ii) Data preparation, iii) Classifying unnormalized tokens into correct classes, iv) Normalizing tokens using the corresponding class.
3.1 Tokenizer Typically TN approaches either assume presegmented text by the rule-based standard (Ebden and Sproat, 2014) which identifies multiword sequences as single segment like dates (Jan. 3, 2016) according to pre-defined semiotic classes or train a neural network for tokenization together with a normalization model (Zhang et al., 2019).
Proteno’s tokenization on the other hand, has elementary rules and is deterministic.
Eg: after splitting on spaces a token like ‘C3PO’ will be further split into [‘C’,‘3’,‘PO’].
Such tokenization enables the system to accurately split complex entities like dates while eliminating the need for a manually defined complex class for them.
The same tokenization mechanism was used for all the languages tested.
3.2 Data Preparation While collecting training data, first the unnormalized data is tokenized according to the granular tokenization mechanism described above and then each token is annotated with its corresponding normalized form.
Thus, we obtain unnormalized token to normalized token mappings.
Eg: a date occurrence ‘1/1/2020’ tokenized as [‘1’,‘/’,‘1’,‘/’,‘2020’] is annotated as [‘first’,‘of’, ‘January’,‘’,‘twenty twenty’].
Hence, while collecting the data we try to ensure decent coverage of different semiotic classes by having at least 25% of tokens which need normalization (i.e.
3.3 Classes Each class has 2 functions: i) Accepts: This function returns a boolean value of whether a token is accepted by the class.
Eg: cardinal class accepts only numeric tokens, ii) Normalize: This is a deterministic function that transforms the unnormalized token into its verbalized form A token can be classified into a class only if it is accepted by it.
By restricting the classes a token is accepted into, we limit the kind of normalization output that can be generated.
A token can be accepted by multiple classes which can give different normalizations.
If multiple classes give the same normalization for a token, then during inference it doesn’t matter which class is chosen.
Eg: self class indicates that the input is to be passed through as it is and it accepts tokens containing only alphabetical characters.
ii) Auto Generated (AG): Apart from pre-defined classes, the model learns automatically generated classes from the data by going through the unnormalized to normalized token mappings in the dataset.
If none of the existing classes (pre-coded or AG) can generate the target normalization for a token in the training data, then a class is automatically generated which accepts only the token responsible for its generation.
Its normalize function returns the target normalization observed in the annotated data for that token.
If multiple normalizations are observed for an unnormalized token in the dataset which cannot be generated by existing classes then multiple AGs are stored.
3.4 Classification & Normalization We model TN as a sequence tagging problem where the input is a sequence of unnormalized tokens and the output is the sequence of classes which can generate the normalized text.
Before training the classification model we transform the data to get unnormalized token to class mappings.
We prepare this data by going over the unnormalized token to normalized token mapping for a sentence and identifying which existing classes can give the target normalization.
For a token there can be multiple matching classes.
To classify the sequence of unnormalized tokens to their corresponding classes we experimented with 4 classifiers.
We first train a first order Conditional Random Fields (CRFs) (Lafferty et al., 2001) and then train neural network (NN) based architectures like Bi-LSTMs (Hochreiter and Schmidhuber, 1997), BiLSTM-CRFs (Huang et al., 2015) and Transformers (Vaswani et al., 2017).
We used word embeddings from Mikolov et al.
i) CRF: The features used for each unnormalized token in the model are - part of speech tag, list of classes which accept the token as an input, next token in sequence, suffix of the token (from length 1-4), prefix of the token (from length 1-4), is the token in upper case, is the token numeric and is the token capitalized, ii) Bi-LSTM & BiLSTM-CRFs: Using word embeddings and list of classes which accept the token as input features, iii) Transformer: A Transformer with 6 heads with word embeddings as input features.
For each token we renormalize the probabilities predicted over all classes to only the classes which accept the token.
Hence, the model is restricted to classify a token only to one of its few accepted classes.
If the system is unable to find a suitable class for the given token (i.e.
none of the given classes accept that token) then it gives a empty output instead of an incorrect normalization.
3.5 Aligning tokens in order of verbalization One of the major challenges in automated TN is handling realignment of tokens which may be required between the written and its spoken form.
Our method so far assumes monotonic alignment between the written unormalized tokens and their corresponding spoken normalizations.
Proteno first recognises instances of currency/measure in the text and prevents them from further splitting by the granular tokenizer.
The currency/measure classes have the same granular tokenisation logic along with realignment conditions.
They further pass the final tokens to their corresponding classes.
Due to budget constraints we could collect a dataset of only 135k tokens (5k sentences), ii) Tamil: We annotate the data sourced from English-Tamil parallel corpus (Ramasamy et al., 2012) and Comparable Corpora (Eckart and Quasthoff, 2013).
From these datasets we sampled 500k tokens (30k sentences) with higher preference towards sentences that needed normalization, iii) English: We used a portion of the annotated data from Sproat and Jaitly (2016).
First, we run the Proteno tokenizer over the unnormalized section of the dataset and got unnormalized token to normalized token mappings using elementary rules.
By doing so, we were able to correctly match only a portion of the dataset due to its different tokenization.
And then, from this subset, 300k tokens (24.7k sentences) were randomly sampled to keep the data size comparable to that used for Tamil.
This is 1.5% of the data used by Pramanik and Hussain (2019) which used first 20M tokens and 3% of data used by Zhang et al.
(2019) which used first 10M tokens.
Word Error Rate (WER) is used as the evaluation metric for the different classifiers.
We use this metric instead of classification accuracy on the classes in order to enable comparison of results from different TN approaches in the future, which may not use the same tokenization mechanism and hence may not have the same classes benchmarked by previous work.
We first evaluate all the classifiers on Spanish and then choose the classifier with lowest WER for Tamil and English.
Normalization was required for 27% of tokens in both the training and the test set.
On the test set, all models except Transformers showed statistically significant difference (p<<0.01) in comparison to the RB system.
We can attribute the lower performance of Transformers to lack of accepted classes as input features.
Even though Transformers give unstable performance in class prediction, they still give a low enough WER.
This particular iteration has a bias towards predicting cardinal_ masculine over cardinal_ feminine.
This bias changes with different iterations but the WER remains consistent as the normalization output remains unaffected.
BiLSTMs with the same configurations.
The token proportion and high level classification accuracy results for the tokens are detailed in Table 3.
Out of the 99.26% correctly normalized tokens, 88.2% of the non-self tokens were normalized via AGs i.e.
Moreover, Proteno does not have the same set of classes due to its granular tokenization mechanism.
It cannot use the full dataset due to differing tokenization mechanisms which result into mismatch in the alignment between the unnormalized token and their corresponding normalized forms.
However, we extract their pre-defined categories on the dataset we used and evaluate how many tokens within them were normalized correctly.
It illustrates the token normalization accuracy achieved by Proteno on the test dataset for all the categories which had instances in the small subset we have used.
For complex entities likes date Proteno gave 98.16% accuracy on the 6% tokens available in test set.
