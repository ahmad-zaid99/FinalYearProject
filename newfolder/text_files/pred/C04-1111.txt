 Marti Hearst (1992) was the first to use a pat tern-based approach to extract hyponym relations from a raw corpus. 771Riloff and Shepherd (1997) used a semi automatic method for discovering similar words using a few seed examples by using pattern-based techniques and human supervision. They reported an accuracy of about 55% precision on a corpus of 100,000 words. Mann (2002) and Fleischman et al (2003) used part of speech patterns to extract a subset of hyponym relations involving proper nouns. Also, the patterns are learned with the specific goal of scaling to the terascale (see Table 2). The second class of algorithms uses co occurrence statistics (Hindle 1990, Lin 1998). Assuming the distributional hypothesis (Harris 1985), words that occur in similar gram matical contexts are similar in meaning. CBC (Clustering by Commit tee) proposed by Pantel and Lin (2002) achieves high recall and precision in generating similarity lists of words discriminated by their meaning and senses. Re cently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic de pendency features for each noun. Hyponyms are gen erated in a top-down approach by naming each group of words and assigning that name as a hypo nym of each word in the group (i.e., one hyponym per instance/group label pair). For example, following are two semantic classes discov ered by CBC: (A) peach, pear, pineapple, apricot, mango, raspberry, lemon, cherry, strawberry, melon, blueberry, fig, apple, plum, nectarine, avocado, grapefruit, papaya, banana, cantaloupe, cranberry, blackberry, lime, orange, tangerine, ...
(B) Phil Donahue, Pat Sajak, Arsenio Hall, Geraldo Rivera, Don Imus, Larry King, David Letterman, Conan O'Brien, Rosie O'Donnell, Jenny Jones, Sally Jessy Raph ael, Oprah Winfrey, Jerry Springer, Howard Stern, Jay Leno, Johnny Carson, ... We then construct a mutual information vector MI(e) = (mie1, mie2, ?, miem) for each word e, where mief is the pointwise mutual information between word e and context f, which is defined as: N c N c N c ef m j ej n i if ef mi ?? TOOL 15 GB ORPUS 1 TB CORPUS POS Tagger 2 days 125 days NP Chunker 3 days 214 days Dependency Parser 56 days 10.2 years Syntactic Parser 5.8 years 388.4 years 772 where n is the number of elements to be clustered, cef is the frequency count of word e in grammatical context f, and N is the total frequency count of all features of all words. Following (Pantel and Lin 2002), a committee for each semantic class is constructed. For example, in one of our experiments, the committees for semantic classes (A) and (B) from Sec tion 3 were: A) peach, pear, pineapple, apricot, mango, raspberry, lemon, blueberry B) Phil Donahue, Pat Sajak, Arsenio Hall, Geraldo Rivera, Don Imus, Larry King, David Letterman 3.3 Phase III. For example, Figure 1 shows an excerpt of the grammatical signature for semantic class (B). These relationships, automatically learned in (Pantel and Ravichandran 2004), include apposi tions, nominal subjects, such as relationships, and like relationships. The syntactical co-occurrence approach has worst-case time complexity O(n2k), where n is the number of words in the corpus and k is the feature space (Pantel and Ravichandran 2004). Just to parse a 1 TB corpus, this approach requires ap proximately 10.2 years (see Table 2). For example, consider the following 2 sentences: 1) Platinum is a precious metal. To perform such alignments we introduce two wildcard operators, skip (*s*) and wildcard (*g*). The skip operator represents 0 or 1 instance of any word (similar to the \w* pattern in Perl), while the wildcard operator represents exactly 1 instance of any word (similar to the \w+ pattern in Perl). Consider two strings a(1, n) and b(1, m) of lengths n and m re spectively. Let a1(1, n) and a2(1, n) be the level 1 (lexical level) and level 2 (POS level) representa tions for the string a(1, n). Similarly, let b1(1, m) and b2(1, m) be the level 1 and level 2 representa tions for the string b(1, m). The minimal edit distance algorithm calculates the number of edit operations (insertions, deletions and replacements) required to change one string to another string. The optimal pattern is retrieved by {Phil Donahue,Pat Sajak,Arsenio Hall} N:gen:N talk show 93 11.77 television show 24 11.30 TV show 25 10.45 show 255 9.98 audience 23 7.80 joke 5 7.37 V:subj:N joke 39 7.11 tape 10 7.09 poke 15 6.87 host 40 6.47 co-host 4 6.14 banter 3 6.00 interview 20 5.89 N:appo:N host 127 12.46 comedian 12 11.02 King 13 9.49 star 6 7.47 Figure 1. Algorithm for calculating the minimal edit distance between two strings D[0,0]=0 for i = 1 to n do D[i,0] = D[i-1,0] + cost(insertion) for j = 1 to m do D[0,j] = D[0,j-1] + cost(deletion) for i = 1 to n do for j = 1 to m do D[i,j] = min( D[i-1,j-1] + cost(substitution), D[i-1,j] + cost(insertion), D[i,j-1] + cost(deletion)) Print (D[n,m]) Algorithm for optimal pattern retrieval i = n, j = m; while i ? 0 if D[i,j] = D[i-1,j] + cost(insertion) print (*s*), i = i-1 else if D[i,j] = D[i,j-1] + cost(deletion) print(*s*), j = j-1 else if a1i = b1j print (a1i), i = i -1, j = j =1 else if a2i = b2j print (a2i), i = i -1, j = j =1 else print (*g*), i = i -1, j = j =1 We experimentally set (by trial and error): cost(insertion) = 3 cost(deletion) = 3 cost(substitution) = 0 if a1i=b1j = 1 if a1i?b1j, a2i=b2j = 2 if a1i?b1j, a2i?b2j 4.2 Implementation and filtering. Hence, if there are x strings in the collection, each string having at most length y, the algorithm has time complexity O(x2y2) to extract all the patterns in the collection. Applying the above algorithm on a corpus of 3GB with 50 is-a relationship seeds, we obtain a set of 600 lexico-POS. 2) X_NNP#NNP|NNP#NNP#NNP#NNP#NNP#CC#NNP |NNP|VBN|NN#NN|VBG#NN|NN ,_, _DT Y_NN#IN#NN|JJ#JJ#NN|JJ|NN|NN#IN#NNP |NNP#NNP|NN#NN|JJ#NN|JJ#NN#NN e.g. As shown in example 1, the POS variations of the anchor X are (JJ NN, JJ NN NN, NN). The variations for anchor Y are (JJ JJ NN, JJ, etc.). Since we treat each sentences independently from others, the algorithm runs in linear time O(n) over the corpus size, where n is number of sentences in the corpus. For our experiments, we extract from this corpus six data sets of differ ent sizes: 1.5MB, 15 MB, 150 MB, 1.5GB, 6GB and 15GB. For the co-occurrence model, we used Minipar (Lin 1994), a broad coverage parser, to parse each data set. We collected the frequency counts of the grammatical relationships (contexts) output by Minipar and used them to compute the pointwise mutual information vectors described in Section 3.1. X, or Y X, _DT Y _(WDT|IN) Y like X and X, (a|an) Y X, _RB known as Y _NN, X and other Y X, Y X ( Y ) Y, including X, Y, or X Y such as X Y, such as X X is a Y X, _RB called Y Y, especially X 774relationships. From each resulting set, we then randomly se lected 50 words along with their top 3 highest ranking is-a relationships. For example, Table 4 shows three randomly selected names for the pat tern-based system on the 15GB dataset. For each word, we added to the list of hypernyms a human generated hypernym (obtained from an annotator looking at the word without any system or Word Net hyponym). Each of the 11 random samples contained a maximum of 350 is-a relationships to manually evaluate (50 random words with top 3 system, top 3 WordNet, and human generated relationship)..
We presented each of the 11 random samples to two human judges. The 50 randomly selected words, together with the system, human, and WordNet generated is-a relationships, were ran domly ordered. For small datasets (below 150MB), the pattern based method achieves higher precision since the co-occurrence method requires a certain critical mass of statistics before it can extract useful class signatures (see Section 3). On the other hand, the pattern-based approach has relatively constant precision since most of the is-a relationships se lected by it are fired by a single pattern. Once the co-occurrence system reaches its critical mass (at 150MB), it generates much more precise hypo nyms. The variation between the human and WordNet scores across both systems is mostly due to the relative cleanliness of the tokens in the co-occurrencebased system (due to the parser used in the ap proach). WordNet consistently generated higher precision relationships although both algorithms approach WordNet quality on 6GB (the pattern based algorithm even surpasses WordNet precision on 15GB). Furthermore, WordNet only generated a hyponym 40% of the time. On the 6 GB corpus, the co-occurrence approach took approximately 47 single Pentium-4 2.5 GHz processor days to complete, whereas it took the pattern-based approach only four days to complete on 6 GB and 10 days on 15 GB. Is-a relationships assigned to three randomly selected words (using pattern-based system on 15GB dataset). RANDOM WORD HUMAN WORDNET PATTERN-BASED SYSTEM (RANKED) Sanwa Bank bank none subsidiary / lender / bank MCI Worldcom Inc. telecommunications company none phone company / competitor / company cappuccino beverage none item / food / beverage Table 5. PATTERN SYSTEM CO-OCCURRENCE SYSTEM Prec Top-3 MRR Prec Top-3 MRR 1.5MB 38.7% 41.0% 41.0% 4.3% 8.0% 7.3% 15MB 39.1% 43.0% 41.5% 14.6% 32.0% 24.3% 150MB 40.6% 46.0% 45.5% 51.1% 73.0% 67.0% 1.5GB 40.4% 39.0% 39.0% 56.7% 88.0% 77.7% 6GB 46.3% 52.0% 49.7% 64.9% 90.0% 78.8% 15GB 55.9% 54.0% 52.0% Too large to process Table 6. PATTERN SYSTEM CO-OCCURRENCE SYSTEM Prec Top-3 MRR Prec Top-3 MRR 1.5MB 56.6% 60.0% 60.0% 12.4% 20.0% 15.2% 15MB 57.3% 63.0% 61.0% 23.2% 50.0% 37.3% 150MB 50.7% 56.0% 55.0% 60.6% 78.0% 73.2% 1.5GB 52.6% 51.0% 51.0% 69.7% 93.0% 85.8% 6GB 61.8% 69.0% 67.5% 78.7% 92.0% 86.2% 15GB 67.8% 67.0% 65.0% Too large to process 775 However, Figure 2 shows that the pattern-based approach extracts many more relationships. To approximate recall, we defined a relative recall measure and conducted a question answering (QA) task of answering defi nition questions. 5.3.1 Relative recall Although it is impossible to know the number of is-a relationships in any non-trivial corpus, it is possible to compute the recall of a system relative to another system?s recall. The recall of a system A, RA, is given by the following formula: C C R AA = where CA is the number of correct is-a relation ships extracted by A and C is the total number of correct is-a relationships in the corpus. = ,Figure 3 shows the relative recall of A = pattern based approach relative to B = co-occurrence model. Because of sparse data, the pattern-based approach has much higher precision and recall (six times) than the co-occurrence approach on the small 15MB dataset. In fact, only on the 150MB dataset did the co-occurrence system have higher recall. With datasets larger than 150MB, the co occurrence algorithm reduces its running time by filtering out grammatical relationships for words that occurred fewer than k = 40 times and hence recall is affected (in contrast, the pattern-based approach may generate a hyponym for a word that it only sees once). 5.3.2 Definition questions Following Fleischman et al (2003), we select the 50 definition questions from the TREC2003 (Voorhees 2003) question set. we extract its respective instance (e.g., ?Neils Bohr? ), look up their corresponding hyponyms from our is-a table, and present the corresponding hyponym as the answer. We manually evaluate the three systems and assign 3 classes ?Correct (C)?, ?Partially Correct (P)? However, by being consistent across all Total Number of Is-A Relationships vs. Dataset 0 200000 400000 600000 800000 1000000 1200000 1400000 1.5MB 15MB 150MB 1.5GB 6GB 15GB Datasets To ta l Is A Re la tio n s hi ps s Pattern-based System Co-occurrence-based System Figure 2. PRECISION MRR Co-occ WNet Human Co-occ WNet Human 1.5MB 4.3% 42.7% 52.7% 7.3% 87.7% 95.0% 15MB 14.6% 38.1% 48.7% 24.3% 86.6% 95.0% 150MB 51.1% 57.5% 65.8% 67.0% 85.1% 98.0% 1.5GB 56.7% 62.8% 70.3% 77.7% 93.0% 98.0% 6GB 64.9% 68.9% 75.2% 78.8% 94.3% 98.0% Relative Recall (Pattern-based vs. Co-occurrence-based) 0.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 1.5MB 15MB 150MB 1.5GB 6GB 15GB (projected) Datesets Re la tiv e Re ca ll Figure 3. The corresponding scores for WordNet are 38% accuracy in both the top-1 and top-5 categories (for both strict and lenient). As seen in this experiment, the results for both the pattern-based and cooccurrence-based systems report very poor per formance for data sets up to 150 MB. The per formance of the system in the top 5 category is much better than that of WordNet (38%).