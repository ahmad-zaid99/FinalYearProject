 Existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: Descriptivity: Grammatical phenomena are to be described rather than explained. (Marcus et al., 1994). al., 1994), (Sampson, 1995), (Black et. (Bies et al., 1995), (Sampson, 1995)). At, this point the importance of the underlying argument structure is emphasised (cf. (Lehmann et al., 1996), (Marcus et al., 1994), (Sampson, 1995)). Due to the frequency of discontinuous constituents in non-configurational languages, the filler-trace mechanism would be used very often, yielding syntactic trees fairly different from the underlying predicate-argument structures. Consider the German sentence (1) daran wird ihn Anna erkennen, &di er weint at-it will him Anna recognise that he cries 'Anna will recognise him at his cry' A sample constituent structure is given below: The fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes. Apart from this rather technical problem, two further arguments speak against phrase structure as the structural pivot of the annotation scheme: Finally, the structural handling of free word order means stating well-formedness constraints on structures involving many trace-filler dependencies, which has proved tedious. (McCawley, 1987), (Dowty, 1989), (Reape, 1993), (Kathol and Pollard, 1995). These approaches provide an adequate explanation for several issues problematic for phrase-structure grammars (clause union, extraposition, diverse second-position phenomena). In order to reduce their ambiguity potential, rather simple, 'flat' trees should be employed, while more information can be expressed by a rich system of function labels. Thus, notions such as head should be distinguished at the level of syntactic functions rather than structures. (Hudson, 1984). SB (subject), MO (modifier), HD (head). (2) schade, daB kein Arzt anwesend ist, der pity that no doctor present is who sich a.uskennt is competent 'Pity that no competent doctor is here' Note that the root node does not have a head descendant (HD) as the sentence is a predicative construction consisting of a subject (SB) and a predicate (PD) without a copula. For instance, the extraposed relative clause (RC) is still treated as part of the subject NP. As the annotation scheme does not distinguish different bar levels or any similar intermediate categories, only a small set of node labels is needed (currently 16 tags, S, NP, AP ...). Due to the rudimentary character of the argument structure representations, a great deal of information has to be expressed by grammatical functions. Their further classification must reflect different kinds of linguistic information: morphology (e.g., case, inflection), category, dependency type (complementation vs. modification), thematic role, etc. In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714. While in the first phase each annotator has to annotate structures as well as categories and functions, the refinement call be done separately for each representation level. During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc. Separate labels are defined for dependencies that do not fit the complement/modifier dichotomy, e.g., pre- (GL) and postnominal genitives (GR). Consider (qui verbs where the subject of the infinitival VP is not realised syntactically, but co-referent with the subject or object. 4, showing the structure of (3). headless) constructions, appositions, temporal expressions, etc. However, this idealised model needs several additional assumptions in order to account for such important phenomena as complex nominal NP components (cf. In (4), different theories make different headedness predictions. In (5), either a lexical nominalisation rule for the adjective Gliickliche is stipulated, or the existence of an empty nominal head. The difference between the particular NK's lies in the positional and part-of-speech information, which is also sufficient to recover theory-specific structures from our `underspecified' representations. In addition, a. number of clear-cut NP cornponents can be defined outside that, juxtapositional kernel: pre- and postnominal genitives (GL, GR), relative clauses (RC), clausal and sentential complements (OC). Since a precise structural description of non-constituent coordination would require a. rich inventory of incomplete phrase types, we have agreed on a sort of unde.rspe.cified representations: the coordinated units are assigned structures in which missing lexical material is not represented at the level of primary links. 3 shows the representation of the sentence: (6) sic wurde von preuBischen Truppen besetzt she was by Prussian troops occupied und 1887 dem preuliischen Staat angegliedert and 1887 to-the Prussian state incorporated 'it was occupied by Prussian troops and incorporated into Prussia in 1887' The category of the coordination is labeled CVP here, where C stands for coordination, and VP for the actual category. As keyboard input, is more efficient than mouse input (cf. (Lehmann et al., 1996)) most effort, has been put in developing an efficient keyboard interface. The following commands are available: The three tagsets used by the annotation tool (for words, phrases, and edges) are variable and are stored together with the corpus. (Cutting et al., 1992) and (Feldweg, 1995)). For a phrase Q with children of type T..., Ta and grammatical functions G...,GA., we use the lexical probabilities and the contextual (trigram) probabilities The lexical and contextual probabilities are determined separately for each type of phrase. During annotation, the highest rated grammatical function labels Gi are calculated using the Viterbi algorithm and assigned to the structure, i.e., we calculate argma.x11 PQ (Ti 1Z-1, Ti.-2) PQ (Gi ITi). To keep the human annotator from missing errors made by the tagger, we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient), the assignment is regarded as unreliable, and the annotator is asked to confirm the assignment. For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%). Owing to the partial automation, the average annotation efficiency improves by 25% (from around 4 minutes to 3 minutes per sentence).