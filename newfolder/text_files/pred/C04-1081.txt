 Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al, 2001). = {?1, ...}
defines a conditional proba bility for a state (label) sequence y = y1...yT (for example, labels indicating where words start or have their interior) given an input sequence x = x1...xT (for example, the characters of a Chinese sentence) to be P? k ?kfk(yt?1, yt,x, t) ) , (1) where Zx is the per-input normalization that makes the probability of all state sequences sum to one;fk(yt?1, yt,x, t) is a feature function which is of ten binary-valued, but can be real-valued, and ?k is a learned weight associated with feature fk. yt, and the entire observation se quence, x, centered at the current time step, t. For example, one feature function might have value 1when yt?1 is the state START, yt is the state NOT START, and xt is a word appearing in a lexicon of people?s first names. (y|x),can be efficiently determined using the Viterbi algorithm (Rabiner, 1990). An N -best list of labeling sequences can also be obtained using modi fied Viterbi algorithm and A* search (Schwartz and Chow, 1990). The parameters can be estimated by maximum likelihood?maximizing the conditional probabilityof a set of label sequences, each given their cor responding input sequences. The log-likelihood of training set {(xi, yi) : i = 1, ...M} is written L? k ?kfk(yt?1, yt,x, t)? Traditional maximum entropy learning algorithms, such as GIS and IIS (della Pietra et al, 1995), canbe used to train CRFs. However, our implemen tation uses a quasi-Newton gradient-climber BFGS for optimization, which has been shown to converge much faster (Malouf, 2002; Sha and Pereira, 2003). i,t fk(yt?1, y(i)t ,x(i), t) ? (y|x(i))fk(yt?1, yt,x(i), t) CRFs share many of the advantageous properties of standard maximum entropy classifiers, including their convex likelihood function, which guarantees that the learning procedure converges to the global maximum. ?2 where ck is the count of features, M is the bin size set by held out validation, and dae is the ceiling function. We define four different state transition feature functions corresponding to different Markov orders.Higher-order features capture more long-range de pendencies, but also cause more data sparseness problems and require more memory for training. The feature functions are represented as f(yt,x).There are no separate parameters for state tran sitions. The fea ture functions used are f(yt,x), f(yt?1, yt).context of the current and previous states. Fea ture function are represented as f(yt?1, yt,x). Feature function are represented as f(yt?2, yt?1, yt,x). We cast the segmentation problem as one of se quence tagging: Chinese characters that begin a new word are given the START tag, and characters in the middle and at the end of words are given theNONSTART tag. The task of segmenting new, un segmented test data becomes a matter of assigning a sequence of tags (labels) to the input sequence of Chinese characters. Conditional random fields are configured as a linear-chain (finite state machine) for this purpose,and tagging is performed using the Viterbi algorithm to efficiently find the most likely label se quence for a given character sequence. To specifically evaluate the importance ofdomain knowledge beyond the training data, we divide our features into two categories: closed fea tures and open features, (i.e., features allowed in thecompetition?s ?closed test? The open features include a large word list (containing single and multiple-character words), a character list, and additional topic or part-of-speech character lexicons obtained from various sources. The closed features are obtained from training data alone, by intersecting the character list obtainedfrom training data with corresponding open lexi cons. Besides the word list and character list, our lexiconsinclude 24 lists of Chinese words and characters obtained from several Internet sites1 cleaned and augmented by a local native Chinese speaker indepen dently of the competition data. We 1http://www.mandarintools.com, ftp://xcin.linux.org.tw/pub/xcin/libtabe, http://www.geocities.com/hao510/wordlist noun (e.g.,?,?) verb (e.g.,?) adjective (e.g.,?,?) adverb (e.g.,!,?) auxiliary (e.g.,,?) preposition (e.g.,?) number (e.g.,,) negative (e.g.,X,:) determiner (e.g.,?,?,Y) function (e.g. letter (English character) punctuation (e.g., # $) last name (e.g.,K) foreign name (e.g.,?) maybe last-name (e.g.,?,[) plural character (e.g.,?,?) pronoun (e.g.,fi,?,?) unit character (e.g.,G,?) country name (e.g.,?,?) Chinese place name (e.g.,?) organization name title suffix (e.g.,?,?) title prefix (e.g.,,?) date (e.g.,#,?,?) Figure 1: Lexicons used in our experiments C?2: second previous character in lexicon C?1: previous character in lexicon C1: next character in lexicon C2: second next character in lexicon C0C1: current and next character in lexicon C?1C0: current and previous character in lexicon C?2C?1: previous two characters in lexicon C?1C0C1: previous, current, and next character in the lexicon Figure 2: Feature conjunctions used in experiments use feature conjunctions in both the open and closed tests, as listed Figure 2. Since no vocabulary list could ever be complete,new word (unknown word) identification is an im portant issue in Chinese segmentation. Unknownwords cause segmentation errors in that these outof-vocabulary words in input text are often in correctly segmented into single-character or otheroverly-short words (Chen and Bai, 1998). We consider here new word detection as an integral part of segmentation, aimingto improve both segmentation and new word detec tion: detected new words are added to the word list lexicon in order to improve segmentation; improved segmentation can potentially further improve new word detection. A confidence threshold of 0.9 is determined by cross-validation.Segment confidence is estimated using constrained forward-backward (Culotta and McCallum, 2004). The standard forward-backward algorithm (Rabiner, 1990) calculates Zx, the total like lihood of all label sequences y given a sequence x. Constrained forward-backward algorithm calculates Z ?x, total likelihood of all paths passing through a constrained segment (in our case, a sequence of characters starting with a START tag followed by a few NONSTART tags before the next START tag). x Zx , a real number between 0 and 1.In order to increase recall of new words, we consider not only the most likely (Viterbi) segmen tation, but the segmentations in the top N most likely segmentations (an N -best list), and detect new words according to the above criteria in all N segmentations.Many errors can be corrected by new word detection. To make a comprehensive evaluation, we use allfour of the datasets from a recent Chinese word segmentation bake-off competition (Sproat and Emer son, 2003). Thus, each training set is randomly split?80% used for training and theremaining 20% for validation?and based on vali dation set performance, choices are made for model structure, prior, and which word lexicons to include. Encoding #Train words #Test Words OOV rate (%) UPenn Chinese Treebank CTB GB 250K 40K 18.1 Beijing University PK GB 1.1M 17K 6.9 Hong Kong City U HK Big 5 240K 35K 7.1 Academia Sinica AS Big 5 5.8M 12K 2.2 Table 1: Datasets statistics bin-Size M Markov order CTB 10 first-order + transitions PK 15 first-order + transitions HK 1 first-order AS 15 first-order + transitions Table 2: Optimal prior and Markov order setting in Section 3.1. Each entry is the performance of the given metric (precision, recall, F1, and Roov) on the test set. Closed Precision Recall F1 Roov CTB 0.828 0.870 0.849 0.550 PK 0.935 0.947 0.941 0.660 HK 0.917 0.940 0.928 0.531 AS 0.950 0.962 0.956 0.292 Open Precision Recall F1 Roov CTB 0.889 0.898 0.894 0.619 PK 0.941 0.952 0.946 0.676 HK 0.944 0.948 0.946 0.629 AS 0.953 0.961 0.957 0.403 Table 3: Overall results of CRF segmentation on closed and open tests To compare our results against other systems, we summarize the competition results reported in (Sproat and Emerson, 2003) in Table 4. Column OUR-AVG is the average F1 performance of our system over the same datasets.Comparing performance across systems is diffi cult since none of those systems reported results on all eight datasets (open and closed runs on 4 datasets). S01 is one of the best segmentation systems in mainland China (Zhang et al., 2003). We also achieve two best runs (ASo and HKc), with a comparable average of 91.9% over the same 6 runs, and a 92.7% average over all the 8 runs.Second, performance varies significantly across dif ferent datasets, indicating that the four datasets havedifferent characteristics and use very different seg mentation guidelines. This is due to significant inconsistent segmen tation in training and testing (Sproat and Emerson, 2003). Third, consider a comparison of our results with site S12, who use a sliding-window maximum entropy model (Xue, 2003). This gives some empirical evidenceof the advantages of linear-chain CRFs over sliding window maximum entropy models, however, this comparison still requires further investigation sincethere are many factors that could affect the performance such as different features used in both sys tems. To further study the robustness of our approach to segmentation, we perform cross-testing?that is, training on one dataset and testing on other datasets. Not surprisingly, cross testing re sults are worse than the results using the same ASc ASo CTBc CTBo HKc HKo PKc PKo SITE-AVG OUR-AVG S01 93.8 88.1 88.1 90.1 95.1 95.3 91.8 91.9 S02 87.4 91.2 89.3 87.2 S03 87.2 82.9 88.6 92.5 87.8 93.6 S04 93.9 93.7 93.8 94.4 S05 94.2 73.2 89.4 85.6 91.5 S06 94.5 82.9 92.4 92.4 90.6 91.9 S07 94.0 94.0 94.6 S08 90.4 95.6 93.6 93.8 93.4 94.0 S09 96.1 94.6 95.4 94.9 S10 83.1 90.1 94.7 95.9 91.0 90.8 S11 90.4 88.4 87.9 88.6 88.8 93.6 S12 95.9 91.6 93.8 94.2 95.6 95.7 84.9 89.4 92.8 94.6 94.1 94.6 92.7 Table 4: Comparisons against other systems: the first column contains the 12 sites participating in bake-off competition; the second to the ninth columns contain their results on the 8 runs, where a bold entry is the winner of that run; column SITE-AVG contains the average performance of the site over the runs in which it participated, where a bold entry indicates that this site performs better than our system; column OUR-AVG is the average of our system over the same runs, where a bolded entry indicates our system performs better than the other site; the last row is the performance of our system over all the runs and the overall average. One of the most attractive advantages of CRFs (and maximum entropy models in general) is its the flexibility to easily incorporate arbitrary features,here in the form domain-knowledge-providing lex icons. In addition, compared to simple models like n-gram language models (Teahan et al, 2000), another shortcomingof CRF-based segmenters is that it requires signifi cantly longer training time.