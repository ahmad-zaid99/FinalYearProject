 We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh, 1998). For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE. For the following example, the template relation in Figure 2 was to be generated: &quot;Donald M. Goldstein, a historian at the University of Pittsburgh who helped write...&quot;
Almost all approaches to information extraction  even at the sentence level  are based on the divide-and-conquer strategy of reducing a complex problem to a set of simpler ones. Currently, the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: Since we were interested in exploiting recent advances in parsing, replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility. For this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other. 1993), and more recently, had begun using a generative statistical model for name finding (Bikel et al. Finally, our newly constructed parser, like that of (Collins 1997), was based on a generative statistical model. Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties  especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs  would also benefit semantic analysis. The five key facts in this example are: Here, each &quot;reportable&quot; name or description is identified by a &quot;-r&quot; suffix attached to its semantic label. For example, &quot;per-r&quot; identifies &quot;Nance&quot; as a named person, and &quot;per-desc-r&quot; identifies &quot;a paid consultant to ABC News&quot; as a person description. For example, the coreference relation between &quot;Nance&quot; and &quot;a paid consultant to ABC News&quot; is indicated by &quot;per-desc-of.&quot; In this case, because the argument does not connect directly to the relation, the intervening nodes are labeled with semantics &quot;-ptr&quot; to indicate the connection. To produce a corpus of augmented parse trees, we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus, now annotated with complete augmented trees like that in Figure 3. In this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees. For example, in the phrase &quot;Lt. Cmdr. David Edwin Lewis,&quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5. In our statistical model, trees are generated according to a process similar to that described in (Collins 1996, 1997). The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process. The categories for head constituents, cl are predicted based solely on the category of the parent node, cp: Modifier constituent categories, cm, are predicted based on their parent node, cp, the head constituent of their parent node, chp, the previously generated modifier, c,_1, and the head word of their parent, wp. Separate probabilities are maintained for left (pre) and right (post) modifiers: Part-of-speech tags, t,,, for modifiers are predicted based on the modifier, cm, the partof-speech tag of the head word, th, and the head word itself, wh: Head words, w for modifiers are predicted based on the modifier, cm, the part-of-speech tag of the modifier word , t the part-ofspeech tag of the head word , th, and the head word itself, wh: lAwmicm,tm,th,wh), e.g. Finally, word features, fm, for modifiers are predicted based on the modifier, cm, the partof-speech tag of the modifier word , t the part-of-speech tag of the head word th, the head word itself, wh, and whether or not the modifier head word, w is known or unknown. If we generalize the tree components (constituent labels, words, tags, etc.) and treat them all as simply elements, e, and treat all the conditioning factors as the history, h, we can write:
Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus. For modifier constituents, the mixture components are: For part-of-speech tags, the mixture components are: Finally, for word features, the mixture components are:
Given a sentence to be analyzed, the search program must find the most likely semantic and syntactic interpretation. For purposes of pruning, and only for purposes of pruning, the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman, 1997). Given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a While our focus throughout the project was on TE and TR, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding. We evaluated part-of-speech tagging and parsing accuracy on the Wall Street Journal using a now standard procedure (see Collins 97), and evaluated name finding accuracy on the MUC7 named entity test.