 A tokenizer (Grefenstette and Tapanainen, 1994) and a sentence boundary disambiguation algorithm (Palmer and Hearst, 1994; Reynar and Ratnaparkhi, 1997) or EAGLE (Reynar et al., 1997) may be used to convert a plain text document into the acceptable input format. A stemming algorithm (Porter, 1980) is then applied to the remaining tokens to obtain the word stems. The similarity between a pair of sentences :1:, y For short text segments, the absolute value of sim(x, y) is unreliable. An additional occurrence of a common word (reflected in the numerator) causes a disproportionate increase in sim(x, y) unless the denominator (related to segment length) is large. We present a ranking scheme which is an adaptation of that described in (O'Neil and Denos, 1992). Figure 2 shows an example of image ranking using a 3 x 3 rank mask with output range {0, 8). The output is expressed as a ratio r (equation 2) to circumvent normalisation problems (consider the cases when the rank mask is not contained in the image). r(x) is the rank (1 x 11 mask) of (x) which is a sine wave with decaying mean, amplitude and frequency (equation 3). The method is based on Reynar's maximisation algorithm (Reynar, 1998; Helfman, 1996; Church, 1993; Church and Helfman, 1993). A text segment is defined by two sentences i, j (inclusive). Let si,j denote the sum of the rank values in a segment and ai,j = (j -i +1)2 be the inside area. Den) is the inside density of n segments and SD(n) , Den) Den-1) is the gradient. For a document with b potential boundaries, b steps of divisive clustering generates {D(1), ...,D(b+1)} and {bD(2), oD(b+1)} (see figure 6 and 7). An unusually large reduction in 6D suggests the optiinal clustering has been obtained3 (see n = 10 in the threshold, p+c x to dD (c= 1.2 works well in practice) The running time of each step is dominated by the computation of sk. Given R of size n X 77,, S is computed in three steps (see equation 5). The definition of a topic segment ranges from complete stories (Allan et al., 1998) to summaries (Ponte and Croft, 1997). Our evaluation strategy is a variant of that described in (Reynar, 1998, 71-73) and the TDT segmentation task (Allan et al., 1998). p(erroriref, hyp, k) = p(misslref, hyp, diff, k)p(diffl ref, k)+ (6) p(fairef, hyp, same, k)p(samelref, k) Speed performance is measured by the average number of CPU seconds required to process a test sample6. Segmentation accuracy is measured by the error metric (equation 6, fa false alarms) proposed in (Beeferman et al., 1999). Other performance measures include the popular precision and recall metric (PR) (Hearst, 1994), fuzzy PR (Reynar, 1998) and edit distance (Ponte and Croft, 1997). The problems associated with these metrics are discussed in (Beeferman et al., 1999). B(i.,?) B(r,b) randomly selects b boundaries as real boundaries. However, their differences are insignificant according to the Kolmogorov-Smirnov, or KS-test (Press et al., 1992). We compare three versions of the TextTiling algorithm (Hearst, 1994). H94(c,d) is Hearst's C implementation with default parameters. H94(3,,,) is my implementation of the algorithm. Experimental result (table 3) shows H94(,,d) and H94(,,) are more accurate than H94(j,,,). Five versions of Reynar's optimisation algorithm (Reynar, 1998) were evaluated. R98(8,,08) is my version of the maximisation algorithm which uses the cosine coefficient instead of dot density for measuring similarity. R98(,,d0t) is the modularised version of R98 for experimenting with different similarity measures. R98(,,,,) uses a variant of Kozima's semantic similarity measure (Kozima, 1993) to compute block similarity. Given the co-occurrence frequencies f (wi, wi), the transition probability matrix t is computed by equation 10. s denotes the word similarity matrix, x is the number of activation steps and norm(y) converts a matrix y into a transition matrix. Experimental result (table 4) shows the cosine coefficient and our spread activation method improved segmentation accuracy. We compare three versions of Segmenter (Kan et at, 1998). K98(j,,i) is a version of K98(i) which uses a document specific chain breaking strategy. K98 performed performed significantly better than K98(J,). Our chain breaking strategy improved accuracy (compare K98(i) with K98(j,a)) Two versions of our algorithm were developed, C99 and C99(b). The first experiment focuses on the impact of our automatic termination strategy on C99(b) (table 6). The second experiment investigates the effect of different ranking mask size on the performance of C99 (table 7). Experimental result (table 8) shows our algorithm C99 is more accurate than existing algorithms. If one disregards segmentation accuracy, H94 has the best algorithmic performance (linear).