 Writers sometimes produce errors that violate basic principles of English syntax (e.g., a desks), while other mistakes show a lack of information about a specific vocabulary item (e.g., a knowledge). In order to detect these two types of problems, ALEK uses a 30-million word general corpus of English from the San Jose Mercury News (hereafter referred to as the general corpus) and, for each target word, a set of 10,000 example sentences from North American newspaper text' (hereafter referred to as the word-specific corpus). It uses two kinds of contextual cues in a 2 word window around the target word: function words (closed-class items) and part-of-speech tags (Brill, 1994). The Brill tagger output is post-processed to &quot;enrich&quot; some closed class categories of its tag set, such as subject versus object pronoun and definite versus indefinite determiner. After the sentences have been preprocessed, ALEK counts sequences of adjacent part-ofspeech tags and function words (such as determiners, prepositions, and conjunctions). From the general corpus, ALEK computes a mutual information measure to determine which sequences of part-of-speech tags and function words are unusually rare and are, therefore, likely to be ungrammatical in English (e.g., singular determiner preceding plural noun, as in *a desks). ALEK also looks for sequences that are common in general but unusual in the word specific corpus (e.g., the singular determiner a preceding a singular noun is common in English but rare when the noun is specific corpora, we tried to minimize the mismatch between the domains of newspapers and TOEFL essays. The system computes mutual information comparing the proportion of observed occurrences of bigrams in the general corpus to the proportion expected based on the assumption of independence, as shown below: Here, P(AB) is the probability of the occurrence of the AB bigram, estimated from its frequency in the general corpus, and P(A) and P(B) are the probabilities of the first and second elements of the bigram, also estimated from the general corpus. Trigram sequences are also used, but in this case the mutual information computation compares the co-occurrence of ABC to a model in which A and C are assumed to be conditionally independent given B (see Lin, 1998). To return to a previous example, the phrase a knowledge contains the tag bigram for singular determiner followed by singular noun (AT NN). In addition to bigram and trigram measures, ALEK compares the target word's part-ofspeech tag in the word-specific corpus and in the general corpus. Specifically, it looks at the conditional probability of the part-of-speech tag given the major syntactic category (e.g., plural noun given noun) in both distributions, by computing the following value. To reduce the number of false positives, no candidate found by the MI measures is considered an error if it appears in the word-specific corpus at least two times. For example, a knowledge will not be treated as an error because it appears in the training corpus as part of the longer a knowledge of sequence (as in a knowledge of mathematics). ALEK also uses another statistical technique for finding rare and possibly ungrammatical tag and function word bigrams by computing the x2 (chi square) statistic for the difference between the bigram proportions found in the word-specific and in the general corpus: = The x2 measure faces the same problem of overgenerating errors. To reduce false positives, ALEK requires that effect sizes be at least in the moderate-to-small range (Cohen and Cohen, 1983). For each candidate error, ALEK compares the larger context in which the bigram appears to the contexts that have been analyzed in the word-specific corpus. From the wordspecific corpus, ALEK forms templates, sequences of words and tags that represent the local context of the target. If a test sentence contains a low probability bigram (as measured by the x2 test), the local context of the target is compared to all the templates of which it is a part. To illustrate this, consider the example of a knowledge and a knowledge of The conditional probability of of given a knowledge is high, as it accounts for almost all of the occurrences of a knowledge in the wordspecific corpus. Other function words and tags in the +1 position have much lower conditional probability, so for example, a knowledge is will not be treated as an exception to the error. TOEFL essays are graded on a 6 point scale, where 6 demonstrates &quot;clear competence&quot; in writing on rhetorical and syntactic levels and 1 demonstrates &quot;incompetence in writing&quot;. In every super-essay, for each adjacent pair and triple of tags containing a noun, verb, or adjective, the bigram and trigram mutual information values were computed based on the general corpus. As predicted, there is a significant negative correlation between the score and the proportion of low probability bigrams (r,= -.94, n=6, p<.01, two-tailed) and trigrams (r,= -.84, n=6, p<.05, two-tailed). ALEK was developed using three target words that were extracted from TOEFL essays: concentrate, interest, and knowledge. Before development began, each occurrence of these words was manually labeled as an appropriate or inappropriate usage  without taking into account grammatical errors that might have been present elsewhere in the sentence but which were not within the target word's scope. These words were randomly selected from those which met two criteria: (1) They appear in a university word list (Nation, 1990) as words that a student in a US university will be expected to encounter and (2) there were at least 1,000 sentences containing the word in the TOEFL essay pool. To build the usage model for each target word, 10,000 sentences containing it were extracted from the North American News Corpus. As in the development system, the model of general English was based on bigram and trigram frequencies of function words and part-ofspeech tags from 30-million words of the San Jose Mercury News. For each test word, all of the test sentences were marked by ALEK as either containing an error or not containing an error. To evaluate the system, for each test word we randomly extracted 125 sentences that ALEK classified as containing no error (C-set) and 125 sentences which it labeled as containing an error (E-set). The linguist, who had no part in ALEK's development, marked each usage of the target word as incorrect or correct and in the case of incorrect usage indicated how far from the target one would have to look in order to recognise that there was an error. For example, in the case of &quot;an period&quot; the error occurs at a distance of one word from period. When the error is an omission, as in &quot;lived in Victorian period&quot;, the distance is where the missing word should have appeared. ALEK's estimated recall is the proportion of sentences in the E-set times its precision, divided by the overall estimated error rate (.083 x .912) / .245 = .310. Nicholls (1999) identifies four error types: an unnecessary word (*affect to their emotions), a missing word (*opportunity of job. ), a word or phrase that needs replacing (*every jobs), a word used in the wrong form (*pollutions). For closed class words, ALEK identified whether a word was missing, the wrong word was used (choice), and when an extra word was used. Since TEOFL graders are not supposed to take punctuation into account, punctuation errors were only marked when they caused the judge to &quot;garden path&quot; or initially misinterpret the sentence. Spelling was marked either when a function word was misspelled, causing part-ofspeech tagging errors, or when the writer's intent was unclear. ALEK is sensitive to open-class word confusions (affect vs effect) where the part of speech differs or where the target word is confused with another word (*In this aspect, ... instead of In this respect,...). In addition, ALEK does not recognize semantic errors when the error involves the misuse of an open-class word in combination with the target (for example, make in &quot;they make benefits&quot;). Since ALEK trains on all senses of concentrate, it does not detect the error in &quot;Susan concentrated in her studies&quot;. Another cause is that adjuncts, especially temporal and locative adverbials, distribute freely in the wordspecific corpora, as in &quot;Susan concentrated in her room.&quot; This second problem is more tractable than the polysemy problem  and would involve training the system to recognize certain types of adjuncts. False positives, when ALEK &quot;identifies&quot; an error where none exists, fall into six major categories. For example, ALEK false alarms on arguments of ditransitive verbs such as offer and flags as an error &quot;you benefits&quot; in &quot;offers you benefits&quot;. Since these errors are not indicative of one's ability to use the target word, they were not considered as errors unless they caused the judge to misanalyze the sentence. An undesirable result of our &quot;enriched&quot; tag set is that some tags, e.g., the post-determiner last, occur too infrequently in the corpora to provide reliable statistics. Given this limitation, we compared ALEK's performance to a widely used grammar checker, the one incorporated in Microsoft's Word97. We created files of sentences used for the three development words concentrate, interest, and knowledge, and manually corrected any errors outside the local context around the target before checking them with Word97. In summary, Word97's precision in error detection is impressive, but the lower recall values indicate that it is responding to fewer error types than does ALEK. In particular, Word97 is not sensitive to inappropriate selection of prepositions for these three words (e.g., *have knowledge on history, *to concentrate at science). Park, Palmer and Washburn (1997) adapted a categorial grammar to recognize &quot;classes of errors [that] dominate&quot; in the nine essays they inspected.