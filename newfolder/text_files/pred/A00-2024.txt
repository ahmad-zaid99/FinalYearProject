 Examples include sentence reduction, sentence combination, syntactic transformation, and lexical paraphrasing. We implemented a sentence reduction module that removes extraneous phrases from extracted sentences, and a sentence combination module that merges the extracted sentences or the reduced forms resulting from sentence reduction. Our sentence reduction model determines what to cut based on multiple sources of information, including syntactic knowledge, context, and statistics learned from corpus analysis. The major components of the system, including sentence reduction, sentence combination, decomposition, and sentence selection, are described in Section 4. One school of scholars is opposed; &quot;(use) your own words... Do not keep too close to the words before you&quot;, states an early book on abstracting for American high school students (Thurber, 1924). Another study, however, shows that professional abstractors actually rely on cutting and pasting to produce summaries: &quot;Their professional role tells abstractors to avoid inventing anything. They follow the author as closely as possible and reintegrate the most important points of a document in a shorter text&quot; (Endres-Niggemeyer et al., 1998). Some studies are somewhere in between: &quot;summary language may or may not follow that of author's&quot; (Fidel, 1986). We manually analyzed 30 articles and their corresponding human-written summaries; the articles and their summaries come from different domains ( 15 general news reports, 5 from the medical domain, 10 from the legal domain) and the summaries were written by professionals from different organizations. We defined six operations that can be used alone, sequentially, or simultaneously to transform selected sentences from an article into the corresponding summary sentences in its human-written abstract:
Remove extraneous phrases from a selected sentence, as in the following example 1: 'All the examples in this section were produced by human professionals Document sentence: When it arrives sometime next year in new TV sets, the V-chip will give parents a new and potentially revolutionary device to block out programs they don't want their children to see. It can be used together with sentence reduction, as illustrated in the following example, which also uses paraphrasing: Text Sentence 1: But it also raises serious questions about the privacy of such highly personal information wafting about the digital world. Text Sentence 2: The issue thus fits squarely into the broader debate about privacy and security on the internet, whether it involves protecting credit card number or keeping children from offensive information. Examples of generalization and specification include: Generalization: &quot;a proposed new law that would require Web publishers to obtain parental consent before collecting personal information from children&quot; &quot;legislation to protect children's privacy on-line&quot; Specification: &quot;the White House's top drug official&quot; -4 &quot;Gen. Barry R. McCaffrey, the White House's top drug official&quot;
Change the order of extracted sentences. In human-written abstracts, there are, of course, sentences that are not based on cut and paste, but completely written from scratch. We used our decomposition program to automatically analyze 300 human-written abstracts, and found that 19% of sentences in the abstracts were written from scratch. In the first stage, extraction, key sentences in the article are identified, as in most current summarizers. In the second stage, cut and paste based generation, a sentence reduction module and a sentence combination module implement the operations we observed in human-written abstracts. The cut and paste based component receives as input not only the extracted key sentences, but also the original article. This component can be ported to other single-document summarizers to serve as the generation component, since most current summarizers extract key sentences - exactly what the extraction module in our system does. Other resources and tools in the summarization system include a corpus of articles and their humanwritten abstracts, the automatic decomposition program, a syntactic parser, a co-reference resolution system, the WordNet lexical database, and a largescale lexicon we combined from multiple resources. The main focus of our work is on decomposition of summaries, sentence reduction, and sentence combination. The decomposition program, see (Jing and McKeown, 1999) for details, is used to analyze the construction of sentences in human-written abstracts. The Viterbi algorithm (Viterbi, 1967) is used to efficiently find the most likely document position for each word in the summary sentence. For the given summary sentence, the program correctly identified that the sentence was combined from four sentences in the input article. A phrase in the summary sentence is annotated as (FNUM:SNUM actual-text), where FNUM is the sequential number of the phrase and SNUM is the number of the document sentence where the phrase comes from. The task of the sentence reduction module, described in detail in (Jing, 2000), is to remove extraneous phrases from extracted sentences. The goal of reduction is to &quot;reduce without major loss&quot;; that is, we want to remove as many extraneous phrases as possible from an extracted sentence so that it can be concise, but without detracting from the main idea that the sentence conveys. Our reduction module makes decisions based on multiple sources of knowledge: Original sentence : When it arrives sometime next year in new TV sets, the V-chip will give parents a new and potentially revolutionary device to block out programs they don't want their children to see. This shortened text can be used directly as a summary, or it can be fed to the sentence combination module to be merged with other sentences. 21t is actually also possible that the reduction program decides no phrase in a sentence should be removed, thus the result of reduction is the same as the input. To build the combination module, we first manually analyzed a corpus of combination examples produced by human professionals, automatically created by the decomposition program, and identified a list of combination operations. First, we link words in a sentence with other words in the article through repetitions, morphological relations, or one of the lexical relations encoded in WordNet, similar to step 2 in sentence reduction. This score is then normalIF: ((a person or an organization is mentioned the first time) and (the full name or the full description of the person or the organization exists somewhere in the original article but is missing in the summary)) THEN: replace the phrase with the full name plus the full description IF: ((two sentences are close to each other in the original article) and (their subjects refer to the same entity) and (at least one of the sentences is the reduced form resulting from sentence reduction)) THEN: merge the two sentences by removing the subject in the second sentence, and then combining it with the first sentence using connective &quot;and&quot;. The extraction system selects sentences based on the importance computed as above, as well as other indicators, including sentence positions, cue phrases, and tf*idf scores. In the first experiment, we selected 50 human-written abstracts, consisting of 305 sentences in total. We compared the set of sentences identified by the program with the set of sentences selected by the majority of human subjects, which is used as the gold standard in the computation of precision and recall. Recently, we have also tested the system on legal documents (the headnotes used by Westlaw company), and the program works well on those documents too. The evaluation of sentence reduction (see (Jing, 2000) for details) used a corpus of 500 sentences and their reduced forms in human-written abstracts. The humans reduced the length of the 500 sentences by 44.2% on average, and the system reduced the length of the 100 test sentences by 32.7%. The evaluation of sentence combination module is not as straightforward as that of decomposition or reduction since combination happens later in the pipeline and it depends on the output from prior The new measure is an echo of the original bad idea, blurred just enough to cloud prospects both for enforcement and for court review. The new version also replaces the vague &quot;indecency&quot; standard, to which the court objected, with the better-defined one of material ruled &quot;harmful to minors.&quot; Combined sentences: The new measure is an echo of the original bad idea. In the intrinsic evaluation, we asked human subjects to compare the quality of extraction-based summaries and their revised versions produced by our sentence reduction and combination modules. We selected 20 documents; three different automatic summarizers were used to generate a summary for each document, producing 60 summaries in total. We then ran our sentence reduction and sentence combination system to revise the summaries, producing a revised version for each summary. The human subjects were asked to score the conciseness of the summaries (extractionbased or revised) based on a scale from 0 to 10 the higher the score, the more concise a summary is. On average, the extraction-based summaries have a score of 4.2 for conciseness, while the revised summaries have a score of 7.9 (an improvement of 88%). For summary coherence, the average score for the extraction-based summaries is 3.9, while the average score for the revised summaries is 6.1 (an improvement of 56%). We are preparing a task-based evaluation, in which we will use the data from the Summarization Evaluation Conference (Mani et al., 1998) and compare how our revised summaries can influence humans' performance in tasks like text categorization and ad-hoc retrieval.