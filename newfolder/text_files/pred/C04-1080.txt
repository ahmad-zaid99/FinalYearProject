 In a traditional HMM tagger, the probability of transitioning into a state representing tag ti is computed based on the previous two tags ti-1 and ti 2, and the probability of a word wi is conditioned only on the current tag ti. This type of structure is analogous to context-dependent phone models used in acoustic modeling for speech recognition (e.g.Young, 1999, Section 4.3). In order to build both left and right-context into an HMM part-of-speech tagger, we reformulate the Figure 1: Graphical Structure of Traditional HMM Tagger (top) and Contextualized HMM Tagger (bottom) trigram HMM model traditionally described as ? ?= n i iiiiiiiii twtwtpttwtwwpTWp 1 111111 )..|()...|(),( by replacing the approximation: )|()..|( )|()...|( 1211 1111 ???? = = iiiiiiii iiiiiii tttptwtwtp tttwptwtwwp Given that we are using an increased context size during the estimation of lexical probabilities, thus fragmenting the data, we have found it desirable to smooth these estimates, for which we use a standard absolute discounting scheme (Ney, Essen and Knesser, 1994). For our comparison of unsupervised tagging methods, we implemented the HMM taggers described in Merialdo (1991) and Kupiec (1992), as well as the UTBL tagger described in Brill (1995). The algorithms were trained and tested using version 3 of the Penn Treebank, using the training, development, and test split described in Collins (2002) and also employed by Toutanova et al (2003) in testing their supervised tagging algorithm. One issue we noticed which impacted tagging accuracy was that of a frequently occurring word (a) The/VB Lyneses/NNP ,/, of/IN Powder/NNP Springs/NNP ,/, Ga./NNP ,/, have/VBP filed/VBN suit/NN in/IN Georgia/NNP state/NN court/NN against/IN Stuart/NNP James/NNP ,/, *-1/-NONE- alleging/VBG fraud/NN ./. In another, more frequently occurring scenario, human annotators have chosen to tag all words in multi word names, such as titles, with the proper-noun tag, NNP (Figure 2b). a, to, of) are sometimes labeled with infrequently occurring tags (e.g. In the case of the HMM taggers, where we begin with uniform estimates of both the state transition probabilities and the lexical probabilities, the learner finds it difficult to distinguish between more and less probable tag assignments. The best test set accuracies for the learners in the class of HMM taggers are 1 Eric Brill, Personal Communication 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0 0.1 0.2 0.3 Threshold Ta g A cc u ra c y Merialdo Trigram Contextual Trigram Kupiec Trigram UTBL Figure 3: The effect of lexicon construction on unsupervised part-of-speech taggers 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0 1 2 3 4 5 Iteration Ta g A cc u ra cy Contextual Trigram Kupiec Trigram Merialdo Trigram Figure 4: Test Accuracy of HMMs using Optimzed Lexicons plotted against the number of training iterations in Figure 4. Unfiltered Lexicon Optimized Lexicon Merialdo HMM 71.9 93.9 Contextualized HMM 76.9 94.0 Kupiec HMM 77.1 95.9 UTBL 77.2 95.9 Contextualized HMM with Classes 77.2 95.9 Table 1: Tag Accuracy of Unsupervised POS Taggers 5.1 Using Unambiguous Tag Sequences To. This approach is similar to that described in Ratnaparhki (1998), who used unambiguous phrasal attachments to train an unsupervised prepositional phrase attachment model. From our training data, we were able to extract data for on the order of 10,000 unique unambiguous tag sequences which were then be used for better initializing the state transition probabilities. As shown in Table 2, this method improved tagging accuracy of the Merialdo and contextual taggers over traditional simultaneous HMM training, reducing error by 0.4 in the case of Merialdo and 0.7 for the contextual HMM part-of-speech tagger. HMM Tagger Simultaneous Model Training Sequential Model Training Merialdo 93.9 94.3 Contextualized 94.0 94.7 Kupiec 95.9 95.9 Table 2: Effects of HMM Training on Tagger Accuracy In this paradigm, tagging accuracy of the Kupiec HMM did not change. As one more way to assess the potential benefit from using left and right context in an HMM tagger, we tested our tagging model in the supervised framework, using the same sections of the Treebank previously allocated for unsupervised training, development and testing. In addition to comparing against a baseline tagger, which always chooses a word?s most frequent tag, we implemented and trained a version of a standard HMM trigram tagger. We also chose to examine this tagger?s results when using only <ti, t i-1, t i+1> as feature templates, which represents the same amount of context built into our contextualized tagger. As shown in Table 3, incorporating more context into an HMM when estimating lexical probabilities improved accuracy from 95.87% to 96.59%, relatively reducing error rate by 17.4%.