Potential sentence boundaries are identified by scanning the text for sequences of characters separated by whitespace (tokens) containing one of the symbols !, . or ?.
The exact information used by the maximum entropy model for the potential sentence boundary marked by . in Corp. in Example 1 would be: PreviousWordIsCapitalized, Prefix= Corp, Suffix=NULL, PrefixFeature=CorporateDesignator.
The highly portable system uses only the identity of the Candidate and its neighboring words, and a list of abbreviations induced from the training data.2 Specifically, the &amp;quot;templates&amp;quot; used are: The information this model would use for Example 1 would be: PreviousWord=ANLP, FollowingWord=chairmon, Prefix=Corp, Suffix=NULL, PrefixFeature=InducedAbbreviation.
For each potential sentence boundary token (., ?, and !, we estimate a. joint, probability distribution p of the token and its surrounding context, both of which are denoted by c, occurring as an actual sentence boundary.
The distribution is given by: p(b, c) = Ir &#8222;,,,.f-(b&#8222;c), where b e no, yes}, where the cri's are the unknown parameters of the model, and where each aj corresponds to a fi, or a feature.
Thus the probability of seeing an actual sentence boundary in the context c is given by p(yes, c).
>We trained our system on 39441 sentences (898737 words) of Wall Street Journal text from sections 00 through 24 of the second release of the Penn Treebank3 (Marcus, Santorini, and Marcinkiewicz, 1993).
The first test set, WSJ, is Palmer and Hearst's initial test data and the second is the entire Brown corpus.
Since 39441 training sentences is considerably more than might exist in a new domain or a language other than English, we experimented with the quantity of training data required to maintain performance.
>As can seen from the table, performance degrades a.s the quantity of training data decreases, but even with only 500 example sentences performance is beter than the baselines of 64.00/0 if a. sentence boundary is guessed at every potential site and 78.4%, if only token-final instances of sentence-ending punctuation are assumed to be boundaries.
