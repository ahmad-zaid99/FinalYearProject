 Generate a set of initial translation hypotheses H = {h1 ?hn} for source sentences s, using either the baseline MT system with the background language model or only the translation model ? As an alternative to using translations for the baseline system, we will also describe an approach, which uses partial translations of the source sentence, using the translation model only. Our approach focuses on query model building, using different levels of knowledge representations from the hypothesis set or from the translation model itself. We follow (Eck, et al, 2004) in considering each sentence in the monolingual corpus as a document, as they have shown that this gives better results compared to retrieving entire news stories. All sentences are ranked according to their similarity with the query, and the most similar sentences are used as the data for building the specific language model. models, based on different levels of knowledge collected from the hypotheses of the statistical machine translation engine. It is the optimal hypothesis the statistical machine translation system can generate using the given translation and language model, and restricted by the applied pruning strategy. Ignoring word order, the hypothesis is converted into a bag-of-words representation, which is then used as a query: }|),{(),,( 1211 TiiilT VwfwwwwQ ?== L where iw is a word in the vocabulary 1TV of the Top 1 hypothesis. The first-best hypothesis is the actual translation we want to improve, and usually it captures enough correct word translations to secure a sound adaptation process. But it can miss some informative translation words, which could lead to better-adapted language models. 2.2.2 N-Best Hypothesis List as a Query Model Similar to the first-best hypothesis, the n-best hypothesis list is converted into a bag-of-words representation. }|),{( ),,;;,,( ,2,1,,12,11,1 1 TNiii lNNNlTN Vwfw wwwwwwQ N ?= = LLL where TNV is the combined vocabulary from all n best hypotheses and if is the frequency of iw ?s occurrence in the n-best hypothesis list. In addition, the confidently translated words usually occur in every hypothesis in the n-best list, therefore have a stronger impact on the retrieval result due to the higher term frequency (tf) in the query. 2.2.3 Translation Model as a Query Model To fully leverage the available knowledge from the translation system, the translation model can be used to guide the language model adaptation process. As introduced in section 1, the translation model represents the full knowledge of translating words, as it encodes all possible translations candidates for a given source sentence. Thus the query model based on the translation model, has potential advantages over both 1TQ and TNQ . To utilize the translation model, all the n-grams from the source sentence are extracted, and the corresponding candidate translations are collected from the translation model. These are then converted into a bag-of-words representation as follows: }|),{( ),,;;,,( ,2,1,,2,1, 1111 TMiii nsssnsssTM Vwfw wwwwwwQ IIII ?= = LLL where is is a source n-gram, and I is the number of n-grams in the source sentence. This means TMQ does not incorporate any background language model information at all, while both 1TQ and TNQ implicitly use the background language model to prune the words in the query. However, it is not modeled in the query models presented so far, which are simple bag-of-words representations. The word-proximity and word ordering information can be easily extracted from the first best hypothesis, the n-best hypothesis list, and the translation lattice built from the translation model. After extraction of the information, structured query models are proposed using the structured query language, described in the Section 3.1. This query language essentially enables the use of proximity operators (ordered and unordered windows) in queries, so that it is possible to model the syntactic and semantic information encoded in phrases, n-grams, and co-occurred word pairs. So far 16 operators are defined in InQuery to model word proximity (ordered, unordered, phrase level, and passage level). Given the representation power of the structured query language, the Top-1 hypothesis, Top-N Best hypothesis list, and the translation lattice can be converted into three Structured Query Models respectively. If the system is a phrase-based translation system, we can encode the phrases using the ordered distance operator (#N) with N equals to the number of the words of that phrase, which is denoted as the #phrase operator in InQuery implementation. An example is shown below, where #phrase indicates the use of the ordered distance operator with varying n: #q=#sum( #wsum(2 eu 2 #phrase(european union) ) #wsum(12 #phrase(the united states) 1 american 1 #phrase(an american) ) #wsum(4 are 1 is ) #wsum(8 markets 3 market)) #wsum(7 #phrase(the main) 5 primary ) );
Experiments are carried out on a standard statistical machine translation task defined in the NIST evaluation in June 2002. Our baseline system (Vogel et al, 2003) gives scores of 7.80 NIST and 0.1952 Bleu for Top-1 hypothesis, which is comparable to the best results reported on this task. For the baseline system, we built a translation model using 284K parallel sentence pairs, and a trigram language model from a 160 million words general English news text collection. With the baseline system, the n-best hypotheses list and the translation lattice are extracted to build the query models. Experiments are carried out on the adapted language model using the three bag-of words query models: 1TQ , TNQ and TMQ , and the corresponding structured query models. AFE APW NYT XIE 170,969K 539,665K 914,159K 131,711K Table-1: Number of words in the different GigaWord corpora As the Lemur toolkit could not handle the two large corpora (APW and NYT) we used only 200 million words from each of these two corpora. Table-2 shows the size of 1TQ , TNQ and TMQ in terms of number of tokens in the 878 queries: 1TQ TNQ TMQ || Q 25,861 231,834 3,412,512 Table-2: Query size in number of tokens As words occurring several times are reduced to word-frequency pairs, the size of the queries generated from the 100-best translation lists is only 9 times as big as the queries generated from the first-best translations. For each of the 4 corpora different numbers of similar sentences (1, 10, 100, and 1000) were retrieved to build specific language models. 1-Best/NIST Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline 1-Best/BLEU-Scores 0.1900 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Figure-2: NIST and Bleu scores 1TQ We see that each corpus gives an improvement over the baseline. 100-Best/NIST-Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline 100-Best/BLEU-Scores 0.1900 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Figure-3: NIST and Bleu scores from TNQ Using the translation alternatives to retrieve the data for language model adaptation gives an improvement over using the first-best translation only for query construction. 4.3.3 Results for Query TMQ The third bag-of-words query model uses all translation alternatives for source words and source phrases. The reason is probably that all translation alternatives, even wrong translations resulting from errors in the word and phrase alignment, contribute alike to retrieve similar sentences. Thereby, an adapted language model is built, which reinforces not only good translations, but also bad translations. Lattice/NIST-Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Lattice/BLEU-Scores 0.1900 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Figure-4: NIST and Bleu scores from TMQ 4.4 Structured Query Models. By using the structured query language we converted the same first-best hypothesis, the 100-best list, and the translation lattice into structured query models. Figure-5 shows the results for all three structured query models, built from the first-best hypothesis (?1-Best? ), and translation lattice (?TM-Lattice?). Using these query models, different numbers of most similar sentences, ranging from 100 to 4000, where retrieved from the AFE corpus. Again, optimal interpolation factors to interpolate the specific language models with the background language model were used, which typically were in the range of [0.6, 0.7]. Structured query models give most improvements when using more sentences for language model adaptation. Structured query/NIST-Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 8.0500 8.1000 8.1500 Baseline Top100 Top500 Top1000 Top2000 Top4000 1-Best 100-Best TM-Lattice Structured query/BLEU-Scores 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 0.2060 0.2080 Baseline Top100 Top500 Top1000 Top2000 Top4000 1-Best 100-Best TM-Lattice Figure-5: NIST and Bleu scores from the structured query models The really interesting result is that the structured query model TMQ gives now the best translation results. Adding word order information to the queries obviously helps to reduce the noise in the retrieved data by selecting sentences, which are closer to the good translations, The best results using the adapted language models are NIST score 8.12 for using the 2000 most similar sentences, whereas Bleu score goes up to 0.2068 when using 4000 sentences for language model adaptation. We applied the baseline system (Base), the bag-of-word query model (Hyp1), and the structured query model (Hyp2) using AFE corpus. Table-3 Translation examples 4.6 Oracle Experiment Finally, we run an oracle experiments to see how much improvement could be achieved if we only selected better data for the specific language models. We converted the four available reference translations into structured query models and retrieved the top 4000 relevant sentences from AFE corpus for each source sentence. Using these language models, interpolated with the background language model gave a NIST score of 8.67, and a Bleu score of 0.2228. This lead to the question if we can iterate the retrieval process several times to get further improvement, or if the observed improvement results form using for (good) translations, which have more diversity than the translations in an n-best list. In this paper, we studied language model adaptation for statistical machine translation. Extracting sentences most similar to the initial translations, building specific language models for each sentence to be translated, and interpolating those with the background language models gives significant improvement in translation quality. Using structured query models, which capture word order information, leads to better results that plain bag of words models.