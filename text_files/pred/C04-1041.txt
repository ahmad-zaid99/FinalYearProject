 Parsing using CCG can be viewed as a two-stage process: first assign lexical categories to the wordsin the sentence, and then combine the categories to gether using CCG?s combinatory rules.1 The first stage can be accomplished by simply assigning to each word all categories from the word?s entry in the lexicon (Hockenmaier, 2003). 1See Steedman (2000) for an introduction to CCG, and see Clark et al (2002) and Hockenmaier (2003) for an introduction to wide-coverage parsing using CCG. The WSJ is a publication that I enjoy reading NP/N N (S[dcl]\NP)/NP NP/N N (NP\NP)/(S[dcl]/NP) NP (S[dcl]\NP)/(S[ng]\NP) (S[ng]\NP)/NP Figure 1: Example sentence with CCG lexical categories frequency # cat types # cat tokens in # sentences in 2-21 # cat tokens in # sentences in 00 cut-off 2-21 not in cat set with missing cat 00 not in cat set with missing cat 1 1 225 0 0 12 (0.03%) 12 (0.6%) 10 409 1 933 (0.2%) 1 712 (4.3%) 79 (0.2%) 69 (3.6%) Table 1: Statistics for the lexical category setAn alternative is to use a statistical tagging approach to assign one or more categories. An advantage of the Maximum Entropy approachis that it is easy to encode a wide range of poten tially useful information as features; for example,Clark (2002) has shown that POS tags provide use ful information for supertagging. The set of lexical categories is obtained from CCGbank (Hockenmaier and Steedman, 2002; Hockenmaier, 2003), a corpus of CCG normal-form deriva tions derived semi-automatically from the PennTreebank. Following Clark (2002), we apply a fre quency cutoff to the training set, only using thosecategories which appear at least 10 times in sections 2-21. Table 1 gives the number of different category types and shows the coverage on training (seen) anddevelopment (unseen) data (section 00 from CCGbank). The grammars of Chen and Vijay Shanker (2000) contain between 2,000 and 9,000 tree frames, depending on the parameters used inthe extraction process, significantly more elemen tary structures than the number of lexical categories derived from CCGbank. i ?i fi(y,x) (1) where fi is a feature, ?i is the corresponding weight, and Z(x) is a normalisation constant. Curran and Clark(2003) describes the model and explains how Gen eralised Iterative Scaling, together with a Gaussian prior for smoothing, can be used to set the weights. The supertagger in Curran and Clark (2003) finds the single most probable category sequence given the sentence, and uses additional features defined in terms of the previously assigned categories. Theper-word accuracy is between 91 and 92% on un seen data in CCGbank; however, Clark (2002) shows this is not high enough for integration into a parser since the large number of incorrect categories results in a significant loss in coverage. Clark (2002) shows how the models in (1) can be used to define a multi-tagger which can assign more than one category to a word. CATS/ ACC SENT ACC SENT WORD ACC (POS) ACC 0.1 1.4 97.0 62.6 96.4 57.4 0.075 1.5 97.4 65.9 96.8 60.6 0.05 1.7 97.8 70.2 97.3 64.4 0.01 2.9 98.5 78.4 98.2 74.2 0.01k=100 3.5 98.9 83.6 98.6 78.9 0 21.9 99.1 84.8 99.0 83.0 Table 2: Supertagger accuracy on section 00 egories whose probability according to (1) is within some factor, ?, of the highest probability category for the word. For words seen at least k times in the trainingdata, the tagger can only assign categories appear ing in the word?s entry in the tag dictionary. For words seen less than k times, we use an alternative dictionary based on the word?s POS tag: the tagger can only assign categories that have been seen with the POS tag in the training data. A value of k = 20was used in this work, and sections 2-21 of CCG bank were used as training data.Table 2 gives the per-word accuracy (acc) on sec tion 00 for various values of ?, together with the average number of categories per word. The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran andClark (2003) tagger. For words which appear less than 20 times in the training data, the dictionary based on the word?s POS tag is used. To give one example, the number of categories in the tag dictionary?s entry for the wordis is 45 (only considering categories which have appeared at least 10 times in the training data). A packed chart is used to efficiently represent all of the possible analyses for a sentence, and the CKY chart parsing algorithm described in Steedman (2000) is used to build the chart. In this paper weuse the normal-form model, which defines proba bilities with the conditional log-linear form in (1), where y is a derivation and x is a sentence. . . . . The objective function is optimised using L-BFGS (Nocedal and Wright, 1999), an iterative algorithm from the numerical optimisation lit erature.The algorithm requires the gradient of the objective function, and the value of the objective function, at each iteration. However, a very large amount of memory is still needed to store the packed charts for the complete training data even though the representation is very compact; in Clark and Curran (2003) we report a memory usage of 30 GB. The need for large high-performance computing resources is a disadvantage of our earlier approach.In the next section we show how use of the supertag ger, combined with normal-form constraints on thederivations, can significantly reduce the memory re quirements for the model estimation. Since the training data contains the correct lexicalcategories, we ensure the correct category is as signed to each word when generating the packed charts for model estimation. Whilst training theparser, the supertagger can be thought of as supply ing a number of plausible but incorrect categoriesfor each word; these, together with the correct cat egories, determine the parts of the parse space that are used in the estimation process. Thefirst, following Hockenmaier (2003), is to only al low categories to combine if the combination hasbeen seen in sections 2-21 of CCGbank. For exam ple, NP/NP could combine with NP/NP accordingto CCG?s combinatory rules (by forward composi tion), but since this particular combination does not appear in CCGbank the parser does not allow it.The second strategy is to use Eisner?s normal form constraints (Eisner, 1996). 0.1 2 GB 4 GB Table 3: Space requirements for model training dataprevent any constituent which is the result of a forward (backward) composition serving as the primary functor in another forward (backward) composition or a forward (backward) application. Table 3 shows the effect of different supertagger set tings, and the normal-form constraints, on the size of the packed charts used for model estimation. The training sen tences are parsed using a number of nodes from a 64-node Beowulf cluster.3 The time taken to parse the training sentences depends on the supertagging and parsing constraints, and the number of nodes used, but is typically around 30 minutes. = 0.05, and finally ? This strategy was used in our earlier work (Clark and Curran, 2003) and, as the table shows, results in very large charts.Note that, even with this relaxed setting on the su pertagger, the number of categories assigned to each word is only around 3 on average. This suggests that it is only through use of the supertagger that we are able to estimate a log-linear parsing model on all of the training data at all, since without it the memory 3The figures in the table are estimates based on a sample of the nodes in the cluster. requirements would be far too great, even for the entire 64-node cluster.4 The second row shows the reduction in size if the parser is only allowed to combine categorieswhich have combined in the training data. (These are used to analysesome coordination and extraction cases, for example.) In Clark andCurran (2004) we show that the parsing model re sulting from training data generated in this way produces state-of-the-art CCG dependency recovery: 84.6 F-score over labelled dependencies. In Clark and Curran(2004) we show that using this more restrictive set ting has a small negative impact on the accuracy of the resulting parser (about 0.6 F-score over labelled dependencies). The previous section showed how to combine the supertagger and parser for the purpose of creating training data, assuming the correct category for each word is known. Our previous approach to parsing unseen data (Clark et al, 2002; Clark and Curran, 2003) wasto use the least restrictive setting of the supertagger which still allows a reasonable compromise be tween speed and accuracy. = 0.1?0.01k=100 608 3.9 90 CCGbank constraints 124 19.4 440 Eisner constraints 100 24.0 546 Parser beam 67 35.8 814 94% coverage 49 49.0 1 114 Parser beam 46 52.2 1 186 Oracle 18 133.4 3 031 Table 4: Parse times for section 23 The problem with this approach is that, for some sentences, the number of categories in the chart still gets extremely large and so parsing is unacceptably slow. = 0.05, and finally ? In this paper we take the opposite approach: westart with a very restrictive setting of the supertag ger, and only assign more categories if the parser cannot find an analysis spanning the sentence. The results in this section are all using the best per forming normal-form model in Clark and Curran (2004), which corresponds to row 3 in Table 3. CATS/ 0.1 FIRST 0.01 FIRST WORD PARSES % PARSES % 0.1 1.4 1689 88.4 0 0.0 0.075 1.5 43 2.3 7 0.4 0.05 1.7 51 2.7 39 2.0 0.01 2.9 79 4.1 1816 95.1 0.01k=100 3.5 33 1.7 33 1.7 NO SPAN 15 0.8 15 0.8 Table 5: Supertagger ? The parse times and speeds include the failed sentences, but do not include the time takenby the supertagger; however, the supertagger is ex tremely efficient, and takes less than 6 seconds to supertag section 23, most of which consists of load time for the Maximum Entropy model. = 0.01k=100; if the node limit is ex ceeded (for these experiments set at 1,000,000), ? The second row has the CCGbank rule restriction applied, and the third row the Eisner normal-form restrictions.The next three rows correspond to our new strat egy of starting with the least restrictive setting of thesupertagger (? = 0.1), and moving through the set tings if the parser cannot find a spanning analysis. The oracle row shows the parser speed when it is provided with only the correct lexical categories.The parser is extremely fast, and in Clark and Cur ran (2004) we show that the F-score for labelled dependencies is almost 98%. Here we simply use the ex ponential of the inside score of a category as the beam score; the inside score for a category c is the sum over all sub-derivations dominated by c of the weights of the features in those sub-derivations (see Clark and Curran (2004).5The value of ? that we use here reduces the accu racy of the parser on section 00 by a small amount (0.3% labelled F-score), but has a significant impacton parser speed, reducing the parse times by a fur ther 33%. = 0.01); conversely, for the new ap proach, most of the sentences are parsed using the most restrictive setting (? As well as investigating parser efficiency, we have also evaluated the accuracy of the parser onsection 00 of CCGbank, using both parsing strate gies together with the normal-form constraints. The new strategy increases the F-score over labelled de pendencies by approximately 0.5%, leading to the figures reported in Clark and Curran (2004). Kaplan et al (2004) report high parsing speedsfor a deep parsing system which uses an LFG gram mar: 1.9 sentences per second for 560 sentencesfrom section 23 of the Penn Treebank. They also re port speeds for the publicly available Collins parser (Collins, 1999): 2.8 sentences per second for the same set.