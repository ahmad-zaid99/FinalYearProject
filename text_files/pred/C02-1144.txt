 Following (Lin 1998), we represent each word by a feature vector. If the word handgun occurred in this context, the context is a feature of handgun. Let c be a context and Fc(w) be the frequency count of a word w occurring in context c. The pointwise mutual information between c and w is defined as: ( ) ( ) ( ) N jF N wF N wF cw j c i i c mi ??? We therefore multiplied miw,c with a discounting factor: ( ) ( ) ( ) ( ) ( ) ( ) 11 +??? i j ci i j ci c c jF,wFmin jF,wFmin wF wF We compute the similarity between two words wi and wj using the cosine coefficient (Salton and McGill 1983) of their mutual information vectors: ( ) ?? = c cw c cw c cwcw ji ji ji mimi mimi w,wsim 22
CBC consists of three phases. In Phase I, we compute each element?s top-k similar elements. In Phase II, we construct a collection of tight clusters, where the elements of each cluster form a committee. In the final phase of the algorithm, each element is assigned to its most similar cluster. However, one can dramatically reduce the running time by taking advantage of the fact that the feature vector is sparse. By indexing the features, one can retrieve the set of elements that have a given feature. To compute the top similar words of a word w, we first sort w?s features according to their mutual information with w. We only compute pairwise similarities between w and the words that share a high mutual information feature with w. 4.2. In each recursive step, the algorithm finds a set of tight clusters, called committees, and identifies residue elements that are not covered by any committee. In Step 1, the score reflects a preference for bigger and tighter clusters. Step 2 gives preference to higher quality clusters in Step 3, where a cluster is only kept if its similarity to all previously kept clusters is below a fixed threshold. In our experiments, we set ?1 = 0.35. Input: A list of elements E to be clustered, a similarity database S from Phase I, thresh olds ?1 and ?2. avgsim(c), where |c| is the number of elements in c and avgsim(c) is the average pairwise simi larity between elements in c. Store the highest-scoring cluster in a list L. Step 2: Sort the clusters in L in descending order of their scores. Step 3: Let C be a list of committees, initially empty. If c?s similarity to the centroid of each committee previously added to C is be low a threshold ?1, add c to C. Step 4: If C is empty, we are done and return C. Step 5: For each element e ? E If e?s similarity to every committee in C is below threshold ?2, add e to a list of resi dues R. Step 6: If R is empty, we are done and return C. Otherwise, return the union of C and the output of a recursive call to Phase II us ing the same input except replacing E with R. Output: A list of committees. The residue elements are identified in Step 5 and if no residues are found, the algorithm terminates; otherwise, we recursively apply the algorithm to the residue elements. In Phase III, every element is assigned to the cluster containing the committee to which it is most similar. Unlike K-means, the number of clusters is not fixed and the centroids do not change (i.e. when an element is added to a cluster, it is not added to the committee of the cluster). An example of the first approach considers the average entropy of the clusters, which measures the purity of the clusters (Steinbach, Karypis, and Kumar 2000). However, maximum purity is trivially achieved when each element forms its own cluster. Like the entropy scheme, we assume that there is an answer key that defines how the elements are supposed to be clustered. We define the editing distance, dist(C, A), as the number of operations required to make C consistent with A. We say that C is consistent with A if there is a one to one mapping between clusters in C and the classes in A such that for each cluster c in C, all elements of c belong to the same class in A. We define the quality of a set of clusters C as follows: ( ) ( )ABdist ACdist , ,1? We aim to construct a clustering consistent with A as opposed to a clustering identical to A because some senses in A may not exist in the corpus used to generate C. In our experiments, we extract answer classes from WordNet. However, in the newspaper corpus, the Person sense of dog is at best extremely rare. The baseline distance dist(B, A) is exactly the number of elements to be clustered. We start with a list of m empty sets, each of which is labeled with a class in the answer key. For each cluster, merge it with the set. the same as one of the element?s classes, move the element to a set where it be longs. dist(C, A) is the number of operations performed using the above transformation rules on C. a b e c d e a c d b e b a c d e a b c d e A) B) C) D) E) Figure 2. A) The classes in the answer key; B) the clusters to be transformed; C) the sets used to reconstruct the classes (Rule 1); D) the sets after three merge operations (Step 2); E) the sets after one move operation (Step 3). We generated clusters from a news corpus using CBC and compared them with classes extracted from WordNet (Miller 1990). To extract classes from WordNet, we first estimate the probability of a random word belonging to a subhierarchy (a synset and its hyponyms). We use the frequency counts of synsets in the SemCor corpus (Landes, Leacock, Tengi 1998) to estimate the probability of a subhierarchy. Since SemCor is a fairly small corpus, the frequency counts of the synsets in the lower part of the WordNet hierarchy are very sparse. We used Minipar 1 (Lin 1994), a broad coverage English parser, to parse about 1GB (144M words) of newspaper text from the TREC collection (1988 AP Newswire, 1989-90 LA Times, and 1991 San Jose Mercury) at a speed of about 500 words/second on a PIII-750 with 512MB memory. The test set is constructed by intersecting the words in WordNet with the nouns in the corpus whose total mutual information with all of its contexts exceeds a threshold m. Since WordNet has a low coverage of proper names, we removed all capitalized nouns. We constructed two test sets: S13403 consisting of 13403 words (m = 250) and S3566 consisting of 3566 words (m = 3500). For S3566, 78 classes have three or less words and the largest class contains 1181 words. For the K-means and Buckshot algorithms, we set the number of clusters to 250 and the maximum number of iterations to 8. For the Bisecting K-means algorithm, we applied the basic K-means algorithm twice (?= 2 in Section 2) with a maximum of 8 iterations per split. Table 2 shows that K-means, Buckshot and Average-link have very similar performance. Let c be a cluster and wn(c) be the WordNet class that has the largest intersection with c. The precision of c is defined as: Table 1. ALGORITHM S13403 S3566 CBC 60.95 65.82 K-means (K=250) 56.70 62.48 Buckshot 56.26 63.15 Bisecting K-means 43.44 61.10 Chameleon n/a 60.82 Average-link 56.26 62.62 Complete-link 49.80 60.29 Single-link 20.00 31.74 ( ) ( ) c cwnc cprecision ?= CBC discovered 943 clusters. For each cluster c, we also include wn(c). In WordNet, the word pest is curiously only under the person hierarchy. In WordNet, the legal power sense of jurisdiction is not a hyponym of social control as are supervision, oversight and governance. Here is the consumer class in WordNet 1.5: addict, alcoholic, big spender, buyer, client, concert-goer, consumer, customer, cutter, diner, drinker, drug addict, drug user, drunk, eater, feeder, fungi, head, heroin addict, home buyer, junkie, junky, lush, nonsmoker, patron, policy holder, purchaser, reader, regular, shopper, smoker, spender, subscriber, sucker, taker, user, vegetarian, wearer In our cluster, only the word client belongs to WordNet?s consumer class. The cluster is ranked very low because WordNet failed to consider words like patient, tenant and renter as consumers. This is consistent with the fact that Bisecting K-means has a much lower score on S13403 compared to CBC, K means and Buckshot. RANK MEMBERS TOP-15 FEATURES wn(c) 1 handgun, revolver, shotgun, pistol, rifle, machine gun, sawed-off shotgun, submachine gun, gun, automatic pistol, automatic rifle, firearm, carbine, ammunition, magnum, cartridge, automatic, stopwatch __ blast, barrel of __ , brandish __, fire __, point __, pull out __, __ discharge, __ fire, __ go off, arm with __, fire with __, kill with __, open fire with __, shoot with __, threaten with __ artifact / artifact 236 whitefly, pest, aphid, fruit fly, termite, mosquito, cockroach, flea, beetle, killer bee, maggot, predator, mite, houseplant, cricket __ control, __ infestation, __ larvae, __ population, infestation of __, specie of __, swarm of __ , attract __, breed __, eat __, eradicate __, feed on __, get rid of __, repel __, ward off __ animal / animate being / beast / brute / creature / fauna 471 supervision, discipline, oversight, control, governance, decision making, jurisdiction breakdown in __, lack of __ , loss of __, assume __, exercise __, exert __, maintain __, retain __, seize __, tighten __, bring under __, operate under __, place under __, put under __, remain under __ act / human action / human activity 706 blend, mix, mixture, combination, juxtaposition, combine, amalgam, sprinkle, synthesis, hybrid, melange dip in __, marinate in __, pour in __, stir in __, use in __, add to __, pour __, stir __, curious __, eclectic __, ethnic __, odd __, potent __, unique __, unusual __ group / grouping 941 employee, client, patient, applicant, tenant, individual, participant, renter, volunteer, recipient, caller, internee, enrollee, giver benefit for __, care for __, housing for __, benefit to __, service to __, filed by __, paid by __, use by __, provide for __, require for --, give to __, offer to __, provide to __, disgruntled __, indigent __ worker