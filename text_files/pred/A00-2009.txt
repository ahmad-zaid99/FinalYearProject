 In word sense disambiguation, the context in which an ambiguous word occurs is represented by the feature variables (F1, F2, , Fn) and the sense of the ambiguous word is represented by the classification variable (S). In this paper, all feature variables Fi are binary and represent whether or not a particular word occurs within some number of words to the left or right of an ambiguous word, i.e., a window of context. For a Naive Bayesian classifier, the joint probability of observing a certain combination of contextual features with a particular sense is expressed as: The parameters of this model are p(S) and FilS) The sufficient statistics, i.e., the summaries of the data needed for parameter estimation, are the frequency counts of the events described by the interdependent variables (Fi, S). In this paper, these counts are the number of sentences in the sensetagged text where the word represented by Fi occurs within some specified window of context of the ambiguous word when it is used in sense S. Any parameter that has a value of zero indicates that the associated word never occurs with the specified sense value. Once all the parameters have been estimated, the model has been trained and can be used as a classifier to perform disambiguation by determining the most probable sense for an ambiguous word, given the context in which it occurs. This representation of context is a variation on the bag-of-words feature set, where a single window of context includes words that occur to both the left and right of the ambiguous word. An early use of this representation is described in (Gale et al., 1992), where word sense disambiguation is performed with a Naive Bayesian classifier. The work in this paper differs in that there are two windows of context, one representing words that occur to the left of the ambiguous word and another for those to the right. The left and right windows of context have nine different sizes; 0, 1, 2, 3, 4, 5, 10, 25, and 50 words. Naive_Bayes (1,r) represents a classifier where the model parameters have been estimated based on frequency counts of shallow lexical features from two windows of context; one including 1 words to the left of the ambiguous word and the other including r words to the right. Note that Naive_Bayes (0,0) includes no words to the left or right; this classifier acts as a majority classifier that assigns every instance of an ambiguous word to the most frequent sense in the training data. There are three such ranges; narrow corresponds to windows 0, 1 and 2 words wide, medium to windows 3, 4, and 5 words wide, and wide to windows 10, 25, and 50 words wide. For example, Naive_Bayes(1,3) belongs to the range category (narrow, medium) since it is based on a one word window to the left and a three word window to the right. The line data was created by (Leacock et al., 1993) by tagging every occurrence of line in the ACL/DCI Wall Street Journal corpus and the American Printing House for the Blind corpus with one of six possible WordNet senses. This data has since been used in studies by (Mooney, 1996), (Towell and Voorhees, 1998), and (Leacock et al., 1998). In that work, as well as in this paper, a subset of the corpus is utilized such that each sense is uniformly distributed; this reduces the accuracy of the majority classifier to 17%. The interest data was created by (Bruce and Wiebe, 1994) by tagging all occurrences of interest in the ACL/DCI Wall Street Journal corpus with senses from the Longman Dictionary of Contemporary English. This data set was subsequently used for word sense disambiguation experiments by (Ng and Lee, 1996), (Pedersen et al., 1997), and (Pedersen and Bruce, 1997). The senses and their fresense count product 2218 written or spoken text 405 telephone connection 429 formation of people or things; queue 349 an artificial division; boundary 376 a thin, flexible object; cord 371 total 4148 Table 1: Distribution of senses for line - the experiments in this paper and previous work use a uniformly distributed subset of this corpus, where each sense occurs 349 times. sense count money paid for the use of money 1252 a share in a company or business 500 readiness to give attention 361 advantage, advancement or favor 178 activity that one gives attention to 66 causing attention to be given to 11 total 2368 Table 2: Distribution of senses for interest - the experiments in this paper and previous work use the entire corpus, where each sense occurs the number of times shown above. Thus the training data for each word consists of 80% of the available sensetagged text, while each of the test sets contains 10%. The most accurate single classifier for line is Naive_Bayes (4,25), which attains accuracy of 84% The accuracy of the ensemble created from the most accurate classifier in each of the range categories is 88%. The single most accurate classifier for interest is Naive_Bayes(4,1), which attains accuracy of 86% while the ensemble approach reaches 89%. For example, in this work five-fold cross validation is employed to assess accuracy while (Ng and Lee, 1996) train and test using 100 randomly sampled sets of data. The interest data was first studied by (Bruce and Wiebe, 1994). They employ a representation of context that includes the part-of-speech of the two words surrounding interest, a morphological feature indicating whether or not interest is singular or plural, and the three most statistically significant cooccurring words in the sentence with interest, as determined by a test of independence. The interest data was included in a study by (Ng accuracies are associated with the classifiers included in the ensemble, which attained accuracy of 89% when evaluated with the test data. and Lee, 1996), who represent the context of an ambiguous word with the part-of-speech of three words to the left and right of interest, a morphological feature indicating if interest is singular or plural, an unordered set of frequently occurring keywords that surround interest, local collocations that include interest, and verb-object syntactic relationships. (Pedersen et al., 1997) and (Pedersen and Bruce, 1997) present studies that utilize the original Bruce and Wiebe feature set and include the interest data. The first compares a range of probabilistic model selection methodologies and finds that none outperform the Naive Bayesian classifier, which attains accuracy of 74%. The line data was first studied by (Leacock et al., 1993). They report no significant differences in accuracy among the three approaches; the Naive Bayesian classifier achieved 71% accuracy, the content vector 72%, and the neural network 76%. The line data was studied again by (Mooney, 1996), where seven different machine learning methodologies are compared. The line data was recently revisited by both (Towell and Voorhees, 1998) and (Leacock et al., 1998). and Voorhees, 1998) report accuracy of 87% while (Leacock et al., 1998) report accuracy of 84%. A similar finding has emerged in word sense disambiguation, where a number of comparative studies have all reported that no method achieves significantly greater accuracy than the Naive Bayesian classifier (e.g., (Leacock et al., 1993), (Mooney, 1996), (Ng and Lee, 1996), (Pedersen and Bruce, 1997)). For example, (Ng and Lee, 1996) report that local collocations alone achieve 80% accuracy disambiguating interest, while their full set of features result in 87%. Preliminary experiments for this paper used feature sets that included collocates, cooccurrences, partof speech and grammatical information for surrounding words. For example, an ensemble was created for interest using the nine classifiers in the range category (medium, medium). The accuracy of this ensemble was 84%, slightly less than the most accurate individual classifiers in that range which achieved accuracy of 86%.