 Potential sentence boundaries are identified by scanning the text for sequences of characters separated by whitespace (tokens) containing one of the symbols !, . We use information about the token containing the potential sentence boundary, as well as contextual information about the tokens immediately to the left and to the right. The system that focused on maximizing performance used the following hints, or contextual &quot;templates&quot;: The templates specify only the form of the information. The highly portable system uses only the identity of the Candidate and its neighboring words, and a list of abbreviations induced from the training data.2 Specifically, the &quot;templates&quot; used are: The information this model would use for Example 1 would be: PreviousWord=ANLP, FollowingWord=chairmon, Prefix=Corp, Suffix=NULL, PrefixFeature=InducedAbbreviation. The model used here for sentence-boundary detection is based on the maximum entropy model used for POS tagging in (Ratna.parkhi, 1996). For each potential sentence boundary token (., ?, and !, we estimate a. joint, probability distribution p of the token and its surrounding context, both of which are denoted by c, occurring as an actual sentence boundary. The distribution is given by: p(b, c) = Ir ,,,.f-(bc), where b e no, yes}, where the cri's are the unknown parameters of the model, and where each aj corresponds to a fi, or a feature. Thus the probability of seeing an actual sentence boundary in the context c is given by p(yes, c). For example, a useful feature might be: This feature will allow the model to discover that the period at the end of the word Mr. seldom occurs as a sentence boundary. The model also can be viewed under the Maximum Entropy framework, in which we choose a distribution p that maximizes the entropy H (p) where /:5(b, c) is the observed distribution of sentenceboundaries and contexts in the training data. All experiments use a simple decision rule to classify each potential sentence boundary: a potential sentence boundary is an actual sentence boundary if and only if p(yesic) > .5, where and where c is the context including the potential sentence boundary. We trained our system on 39441 sentences (898737 words) of Wall Street Journal text from sections 00 through 24 of the second release of the Penn Treebank3 (Marcus, Santorini, and Marcinkiewicz, 1993). Table 1 also shows the number of sentences in each corpus, the number of candidate punctuation marks, the accuracy over potential sentence boundaries, the number of false positives and the number of false negatives. Since 39441 training sentences is considerably more than might exist in a new domain or a language other than English, we experimented with the quantity of training data required to maintain performance. As can seen from the table, performance degrades a.s the quantity of training data decreases, but even with only 500 example sentences performance is beter than the baselines of 64.00/0 if a. sentence boundary is guessed at every potential site and 78.4%, if only token-final instances of sentence-ending punctuation are assumed to be boundaries.