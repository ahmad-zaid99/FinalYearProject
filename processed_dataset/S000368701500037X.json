{"id": "S000368701500037X", "article": "MAIN-TITLE Movement transformation on multi-touch devices: Intuition or instructional preparation?   HIGHLIGHTS          We evaluate the usability of a touch pad device.      An action-regulatory framework is introduced.      Users cannot generalize gestures between touch pads and touch screens.          KEYPHRASES   Intuitive interaction  Multi-touch  Input devices   Since multi-touch technology has been incorporated into most brands and models of cell phones, tablets, even public transportation ticket machines, it is an omnipresent issue in everyday life and becomes growingly important in the working environment. For example, the recent push by Microsoft towards touch-controlled or at least touch-optimized interfaces with the current and upcoming iterations of their operating system Windows makes the ability to use these devices important and worth investigating. Multi-touch technology has often been declared as more intuitive than more traditional input devices (Apple Inc., 2014a; Apple Inc., 2014b). Multi-touch gestures can be defined as movements with two or more fingers touching a touch screen or pad and creating more than one point of contact at a time (Han, 2006).  At this point it becomes crucial to separate touch screen devices and touch pads, as are common today in laptops and as stand-alone input devices for computers in general. While touch screens have no separation between the area of execution and the area of effect (with their unique drawbacks because of it), many touch pads involve the same gesture functionality one is accustomed to on touch screens, but separating the area of execution and the area of effect. Developers don't currently seem to separate the two different devices, it rather seems they want to treat the operational concepts as equal (Apple Inc., 2014b). An inherent shortcoming of touch pads, the user has to be cognitively aware of one differentiation to touch screens no matter the situation: that his/her actions will not take place at the same space they were performed. Movement transformation in order to perform an action is hindered by this obstacle, quite possibly to a point where multi-touch gestures, close to reality in their interaction with virtual instead of physical objects, might lose their appeal towards the user. Similar results have already been obtained by (Schmidt et\u00a0al., 2009) with focus on multi-touch input for large surfaces.  Both multi-touch and traditional input devices are subject to the same regulatory principles of cognitive and motor action on the side of the user, as described in the action regulation theory (Hacker, 1994). It specifies three levels of regulation, namely the intellectual, the perceptive-conceptual and the sensorimotor level. Given the different task scenarios of multi-touch and traditional input devices, one can assign stages of device usage to the levels of action regulation theory. A simple gesture on a multi-touch device for example can be broken down into the different levels as is shown in Table\u00a01 .  According to the TOTE-model (Miller et\u00a0al., 1973), the user will undergo a loop of indicative and executive processes until the desired outcome is achieved. If that qualitative (i.e. \u201cThis is not the page I want to see\u201d) or quantitative goal (i.e. \u201cI am still three pages away from the page I want to see\u201d) is not accomplished, the user will perform transformations of the implemented movement variables. (Sangals, 1997) defines the transformation of sensorimotor variables as a key part of action since it is most commonly influenced by specific types of sensorimotor motion, either using endogenous bodily movements or tools to help achieve task completion. The reference also specifies motion as a tool itself to achieve verbal, cognitive or even social goals.  The theoretical framework presented above provides researchers and usability engineers with a focus on the movement transformations required to be conducted on the side of the user. The movement transformation loops of the TOTE-model require constant comparisons between the status quo and the desired outcome, even more so for complex tasks (Palinko et\u00a0al., 2010). One can infer that in order to achieve complex goals, the user will be cognitively involved in the process of carrying out the task as long as it integrates more than merely sensorimotor levels of action. As far as we know, no competing framework has been proposed in the literature that involves different levels of action regulation or includes hierarchical cognitive functioning in research on intuitive interaction.  For gesture-controlled devices, (George, 2010) specifies a conversation metaphor in which the interface is \u201ca language medium in which the user and system have a conversation about an assumed, but not explicitly represented world\u201d. The authors state that in modern, \u201cnatural\u201d user interfaces, symbolic gestures resemble an indirect learning process assigned to triggering an action. In that way, we agree with the authors' reasoning that this puts multi-touch gestures a lot closer to learning command line interface actions or using graphical user interface alternatives than being presented a natural or even intuitive interaction. To use two fingers on a multi-touch surface and rotate them in order to activate the function of rotating an image file on screen for example requires a learning success on the side of the user, just as learning the placement of the rotating functionality in a graphic user interface would. References (Hutchins et\u00a0al., 1985) and (Jetter et\u00a0al., 2010) describe ways to implement such learning opportunities in a way that preserves cognitive resources of the user, especially through direct interface manipulation in terms of feedback. The goal is to ease the user into understanding a function on higher levels of the action regulation theory in order to use it correctly. To convey a sense of intuition while using a device, the conceptual difficulty of the functionality to be learned and the user's pre-existing experience of working with such a device have to be taken into account. Intuitive interaction with a product is defined as the unconscious application of knowledge on the side of the user (Mohs et\u00a0al., 2006). Task difficulty in intuitive interaction can therefore be understood as the amount of effort it takes to transfer knowledge about functionality from one action (i.e. rotating a picture on your desk in real life) to another (i.e. using a rotation gesture on a multi-touch device), without that process turning into conscious knowledge transfer. Whether the user can intuitively utilize an interface functionality can be considered part of the perceptive-conceptual level of action regulation theory.  The issue of movement transformation on devices separating the area of execution from the area of effect becomes especially relevant once the transition of prior knowledge is not supposed to take place from real world to virtual applications, but from one virtual world with certain properties to another \u2013 this is the case for gesture prior knowledge between touch screen and touch pad devices.   Sutter (2006) enhances the concept of perceptive-conceptual difficulty provided here to sensorimotor variables of movement transformation, indicating a difference in sensorimotor difficulty as well as in a perceptional one. The assessment is based on (Heuer, 1983) and describes how paths of movement in various input devices (i.e. trackballs and touchscreens) can lead to different difficulties in movement transformation. In the case of this study, paths of movement between direct and indirect multi-touch devices are identical (meaning that using a zoom gesture on a touch pad is implemented the same way it is on a touch screen, which corresponds to identical paths of movement), hence focus will be laid on perceptive-conceptual difficulty. If different paths of movement were used to trigger the same functionality between direct and indirect devices, one would also need to investigate whether or not one gesture is more effortlessly triggered on a sensorimotor level than the other. An example of a study that does not take paths of movement into account is provided in (Frisch et\u00a0al., 2009). Here, the authors let subjects choose their preferred gesture on a multi-touch tabletop device, being able to use their fingers (single or multi-touch), a stylus pen or any of the possible combinations they like. Granted, Frisch et\u00a0al. do not focus on differences on reported usability levels, so their approach is different to ours. It does provide a comparison of hypothetical frameworks though: the authors observed the frequency of gestures that were used. If they also wanted to measure if gestures used more often were also rated more intuitive or usable, their approach would not be able to explain whether differences in usage or usability assessment originated in difficulties on the perceptive-conceptual or sensorimotor level, due to different paths of movement. We consider that differentiation a benefit to our framework. As stated before, our focus lies on the perceptive-conceptual level of action regulation since we can neglect possible differences on the sensorimotor level.  It follows from the passages above that touch pads, their interaction with the user being indirect and involving the perceptive-conceptual level of action regulation more strongly, cannot be expected to be as intuitively usable as touch screens with their direct possibility of interaction. We take the view that the difference between area of execution and area of effect could be a key issue in learning if and how multi-touch functionality does not work as well on touch pads than it does on touch screens. Implementing Action Regulation Theory and the TOTE-model, enhanced perceptional difficulty is to be expected in a task while manipulating one area motorically and scanning another one for the effect visually. This article however does not draw a direct comparison between the two device categories, it merely investigates under which circumstances touch pad devices are used intuitively. It is designed as a preliminary study to study the effects of differing areas of execution and effect solely for touch pad devices. Three research questions have been investigated to examine this statement: First, participants were hypothesized to use more multi-touch gestures on a touch pad if they experienced a more \u201cinformative\u201d instructional condition (see Method section for further information). If confirmed this hypothesis would establish that touch pads, being interacted with indirectly, are not intuitively used by themselves. Our second hypothesis states that participants in more informative instructional conditions assign higher ratings of intuition and usability to the Magic Trackpad, measured via the INTUI and AttrakDiff questionnaires. The perception of intuitive interaction is separated into four subcomponents by (Ullrich and Diefenbach, 2010): effortlessness, gut feeling, verbalization and magical experience. The four components are measured using the INTUI questionnaire. According to (Hassenzahl et\u00a0al., 2008), product categories differ with regards to their desired qualities. Pragmatic products for example are judged mainly in terms of their usability and their ability to let the user achieve his/her goals using the product. Products that are perceived as hedonic on the other hand lay emphasis on social appraisal and brand-associated values. (Hassenzahl, 2001) points out that the assessment of pragmatism or hedonism is not mutually excludable \u2013 a product can be majorly pragmatic, majorly hedonic or assessed as both. This assessment affects the manifestation of the subcomponents, but not necessarily the overall perceived \u201cintuition\u201d of the product (Ullrich and Diefenbach, 2010). In addition to the INTUI questionnaire, the AttrakDiff 2 mini (Hassenzahl et\u00a0al., 2008) was handed out to assess the dimensions \u201cPragmatic Quality\u201d, \u201cHedonic Quality\u201d, its two subcomponents \u201cHedonic Quality \u2013 Identity\u201d and \u201cHedonic Quality \u2013 Stimulation\u201d and the dimension \u201cAttractiveness\u201d. If confirmed, this hypothesis would make the case for more instruction-oriented marketing approaches when it comes to touch pad devices, otherwise the user might not use the device correctly and (possibly inter-relatedly) not judge it as intuitive, usable or fun to work with. The third hypothesis focuses on prior experience with touch screens and posits that there is no significant correlation between touch screen experience and the use of multi-touch gestures or intuition ratings on a touch pad. This hypothesis should be able to support the claim that touch pads only \u201cwork\u201d given a certain level of instruction because transition of prior knowledge from touch screens to touch pads apparently does not happen.  For example, a hypothetical subject being accustomed to touch screens might still find himself/herself at a low instructional level, not know how to use the device's multi-touch capabilities and judge it as unintuitive. In this scenario, the low instructional level matches the assumption that users who know how to use touch screen devices do not need any special instruction to transfer their knowledge to touch pad devices. Our hypothetical subject would show that these two domains are not interchangable because he/she could not make use of the gesture functionality the device offers and does not judge it as intuitive.   METHOD   The experiment was conducted at a usability laboratory of the Work and Engineering Psychology Group at the Technische Universitaet Darmstadt, Germany. 54 psychology students (age M\u00a0=\u00a023, 75% female) participated for course credit. They were asked to complete a series of tasks involving the use of scrolling, swiping, zooming and rotation gestures on an Apple Magic Trackpad connected via Bluetooth to a 2010 Macbook. The Magic Trackpad is a standalone device of approximately 13\u00a0\u00d7\u00a011\u00a0cm in size, borrowing design and multi-touch functionality of touchpads found in common laptop PCs.  The participants were randomly assigned to one of three instructional conditions regarding the trackpad: the first one gave no functional instruction at all. The second condition involved a standardized, text-based instruction describing the available functions and proper gestures to trigger them. Finally, a video instruction showed participants how to perform the manipulation they wanted to achieve by showing hand movement on the trackpad and interface reaction simultaneously. Each gesture was shown two times in a row, separated from other gestures in the video by a blackscreen and a 2\u00a0s pause.  Three research questions were subsequently addressed by applying a search-and-find task scenario on a map of Dubai, 17,000\u00a0\u00d7\u00a08524\u00a0px in size. Participants first had to find that map in an array of unrelated pictures on an image hosting platform, meaning they had to sort through several folders to find the picture with no link back to the parent folder on the website itself. This meant they had to use the forward/backward functionality of the web browser.  The participants were then asked to search for the Dubai International Airport, from which they were supposed to follow lines of public transportation to end in an industrial area and search for another public transportation line that would take them back to the city. At each stop (airport, industrial area, city), control questions were implemented asking the participants for a certain piece of information to be found in the area. To acquire that information, participants had to zoom in and out of the map, rotate it 180\u00b0, and make heavy use of the scrolling functionality. Since the information would not have been readable if a participant had zoomed out so far that he/she had no further reason to scroll, we could ensure that each functionality had to be used. Whether participants used gestures for achieving their goals or relied on GUI interaction remained to be seen.  During the experiment, the participant's screen and hand were recorded to identify gesture usage. Additionally, participants completed the INTUI (Ullrich and Diefenbach, 2010) and AttrakDiff 2 mini (Hassenzahl et\u00a0al., 2008) and a questionnaire capturing prior knowledge of the participant, as described in the Results section.   RESULTS   The first hypothesis was tested using a Chi2 Test which showed that gesture use was significantly influenced by the instructional condition provided to the user. The gestures measured were Vertical Scrolling (\u03c72\u00a0=\u00a019.11, p\u00a0<\u00a0.01), Horizontal Scrolling (\u03c72\u00a0=\u00a019.73, p\u00a0<\u00a0.01), Zooming (\u03c72\u00a0=\u00a034.17, p\u00a0<\u00a0.01) and Rotation (\u03c72\u00a0=\u00a033.37, p\u00a0<\u00a0.01). A frequency analysis for the Swiping Gesture could not be conducted due to a lack of participants using the gesture (for the first two instructional conditions, no participant used it). Frequencies of gesture usage can be found in Table\u00a02 .  The results for this hypothesis show that multi-touch gestures are more frequently used after the participant is exposed to either text-based or video levels of instruction, showing the effect of the gesture more clearly than instruction levels with less information. Between 0% and 16% of subjects used gestures to complete the given tasks without any functional instruction, while an average of 80% of participants used gestures in the video instruction condition. Without any clarification of the implied functionalities, we derive that gestures are not intuitively used on indirect multi-touch devices.  While the first hypothesis clarified that users only made use of gesture functionality if instructed clearly on them, it remained to be seen if and how the perception of the device was influenced by the instructional level.  A one-way ANOVA was conducted, which revealed significant influence of the instructional conditions on the AttrakDiff subscales \u201cPragmatic Quality\u201d (F2,51\u00a0=\u00a03.27, p\u00a0=\u00a0.04), \u201cHedonic Quality \u2013 Identity\u201d (F2,51\u00a0=\u00a03.95, p\u00a0=\u00a0.02), \u201cHedonic Quality \u2013 Stimulation\u201d (F2,51\u00a0=\u00a04.00, p\u00a0=\u00a0.04), \u201cHedonic Quality\u201d (F2,51\u00a0=\u00a04.97, p\u00a0=\u00a0.01), \u201cAttractiveness\u201d (F2,51\u00a0=\u00a05.63, p\u00a0<\u00a0.01) and the INTUI subscale \u201cMagical Experience\u201d (F2,51\u00a0=\u00a05.03, p\u00a0=\u00a0.01). Planned Post-Hoc Tests showed significant differences between instructional conditions 1 and 3 for the AttrakDiff subscales \u201cHedonic Quality \u2013 Identity\u201d (p\u00a0=\u00a0.021), \u201cHedonic Quality\u201d (p\u00a0=\u00a0.01) and \u201cAttractiveness\u201d (p\u00a0<\u00a0.01) as well as the INTUI subscale \u201cMagical Experience\u201d (p\u00a0=\u00a0.016) after correcting for multiple comparisons. Descriptive measures for the dependent variables of hypothesis 2 can be found in Table\u00a03 .  Results indicate that the instructional condition does influence the perception of the Magic Trackpad, although the impact was not measurable on all available sub-scales. Post-Hoc tests revealed differences only between instructional conditions 1 and 3 but not 2 and 3, following along the lines of the frequency analysis for hypothesis 1. It appears as though the user experiences the product as intuitive the more he/she can grasp its functionality, even though this understanding did not exist intuitively.  It has been examined whether gesture functionality is used intuitively on indirect multi-touch devices and whether the use of said functionality influences the perceived intuition of the product. Our final hypothesis focuses on the question of whether prior experience with direct devices has an effect on gesture usage or the measured user experience subscales.  A short questionnaire was created asking for prior experience with the iPhone, iPod Touch or iPad on a 5-point Likert scale ranging from \u201cNever\u201d to \u201cOften\u201d (Rohrmann, 1978). No prior experience with said direct devices turned out to be significantly correlated to gesture usage or the subscales of the AttrakDiff and INTUI, using the Spearman Coefficient. The means and standard deviation for each direct multi-touch device are as follows: iPhone (M\u00a0=\u00a02.51, SD\u00a0=\u00a01.46), iPod Touch (M\u00a0=\u00a03.06, SD\u00a0=\u00a01.48), iPad (M\u00a0=\u00a01.57, SD\u00a0=\u00a01.00). Prior experience with the Magic Trackpad itself did not correlate significantly with gesture usage or usability assessments, which may admittedly be due to high number of inexperienced users with the device (M\u00a0=\u00a01.07, SD\u00a0=\u00a00.26). Hence, no matter how experienced users had been with Apple touch screen devices, their prior experience was not correlated to their performance in gesture usage or their intuition ratings.   DISCUSSION   After setting up a theoretical background for the interpretation of multi-touch gesture usage and obstacles on an action regulatory basis, the article at hand aimed to examine whether indirect multi-touch devices in general, and touch pads in specific, suffer from drawbacks that do not necessarily apply to direct multi-touch devices. Hypothesis 1 has shown that multi-touch gestures are not used without any further instruction, which contradicts the notion of indirect multi-touch devices being intuitive in their application. We hypothesize that the lack of intuitive interaction originates in an increased difficulty on the perceptive-conceptual level of action regulation, which derives from the physical distance between the area of execution and the area of effect of the user interaction and impedes movement transformation. An interesting topic for follow-up research would be to vary the physical distance between area of execution and area of effect and check for differences in gesture usage and user assessment. At this point, we do not assume any conclusion as to whether direct multi-touch devices suffer the aforementioned drawbacks, but highly recommend further research comparing those two groups of devices. It is important to note though that one should control for identical movement paths in such an experiment, to assure that difficulties on a perceptive-conceptual level are not confused with challenges on a sensorimotor one. For example, vertical scrolling on a touch pad and a trackball involve different sensorimotor tasks, while on a perceptive-conceptual level the tasks remain the same. A touch pad and a touch screen provide equal sensorimotor tasks, but the separation between area of execution and area of effect provides a different perceptive-conceptual task. While this article therefore does not provide conclusive proof with regards to the intuitive usability of the two groups of devices (touch pads and touch screens), it does examine major implications for future research.  We have shown that implementing the Action Regulation Theory has provided the opportunity of estimating effects on the perceptive-conceptual and sensorimotor level separately, something that seems not to have been done previously in usability research. Our experiment showed that gestures on touch pad devices are not used intuitively (i.e. without further instruction) because prior knowledge acquired on touch screen devices does not seem to transfer effortlessly between domains. As a consequence, the device in question is not rated as favorably by the user as possible. We could not however determine whether the increase in user assessment stems from knowing about the device's functionality or actually using the gestures, which we want to point out as another possible direction for future research. To avoid bad user assessments when it comes to usability and intuitive usage, one should manipulate the level of prior knowledge the customer can rely on for that specific device or device domain. We therefore point out that it should be a goal for product developers to make multi-touch gestures as frequently used as possible, as hypothesis 2 has shown that the assessment of device qualities is dependent on complete functionality utilization (or at least the knowledge about functionality). The fact that this did not influence every subcomponent of the AttrakDiff and INTUI questionnaires might be due to users judging the Magic Trackpad as a majorly hedonic product, which might determine relevant categories of quality assessment. It is noteworthy that the subscales which did turn out to be significantly influenced by the instructional condition appear to be contextually comparable to the branding Apple might apply to their product line. Further research may validate these results by aiming to determine the position of touch pads on a Pragmatic \u2013 Hedonic scale. The post-hoc comparisons calculated for hypothesis 2 seem to indicate that on the subscales significantly influenced by instructional condition, only the difference between no instruction at all and video instruction yielded significant mean differences. While near to every electronic product arrives with some kind of text instructions, it should be considered for future studies that these may not differ from providing no user instruction at all. We consider the results of the post-hoc comparisons with caution though, since differences in user assessment between text and video instruction turned out to be insignificant. The question of which instructional level influences user assessment by how much still remains (i.e. if the user needs to only \u201cknow\u201d about available gestures or actually has to use them to improve product assessment) and should be considered for future studies.  Hypothesis 3 validated our distinction between direct and indirect multi-touch devices by pointing out that prior experience with direct multi-touch devices is not correlated to either gesture usage or product assessment. Descriptive data however imply that future research might focus on acquiring a sample with more experienced users especially with regards to the use of direct multi-touch devices (tablets, for example). With that in mind, prior experience with gestures on direct devices is apparently not sufficient to overcome the aforementioned conceptual difficulties and allow intuitive interaction with indirect devices. At this point, product developers should lay emphasis on a more detailed knowledge transfer towards the user: by means of detailed yet subtle instructions (as given in the video instruction condition of this study), for example through advertising channels, they can increase the frequency of gesture use in their products and achieve a higher sense of intuitive interaction in the user. We would like to encourage researchers to replicate the article at hand with a new sample of subjects, given the economical growth of the tablet/smartphone/multi-touch device sector and the appearance of hybrid devices since this experiment was conducted in 2011. Future research therefore now has the opportunity to critically examine the validity of the presented framework in samples with differing base rates of prior knowledge.   REFERENCES", "highlights": "Multi-touch technology is a key part of computer interaction today, yet little is known about the distinction between direct and indirect input devices in terms of intuitive interaction. An experimental study aims to identify the difficulties of interaction with indirect multi-touch devices by applying the action regulation theory and the principle of movement transformation to common computer tasks involving gesture utilization. An analysis of the data acquired from 54 subjects working with an Apple Magic Trackpad implies that gestures on indirect multi-touch devices are not utilized intuitively without instructions that bypass conceptual difficulties of indirect gesture usage. It is shown that gesture use influences product assessment measured by User Experience questionnaires and that prior experience with direct multi-touch devices does not influence gesture usage or product assessment. We advise that product developers utilize video instructions to create a sense of intuitive interaction."}