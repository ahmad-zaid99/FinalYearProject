{"id": "S0168874X15001092", "article": "MAIN-TITLE Ultra-large scale fracture mechanics analysis using a parallel finite element method with submodel technique   HIGHLIGHTS          A software system for large scale fracture mechanics analysis is proposed.      A PC/WS and a supercomputer are used simultaneously to perform their optimum tasks.      A submodel scheme in which a crack is contained in the submodel is developed.      In crack propagation analysis, only remeshing is performed for the submodel only.      A 100 million node finite element fracture mechanics analysis is presented.          KEYPHRASES   Fracture mechanics analysis  Parallel finite element method  Large scale analysis  Crack   It is important to assure the safe operations and the structural integrities of social infrastructures such as power plants and of transportation systems such as railway structures, aircrafts, ships, etc. The authors consider that the demands on the safety assurances in modern social and engineering environment have kept growing. To assure the safe operations, inspections and maintenances on the structures are generally performed. Parts and structures that are found to have structural damages such as cracks, corrosions, etc. are replaced. There are rules and codes to evaluate the structural integrities. For example, JSME (Japan Society of Mechanical Engineers) have published a code \u201cThe rules on fitness-for-service for nuclear power plants\u201d [1].  Recently, some attempts to apply large scale finite element analyses to the problems of structural integrity/safety of power plant structures are seen in literature. Rupp et al. [2] performed a thermal analysis for the pressure water reactor (PWR) vessel structure. In their analysis, the PWR pressure vessel structure was modeled by the linear tetrahedral finite elements in detail. They focused the temperature distributions of the bolts, connecting the baffle and the vessel structure, which are much smaller than the pressure vessel structure. Quinay et al. [3] presented a multiscale fault-building structure interaction analysis. In their analysis, an interaction between the building structure of nuclear power plant and wave propagation through the crust was modeled by using a parallel finite element method. There is a large difference between the length scales of the building structure and of the crust. Methodologies to perform large scale finite element analysis on parallel computers have been developed by researchers. The early development of parallel finite element implementation can be seen in the article of Yagawa et al. [4]. They presented the domain decomposition method (DDM) on Transputer computers. DDM has widely been adopted to perform the parallel finite element analysis. For example, Yoshimura et al. [5] have developed a software system \u201cADVENTURE\u201d based on DDM. The methodology has been developed further to perform the large scale fluid-structure interaction analysis [6]. Recently, Yusa et al. [7,8] proposed a submodeling technique based on an iterative solution algorithm. The crack and its vicinity are modeled by the submodel which is embedded in the global model. The equilibrium at the interface between them is obtained iteratively. Linear elastic as well as large strain elastic\u2013plastic analyses were presented.  The authors think that the size of engineering finite element analyses in terms of the numbers of nodes and elements continue to grow due to the enhancements of computer hardware and software technologies. Thus, local structural damages such as cracks can be included in the analysis models of large and complex engineering structure and the structural integrity analysis can be performed without a large degree of simplification on the model, crack geometries, etc. The purpose of present research is to develop a software technology that is suited for performing the crack and crack propagation analysis of large and complex engineering structure such as nuclear pressure vessels.  To perform such analyses, we adopt the parallel finite element program ADVENTURE_Solid [9] to carry out large scale finite element computations on massively parallel supercomputers. However, it is not easy to generate a finite element mesh with cracks in general. The finite element model generation has been recognized as the bottleneck process in the fracture mechanics analysis. The difficulty may be more pronounced when the finite element model is large and complex.  Methodologies that can eliminate or reduce the needs for meshing have been proposed by the researchers. eXtended finite element method (X-FEM) was proposed (see Belytschko et al. [10], Mo\u00ebs et al. [11], Grabouil et al. [12] and Pathak et al. [13]). The applications of the generalized finite element method (G-FEM) to crack problems were presented by Duarte et al. [14] and Pereir et al. [15]. X-FEM and G-FEM are based on the partition of unity concept and they eliminate the needs to explicitly model the crack by the finite element mesh. The cracks are expressed by the so-called enrich/analytical functions and are inserted in the finite element mesh without the crack. S-version finite element method (S-FEM) that superposes two or more finite element models was adopted to perform the fracture mechanics analysis by Okada et al. [16] and Kamaya et al. [17]. S-FEM was originally proposed by Fish [18]. In S-FEM fracture mechanics analysis, a local finite element model contains the crack and it is superposed on the global finite element model without the crack. The local model containing the crack is generated independently of the global finite element model. Thus, the model generation processes are simplified compared with the case that the finite element model explicitly expresses the crack.  Another way to reduce the meshing effort is to use the automatic meshing technology with the tetrahedral finite elements. For crack problems, Okada et al. [19] and Kaneko et al. [20] have presented the automatic meshing techniques based on the Delaunay tessellation technique. Technostar Co. Ltd. released the finite element pre-processing software that had a crack mesh option [21]. The computations of the crack parameters by the virtual crack closure-integral method (VCCM), J-integral and interaction integral method were made possible by Okada et al. [22,23] and Daimon et al. [24], respectively, even if the model was consisting of the tetrahedral finite elements only. Crack/crack propagation analyses using the straight forward finite element method can be found in the literature. The mixed element approach or submodeling technique is commonly adopted to perform crack/crack propagation analyses (see, for example, Ural et al. [25], Wawrzynek et al. [26], Bremberg et al. [27,28] Sch\u00f6llmann et al. [29] and Buchholz et al. [30]). Such techniques may have been developed to place the hexahedral finite elements at the vicinity of crack front so that proven numerical techniques to compute the crack parameters can be adopted (see Shivakumar et al. [31], Okada et al. [32], Nikishkov et al. [33], Banks-Sills [34]).  Present authors have sought a way to perform the structural integrity analyses on large scale and complex structure with assuming the existence of cracks (for example, see Yodo et al. [35,36]). Yodo et al. used the massively parallel supercomputer \u201cEarth Simulator\u201d and demonstrated the performance of ADVENTURE_Solid. However, the supercomputers are, most of time, owned and operated by organizations such as university\u05f3s information technology center and are designed mainly for performing large scale computation. Thus, data preparations and pre/prost processings for the large scale finite element analyses such as generating the finite element mesh, specifying the boundary conditions, computing the stress intensity factors, etc. should be performed on a local PC/Workstation, while the large scale finite element analysis should be carried out by the supercomputer. Therefore, the mesh data, the result files, etc. need to be transferred between the remote supercomputer and the local PC/Workstation through the Internet. The sizes of data files may be very large because of those of the finite element analyses and their transfers between the computers may take a significant amount of time. In this paper, a computational strategy to perform large scale fracture mechanics analyses for real structure with structural damages due to the cracks with minimizing the amount of the data transfers is presented. The submodel approach and numerical examples are presented in the subsequent sections. Finally, discussions and conclusions are given.  In present development, the authors propose a submodel technique which minimizes execution time for the mesh generation and the data transfers between the remote supercomputer and the local PC/Workstation.  The fracture mechanics analysis system is summarized in Fig. 1. There are global and local finite element models. The submodel is embedded in the global model as shown in Fig. 2. The submodel contains a crack. The local finite element model is called submodel in this paper. In the crack propagation analysis, only the submodel is updated. The size of submodel is relatively small so that data transfer from the local PC/Workstation to the supercomputer at the remote site can be performed quickly and that the mesh generation with cracks can be performed within a short period of time. Therefore, we let the size of submodel be no more than three million node level. To automate the model generation processes, we adopt the quadratic tetrahedral finite element for both the global mesh and submodel.  The analysis procedures as shown in Fig. 1 are briefly described as follows. The global mesh is generated at the local site and is transferred to the remote supercomputer. This is a one-time process. At the same time, the submodel with an initial crack is generated at the local site and is transferred to the remote supercomputer. These models are merged on the remote supercomputer. Then, a monolithic finite element mesh is obtained. After the monolithic analysis model is built, a series of small pre-processings are performed so that the boundary conditions are specified to the combined finite element model. Then, the finite element analysis is performed by using the parallel finite element software ADVENTURE_Solid [9].  After the finite element analysis completed, the stress intensity factors are computed. VCCM computations are performed as a part of post-processings on the local PC/Workstation. As described later in this paper, the VCCM computations only need the displacements at the immediate vicinity of the crack front. Once the stress intensity factors are evaluated, the rate and the direction of crack propagation are predicted based on an appropriate crack propagation criterion, such as Erdogan et al. [37] and Paris et al. [38]. The readers are referred to the review article by Qian et al. [39] for the crack propagation criteria. Once the rate and the direction of crack propagation are determined, the geometry of the crack for next crack propagation step is defined. Then, for the defined crack geometry, the finite element mesh for the submodel is generated. Then, the submodel is transferred to the remote supercomputer. The processes as shown in Fig. 1 are repeated for desired number of times or until the crack grows to the specified size. It is noted that the crack is assumed to be half-elliptical in its shape in the numerical examples of this paper. The stress intensity factors at the deepest and the surface points of the half-elliptical crack are used to define the rate of crack propagation to update the crack geometry. The major advantage of present global-submodel approach can be demonstrated even with the assumption in the crack geometry.  In present approach, the crack is inserted in the submodel whose geometry is relatively simple. A typical submodel geometry is a rectangular parallelepiped. As seen in Tanaka et al. [40] on a shell-solid mixed modeling technique, the solid mesh model containing a crack has a rectangular parallelepiped. Kawai et al. [41] presented an automatic meshing scheme to build a finite element model with a crack. Crack propagation analyses have been performed by Tanaka et al. [42] on welded structure. Tanaka et al. [42] used a commercial finite element mesh generation software (TSV-Pre [21]). Okada et al. [19] and Kaneko et al. [20] performed crack propagation analyses using their point base mesh generation schemes. From the literature, we can consider that the automatic crack mesh generation techniques are the proven technologies as long as the model geometry is relatively simple. Therefore, we can make use of such proven technologies in present submodel approach.  The finite element mesh for submodel is generated by using the commercial finite element mesh generation software (TSV-Pre [21]). The finite element discretizations at the mating faces need to be compatible and the surface triangles of both the models must match perfectly at the mating faces. The mating surfaces are shown in Fig. 2. Since the global model stays the same throughout the crack propagation analysis, it is created only once. The information about the surface triangles on the interface of the global finite element model is extracted from the global model and is stored on the hard-disk during the crack propagation analysis. The surface triangle information is used to generate the finite element meshes for the submodel. Therefore, the global and the submodels have compatible mesh arrangements at the mating faces between them. After connecting the models, a monolithic finite element mesh is obtained and an ordinary finite element program without any special treatments for the mating surfaces can be employed. We use the commercial finite element mesh generation software TSV-Pre [21] for the generations of both the global and sub-finite element models.  In present investigation, we use the ADVENTURE system [9] for finite element analysis on the Fujitsu PRIMEHPC FX10 Supercomputer system at the Information Technology Center, the University of Tokyo. The ADVENTURE system is a module-based finite element analysis software system for parallel computers. In order to solve large-scale problems, the ADVENTURE system is designed based on the Hierarchical Domain Decomposition Method (HDDM) proposed by Yagawa et al. [43] and Miyamura et al. [44]. The HDDM is one of iterative solver algorithms. A whole mesh is decomposed into parts whose total number corresponds to the number of cores and each part is divided into small domains that are called \u201csubdomains\u201d. Fig. 3 shows the examples of the parts and subdomains for a small mechanical part (flange coupler). To obtain the equilibrium of the finite element model, the finite element analysis for each subdomain is performed under temporary displacement boundary conditions which are assigned to all the nodes at the boundary of subdomain. The displacements at the boundary are iteratively determined so that the forces between the adjacent subdomains are under the equilibrium. For the full details of the HDDM, the readers are referred to Yagawa et al. [43] and Miyamura et al. [44]. The problem domain needs to appropriately be decomposed to the subdomains.  The ADVENTURE system was executed on the Fujitsu PRIMEHPC FX10 supercomputer system in present investigation. To maximize the performance of parallel computation of ADVENTURE_Solid, the parameters in domain decomposition such as number of processors and number of subdomains must be optimized. They depend on model size, computer architecture, size of main memory, etc. For example, we had 24 parts and 400 subdomains in each part in the case of the 25 million node model of the quarter section of the pressure vessel that is presented in subsequent section.  To compute the stress intensity factors, VCCM (virtual crack closure-integral method) for the tetrahedral finite element [22] is adopted. VCCM computation is briefly explained as follows.  First, the energy release rates with respect to the mode I, II and III crack deformations are computed by the nodal crack opening displacements and reaction forces whose Cartesian components are written in the local coordinate system defined at the crack front. The local Cartesian coordinate system is shown in Fig. 4. In the local O \u2212    x \u00af    1   ,    x \u00af    2   ,    x \u00af    3   coordinate system,    x \u00af    1   axis is in the plane of crack and is perpendicular to the crack face,    x \u00af    2   is in the direction perpendicular to the crack plane and    x \u00af    3   is along the tangential direction to the crack front. The base vectors in the O \u2212    x \u00af    1   ,    x \u00af    2   ,    x \u00af    3   coordinate system are denoted to be    e \u00af    1   ,    e \u00af    2   and    e \u00af    3   .  The energy release rates with respect to the mode I, II and III crack deformations due to the closing of one element face, as shown in Fig. 5 are expressed by the multiplications of the respective nodal opening displacements and the reaction forces arising from elements above the crack plane as also depicted in Fig. 5. The energy release rate arising from one element face can be expressed, as follows.  As described by Okada et al. [22], VCCM for the quadratic tetrahedral element originally assume that there are mating element surfaces across the crack front. They have exactly the same orientation and shape, as shown in Fig. 5(a and b). There are two kinds of element face orientations as depicted in Fig. 5(a and b). It is noted that the requirement of exactly the same orientation and shape does not have to be satisfied in a strict sense as described in Okada et al. [22]. However, the width ( \u0394 ) of the finite element face must be the same across the crack face. When the element faces are arranged as shown in Fig. 5(a), the energy release rates can be expressed, by  (1)       G   I    |     S   1     =     K   I   2     E \u2032   =  1  3   S   1      \u2211  I = 1  5      v \u00af    2   I    (    S   1   \u2032    )     P \u00af    2   I    (    S   1    )        G   II    |     S   1     =     K   I I   2     E \u2032   =  1  3   S   1      \u2211  I = 1  5      v \u00af    1   I    (    S   1   \u2032    )     P \u00af    1   I    (    S   1    )        G   III    |     S   1     =     K   I I I   2     2 \u03bc   =  1  3   S   1      \u2211  I = 1  5      v \u00af    3   I    (    S   1   \u2032    )     P \u00af    3   I    (    S   1    )     where   S   1   indicates that the associated quantities are associated with those presented in Fig. 5(a). The vector quantities are written in the local O \u2212    x \u00af    1   ,    x \u00af    2   ,    x \u00af    3   coordinate system.    v \u00af    i   I   and    P \u00af    i   I   are the nodal opening displacements and the nodal forces arising from the cohesive stresses on   S   1   . We assume the plane strain condition at the crack front and constants in Eq. (1) are E \u2032 =  E /  (  1 \u2212   \u03bd  2   )   and \u03bc =  E /  2  (  1 + \u03bd  )    where E and \u03bd are the Young\u05f3s modulus and the Poisson\u05f3s ratio. For the case of Fig. 5(b), we can write  (2)       G   I    |     S   2     =     K   I   2     E \u2032   =  1    S   2      \u2211  I = 1  3      v \u00af    2   I      P \u00af    2   I    (    S   2    )        G   II    |     S   2     =     K   I   2     E \u2032   =  1    S   2      \u2211  I = 1  3      v \u00af    1   I      P \u00af    1   I    (    S   2    )        G   III    |     S   2     =     K   I   2     2 \u03bc   =  1    S   2      \u2211  I = 1  3      v \u00af    3   I      P \u00af    3   I    (    S   2    )        The definitions of   S   1   ,    v \u00af    i   I   and    P \u00af    i   I   follow those in Eq. (1). For further detail, the readers are referred to Okada et al. [22].  The stresses and the strains can be computed from the nodal displacements using the finite element computational procedures. Then, the nodal reaction forces are also computed by the finite element procedures. In order for us to perform VCCM computations, we only need nodal displacement data at nodes of elements which are in the immediate vicinity of the crack front. An example is shown in Fig. 6. The nodal displacements of those nodes are transferred from the remote supercomputer to the local PC/Workstation for the postprocessings. The list of those nodes are prepared when the finite element mesh for the submodel is generated and is transferred to the remote supercomputer as also shown in Fig. 1.  Once the stress intensity factors are computed, the direction and the rate of crack propagation can be predicted. They can be chosen from proposed formulae. For example, the maximum tangential stress criterion of Erdogan et al. [37] is a popular candidate, for the prediction of direction of crack propagation. For the rate of crack propagation, Paris law [38] for fatigue crack propagation may be the most popular one. For stress corrosion cracking (SCC), we can adopt the similar formula. The example problem of present paper deals with the SCC crack propagation problem. Constants in the crack propagation laws can be chosen from the JSME code [1]. More details of the SCC crack propagation law are discussed in the section of numerical example.  The crack geometry is assumed to be half-elliptic in its shape. To describe the crack growth, the rates of SCC crack propagation at the deepest and the surface points of the half-elliptical flaw are used. It is a standard way according to the JSME code [1] for nuclear power plants.  In this section, some numerical examples demonstrating the capability of present software system are presented. As a simple validation problem, a problem of surface crack in a tensile panel is considered first. Present solutions are compared with Newman and Raju [45]. Then, as a demonstration problem for the detailed/large scale crack analysis, the problem of nuclear pressure vessel section and nozzle problem is presented. It is noted that, in the numerical examples, in order to increase the numbers of nodes and elements we let element size be very small. That is to demonstrate the capability of our software system in handling the large scale finite element crack analyses. It is noted that much coarser mesh may be adopted to evaluate the stress intensity factors accurately enough (see, for example, Okada et al. [22]).  As for the first example problem, the problem of tensile plate with a semi-circular surface flow is presented. Although such a problem does not need to be solved by proposed methodology for large-scale finite element fracture mechanics analysis, the accuracy of present methodology is verified by comparing with the known solution. The plate with the surface flaw is depicted in Fig. 7. The plate is subject to a remote tension whose value is 250MPa. Young\u05f3s modulus and Poisson\u05f3s ratio are set to be 234GPa and 0.37, respectively. The sizes of the plate and the surface crack are as depicted in Fig. 7. The finite element model is shown in Fig. 8. The finite element model is consisting of the submodel and the global model. The submodel is indicated by the red box in Fig. 8(a). The magnified view of crack is shown in Fig. 8(b). Fig. 8(c) is the mesh division of the crack face. It is seen from Fig. 8(c) that very fine finite elements are placed along the crack front. The overall sizes of the plate is 100   (  mm  )  \u00d7 100   (  mm  )  \u00d7 5   (  mm  )  , as also shown in Fig. 7. The size of submodel containing the crack is 20   (  mm  )  \u00d7 20   (  mm  )  \u00d7 5   (  mm  )  region. There are a total of 1,697,356 nodes of which 615,703 nodes belong to the submodel. There are a total of 1,206,717 elements. Both the surface width and the depth of the crack are 2.0mm. The smallest element size at the crack front is 0.0157mm which is about 1/127 of the radius of the semi-circular crack.  The distribution of evaluated stress intensity factor is potted in Fig. 9. The result is compared with that of Newman and Raju [45] as the reference solution. In Fig. 9, the variations of the stress intensity factors are depicted with respect to the crack angle \u03d5 . They compare favorably except for at the vicinities of the free surfaces. It is well known that the order of singularity in the stress at the surface point is not the square-root type (see Ba\u017eant et al. [46]). Therefore, the stress intensity factor has a steep change at the vicinity of the free surface. Present approach with very fine mesh discretization capture the change in the order of singularity. The result of the surface crack problem verifies that present analytical procedures evaluate the stress intensity factor accurately.  Analysis models emulating the water inlet nozzle part of BWR (boiled water reactor) are presented in this section. The overall dimensions of the model was taken from the demonstration data of ADEVENTURE TetMesh [9]. The nodal coordinate data of the demonstration data, we first established a 3D CAD model, as shown in Fig. 10. Fig. 10(a and b) shows the details of the water inlet nozzle. Fig. 10(c) shows the image of the 3D CAD drawing. As shown in Fig. 10(a and b), the water inlet nozzle has complex configurations. We assume the material constants to be those of stainless steel. Young\u05f3s modulus and Poisson\u05f3s ratios are set to be 175GPa and 0.3, respectively. An applied pressure p is assumed at the inner wall of the structure. According to the pressure inside the vessel, the section is subjected to the tensile applied stress   \u03c3   t   in the length direction of the pressure vessel. The applied pressure and stress are shown in Fig. 10(d). The pressure p is assumed to be the maximum internal pressure of BWR under its operation. It is set to be 8.62MPa according to the report of JNES (Japan Nuclear Energy Safety Agency) [47]. The tensile applied stress   \u03c3   t   can be given by,  (3)    \u03c3   t   =   p r   2 t     where r and t are the radius of and wall thickness of the pressure vessel.  The location of the crack is assumed according to the press releases of Tohoku Electric Power Company [48,49]. The crack is assumed to emanate from the inner wall of the water inlet nozzle part as shown in Fig. 10(b). Crack propagation analyses assuming the stress corrosion cracking were performed. The SCC crack propagation law can be found in the JSME code [1]. The SCC crack propagation law for DNiCrFE-3 and DNiCrFe-1J Nickel base alloy under a BWR environment is adopted in this analysis. The crack propagation law is written to be  (4)    d a   d t     (  m / s  )  =  {     0    (    K   I   \u2264 0  MPa    m   1 / 2    )       2 \u00d7   10   \u2212 12       (  0  MPa    m   1 / 2   <   K   I   \u2264 13.3  MPa    m   1 / 2    )       3 \u00d7   10   \u2212 18     K   eq   5.186       (  13.3  MPa    m   1 / 2   <   K   I   \u2264 50.3  MPa    m   1 / 2    )       2 \u00d7   10   \u2212 9       (  50.3  MPa    m   1 / 2   <   K   I    )         where   K   I   is the mode I stress intensity factor.  We conducted two analyses. They are quarter and full section analyses. We performed these two analyses to demonstrate two levels of large scale fracture mechanics analyses. The finite element mesh for the quarter analysis model is shown in Fig. 11. There are a total of 25,223,247 nodes of which 3,578,544 nodes belong to the submodel. There are a total of 17,854,979 elements. In Fig. 11(a), a view of the whole quarter section model is shown. Fig. 11(b\u2013d) shows the magnified view of the nozzle part. Fig. 11(b) shows a view of the nozzle part. Fig. 11(c and d) shows the magnified views of the nozzle part from inside and outside of the pressure vessel. Fig. 11(e and f) shows the submodel and the crack face. The initial depth and half-length of the crack are set to be 9.7mm and 5.0mm. The location of the crack is assumed to be as shown in Fig. 10(b). The location and size of the crack are set according to the press release of Tohoku Electric Power Co. Ltd. [49] which were released by Tohoku Electric Power Co. Ltd., Japan.  In this analysis, although we evaluate the stress intensity factors all along the crack front, the rates of crack propagations are computed at the deepest and surface points of the crack. The crack is assumed to be half-elliptic in its shape, as often assumed in practical structural integrity evaluations for the nuclear structures (see, for example, JSME code [1]). The update scheme of the crack shape is schematically presented in Fig. 12. First, the crack propagation rates are computed from the values of the stress intensity factors at the surface and deepest positions of the crack by using eq. (4). They are designated as    d a / d t  |   surface   and    d a / d t  |   deepest   . The largest of    d a / d t  |   surface   and    d a / d t  |   deepest   is set to be    d a / d t  |   max   . The maximum amount   \u0394   max   of the crack propagation is set as one of the analysis parameter. In present example problem,   \u0394   max   is set to be 0.5mm. Duration of time period that is represented by the crack propagation step \u0394   t   step   is computed by \u0394   t   step   =     \u0394   max    /  (     d a / d t  |   max    )   . The lengths   \u0394   surface   and   \u0394   deepest   of crack propagation during one crack propagation step are computed by    d a / d t  |   surface   \u00d7 \u0394   t   step   and    d a / d t  |   deepest   \u00d7 \u0394   t   step   at the surface and the deepest location of the crack front, respectively. Then the surface length and the depth of the crack are updated, as depicted in Fig. 12.  The distribution of the equivalent stress for the initial state is depicted in Fig. 13. Fig. 13(a) shows a view of the stress distribution from the inside of the pressure vessel. Fig. 13(b) shows the magnified view of the nozzle part. Stress concentration due to the inlet nozzle is seen. Fig. 13(c) presents the nozzle seen from the outside of the pressure vessel. We do not find any stress concentrations. Fig. 13(d) shows the submodel and Fig. 13(e) shows the magnified view of the crack. Stress concentrations in the vicinity of the crack front are confirmed. The distributions of the stress intensity factors along the crack front at the initial state are plotted in Fig. 14(a). It is seen that the magnitude of the mode I stress intensity factor dominates those of the others. The value of mode I stress intensity factor is below 13.3MPam1/2 and, therefore, the rate of crack propagation is the same all along the crack front. Thus, the rates of crack propagations at the deepest and the surface-pints of the crack are the same and are 2 \u00d7   10   \u2212 12     (  m / s  )  . The crack shape is updated accordingly.  The SCC crack growth simulation was performed for the duration of about 40 years. The length of crack propagation for the duration of 40 years is 2 \u00d7   10   \u2212 12     (  m / s  )  \u00d7 365  (  days  )  \u00d7 24   ( h )  \u00d7 60   (  min  )  \u00d7 60   ( s )  \u00d7 39.64  (  years  )  = 2.50  mm which is small amount compared with the initial crack size. It took 5 crack propagation steps. The distributions of the stress intensity factors after 39.64 years of crack propagation are plotted in Fig. 14(b). The value of the mode I stress intensity factor that are plotted in Fig. 14(b) are slightly larger than those in Fig. 14(a). It is however noted that the value is well below 13.3MPam1/2 and, therefore, the rate of crack propagation is 2 \u00d7   10   \u2212 12     (  m / s  )  at both the deepest and surface points of the crack front.  The total number of nodes of the submodel changed during the crack growth. They are summarized in Table 1. They actually decreased after the crack growth. We can say that the model size of the submodel does not increase drastically even after the crack propagation, in general.  In order to demonstrate the capability of present software system further, we performed an analysis on a 100 million node problem. The full section of the BWR pressure vessel is considered as our example problem. The full section has four water inlet nozzles. The crack is assumed to be present at one of the nozzles. The crack configuration is the same as the case of the quarter section model. There are a total of 72,261,695 elements and 101,378,939 nodes of which 2,247,525 nodes belong to the submodel. The finite element model is shown in Fig. 15. Fig. 15(a) shows a whole view of the full section model. Fig. 15(b) shows its magnified view of the nozzle part with the submodel. Fig. 15(c and d) shows the submodel and the crack face, respectively. The same applied internal pressure and tensile stress in the longitudinal direction of the vessel as the case of the quarter section analysis are applied. The distribution of equivalent stress is depicted for the submodel at the initial state is shown in Fig. 16(a and b). The distribution looks the same as the case of the quarter section analysis. The analysis was successfully performed and the solutions such as the stress intensity factors were evaluated. The distributions of the stress intensity factors are shown in Fig. 17. They look the same as those shown in Fig. 14(a) for the quarter model.   DISCUSSIONS   As defined in the section of introduction, the purpose of present investigation is to develop a software framework to perform ultra-large scale finite element fracture mechanics analysis. We propose a way to wisely utilize the supercomputer at the remote site and the PC/Workstation at the local site. The supercomputers generally specialize in the large-scale parallel computations. They are not suited for performing small scale computations that are necessary in the finite element pre/postprocessings and the fracture mechanics parameter evaluations. As stated earlier in this paper, a practical solution to this issue is to perform the small scale computations on a PC/Workstation at the local site. In this case, data transfer between the remote supercomputer and the local PC/WC may become the bottleneck process. Another bottleneck process may be the mesh generation. In present analysis, the crack needs to be inserted in the large-scale model. It was found that it would take unacceptably long computer time. When we generated the global model of 24 million node finite element model using TSV-Pre on a latest PC with Core-i7 at 3.3GHz of clock speed and 32GB memory, it took about 8h. When we generated a 70 million node model, it took about 3 days. They are shown in Table 2. It is noted that the execution time to perform the mesh generation depends on the number of nodes. It is expected that the execution times to perform the mesh generations for the monolithic meshes are expected to be longer than those for the global models. Due to our system limitation, the execution times are not very precise as they were recorded by the operator when the operator was present. However, we can notice that the execution time is unacceptably long if the monolithic mesh were generated in each crack propagation step. It is noted that the mesh generation did not require the out-of-core memory. Data transfer by SFTP protocol from the PC at the local site to the remote supercomputer took 0.5\u20132h. Although data transfer highly depends on the environment, it takes a significant amount of time also.  The finite element analysis using ADVENTURE Solid on the remote supercomputer typically took about only 10min for the 100 million node problem. VCCM computations to evaluate the stress intensity factors along the crack front typically took 2min. It is the total execution time to extract crack front mesh data as shown in Fig. 6 on the local PC/Workstation, to extract necessary displacement data on the remote computer and to perform the VCCM computations. The data transfer from the remote to the local computer takes a negligibly small amount of time as the displacement data file is typically smaller than 1MB.  Therefore, it is clear that the mesh generation and mesh data transfer from the local PC/Workstation to the remote supercomputer are the bottleneck processes. Present approach can eliminate both the bottleneck processes and can shorten the total execution time to perform the crack propagation analysis significantly. Rough breakdowns of execution times of pre/postprocessings are summarized for the 68 million node thin plate and 24, and 70 million node nozzle finite element models are shown in Table 2. Their numbers of nodes in the submodels are 1,155,527, 3,578,544 and 2,054,173 for the 6.8, 24 and 70 million node models, respectively. Although the size of the global model may enlarges as the complexities of geometry and configuration of the global structure increase, the size of submodel can stay almost the same. It is considered that the execution times for the submodel mesh generation and for the insertion of the submodel to the global model largely depend on the numbers of nodes in submodel and at the interface, respectively. Therefore, we can expect that the execution times do not increase significantly, even when the complexities of the analysis model increases. That is because they mainly depend on the numbers of nodes and elements of the submodel. Process times to connect the global model and submodel did not increase much when the overall model size increased from 24 million to 70 million nodes. The time to carry out the VCCM computations was generally much shorter than the others. Therefore, we can expect that, if the size of the submodel stayed the same, the increase of execution time of the crack propagation analysis almost depends on that of parallel finite element computation on the remote supercomputer. Additional execution time due to the presence of the crack can be minimized by adopting present submodel approach.  It is noted that all the execution time measurement were performed on a local PC for the convenience. On the local PC, we had a memory problem when we merged the submodel to the global model for the 100 million node problem. That is why the results of 70 million node problem are presented instead of those of the 100 million node problem.   CONCLUSIONS   A software system is presented along with some numerical examples in this paper. Proposed methodology enables us to perform ultra large scale finite element analyses on a supercomputer that is located at a remote site. Data preparation and postprocessings, such as mesh generations, the evaluations of crack parameters, etc. are performed on a local PC/Workstation and the ultra large scale finite element analyses are carried out on a remote supercomputer. Finite element mesh and result data need to be transferred between computers at the local and the remote sites through the network. As discussed, the mesh generation and the data transfers are the bottleneck processes in the crack propagation analysis.  Present research proposes a software system that can minimize sizes of data file to be transferred between the local and the remote sites and can obviate the generation of the finite element mesh for the whole structure by adopting the submodel approach. A 100 million node problem is presented and the capabilities of present software system are successfully demonstrated in this paper. We expect that the problem size will grow further as the speed and memory capacity of supercomputers keep enhancing. Present submodel approach may be applied to one billion node finite element problem in near future.   ACKNOWLEDGMENTS   This work is supported in part by Ministry of Education, Culture, Sports, Science and Technology (MEXT) Strategic Programs for Innovative Research (SPIRE), Industrial Innovation.   REFERENCES", "highlights": "A software system for performing large-scale finite element fracture mechanics analyses is presented in this paper. The method is based on a submodel technique in which the large-scale finite element mesh is divided into two parts. One is the submodel which only represents the crack and its vicinity. The other is the global model for the whole structure. They are generated separately and connected. It is assumed that we use a supercomputer at a remote site and a PC/Workstation at a local site. The local PC/Workstation is used to perform pre/post-processings. The remote supercomputer is used to carry out the large-scale finite element analyses. In a crack propagation analysis, a number of remeshing steps are involved. We have developed a software system that the remeshings are performed only for the submodel. The global model stays the same during the analysis. Also, we minimize the amount of data which are transferred between the computers at the remote and the local site. In this paper, we present 100 million node finite element fracture mechanics analysis on a section model of nuclear pressure vessel, demonstrating the capabilities of present software system."}