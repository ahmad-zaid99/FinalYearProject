{"id": "S001048251500414X", "article": "MAIN-TITLE Segmentation and optical flow estimation in cardiac CT sequences based on a spatiotemporal PDM with a correction scheme and the Hermite transform   HIGHLIGHTS          A new framework for segmentation and optical flow estimation applied to cardiac CT sequences is proposed.      The segmentation is based on two processes: (1) A spatiotemporal point distribution model, and (2) A correction scheme that performs the segmentation of small details.      The optical flow estimation uses a bio-inspired model based on the Hermite transform to code local image features.      Both algorithms are combined to provide a powerful framework to assist the evaluation of heart mechanical problems.          KEYPHRASES   Segmentation  Spatiotemporal point distribution model  Local image features  Optical flow  Hermite transform  Cardiac CT sequences   Cardiac CT is currently one of the main types of radiological images used for heart analysis. Image slices showing the structural composition of the heart can be obtained with CT scanners [1]. The continued improvement of multidetector CT scanners has increased the potential of cardiac CT as clinical tool for heart imaging [2]. Since heart failure is one of the main health problems in developed and developing countries [3], tasks focused on cardiac analysis are of main concern for physicians. Several benefits of CT systems have been recognized to evaluate heart functions. Quantification of the ejection fraction, left and right ventricular functions, and wall motion evaluation are examples of typical uses of cardiac CT data [4].  The natural movement of the heart implies that its mechanical behavior must be evaluated as well. The spatiotemporal data obtained from cardiac CT studies can be used in computer-aided systems to evaluate the cardiac function, which has become essential over the past few years allowing faster assessments in the diagnosis process [5]. Since the left ventricle is vital for the proper functioning of the heart, it has become of major interest when analyzing cardiac images. In cardiac CT heart is commonly scanned at increments of 10% of the cardiac cycle providing a 4D dataset.  Shape extraction for volume measurement and motion estimation are the most typical tasks for heart evaluation where computer-based algorithms are extensively used [6\u20139]. In this sense, development of new and most efficient algorithms, methods and mathematical models to analyze cardiac structures in CT data are activities of great interest for researchers.  In a general sense, basic processes like segmentation and optical flow estimation are primary steps before applying higher processes like image interpretation. Cardiac CT sequences constitute great challenges for segmentation and motion estimation algorithms. A typical problem when working with medical images is that they may vary considerably from one patient to another, from an image processing point of view. These variations are perceived as changes of contrast, size and geometrical shape. Cardiac CT images do not scape from these kinds of problems. Even though development of segmentation and optical flow estimation algorithms imposes issues that researches have tried to solve for several decades, the problem remains open. Recent thorough reviews of segmentation techniques applied to cardiac images [10,11] conclude that shape extraction in heart images remains a very challenging task.  Active Shape Models (ASM) [12] have gained enormous popularity during the last twenty years and have been extensively used for modeling 2D and 3D data in cardiac imaging [13\u201315]. We opted for this approach due to its ability to represent specific shapes of an image. Problems regarding the contrast and shape variability can be easily overcome with ASM-based algorithms. Related literature deals with active shape models as methods to analyze cardiac images [14,16]. ASM have also been combined with other methods with the aim of segmenting heart images [6]. Modifications of the original approach become necessary for improving the segmentation performance in some cases when the training samples are scarce [14]. However, issues of ASM are evident when the number of training samples is small. It is therefore necessary to design new strategies to overcome these problems.  The dynamic nature of the heart has motivated researchers to design image tracking algorithms to process cardiac images [17,9,18]. Tracking heart structures like the left ventricle or the myocardial wall can be performed using optical flow estimation methods which also allow computing the displacements of the cardiac structures in a sequence of images. For this purpose we used a differential approach defined in the Hermite transform (HT) space. The HT is a bio-inspired human vision model that decomposes an image with a set of orthogonal functions defined by the Hermite polynomials. Image patterns and structures relevant to human vision perception such as oriented edges and textures can be efficiently represented with the HT. The proposed optical flow estimation approach using the HT allows defining local image constraints and a multiresolution strategy within differential scheme and are relevant in a perceptual sense as described in [8].  Our main goal is to build a tool that may help physicians evaluate heart mechanical functions. In order to achieve our objective, we implemented a framework with two main processes: (1) A segmentation stage based on a statistical shape model and a new correction scheme, and (2) An optical flow estimation approach based on the Hermite transform. For the first process we have designed a novel correction method that substantially improves the segmentation performance. The goal of the new correction method is to refine the segmentation previously achieved with the statistical shape model. It consists of a deformable scheme that combines three image parameters: histogram, gradient and a binary pattern. These parameters are locally computed for each point of the contour of the segmentation. This work is entirely focused on analyzing sequences of cardiac CT images (2D + time). The algorithms are specifically applied to the left ventricle because it is responsible for some of the most vital functions of the heart. Cardiac CT studies are analyzed using the original axial view. Nevertheless, the method can be extended without major problems to other views. Although short and long axis are the most accepted views used for cardiac analysis, the original axial view is also very important for this task [19]. Combined results of both algorithms are presented. Vectors indicating the motion of the left ventricle are jointly used with contours of the segmentation. Results are evaluated with several image sequences using quantitative and qualitative analysis.  The rest of the paper is organized as follows. Material used in this work is described in Section 2. Methods are depicted in Section 3. Here, segmentation and optical flow approaches are included. Results and discussions are finally presented in Sections 4 and 5 respectively.  Our dataset consists of 40 sequences of cardiac CT images. Selected sequences used for evaluation show the left ventricle at half of the heart. The tomographic studies were acquired with a SIEMENS 16-slice CT system at 120kVp of tube voltage and 900mA. The scanner is composed of 128 detectors and is synchronized with the ECG signal. Each image has a size of 512\u00d7512 pixels, quantized to 12 bits per pixel. A contrast agent was also applied to each patient. Each sequence is composed by 10 frames showing the heart variation throughout the entire cardiac cycle from diastole to systole.   METHODS   Active shape models are one of the most powerful segmentation tools for medical image analysis. They consist of a statistical model that can be deformed within a specific range defined by a training set [12]. Here, shapes are represented using discrete points in the spatial domain. These points are commonly called landmarks when they are used to depict anatomical structures. Two main stages must be implemented in ASM algorithms: (1) Training of the statistical model, and (2) Segmentation of new images using the statistical model. An appearance model for each landmark is also required.  The trained model encodes the principal modes of variation of the landmarks. When these landmarks represent biological structures, they can be categorized as anatomical, mathematical and pseudo-landmarks [20]. In our model we used four mathematical landmarks and several pseudo-landmarks (see Fig. 1 ).  We adopted the method in [21] to build the statistical model. N samples, each one represented by r points, are used for training. Each sample corresponds to an image sequence. Landmarks of all the frames are concatenated in one shape vector. Let S  i be the vector describing shape i of the training set; it can then be obtained by concatenating the P  ij landmarks of the analyzed object:   S   i   =   (    P   i 0   ,   P   i 1   , \u2026 ,   P   i , r \u2212 1    )   \u22a4   with i = 1 , 2 , \u2026 , N and j = 0 , 1 , \u2026 , r \u2212 1 . \u22a4 is the transpose of the vector.  A training set previously marked is needed in order to build the statistical model. For the manual segmentation, we created an interactive graphic interface that enables the experts to mark the contour of the left ventricle in the images. The application allows selecting specific image sequences from the 4D cardiac CT to go through with the annotation process.  A sequence of cardiac CT images includes temporal and spatial information. In this method both types of information are represented using a unique shape vector. This shape representation is commonly called spatiotemporal [18]. All the landmarks are concatenated beginning with the first frame of the sequence (represented by the time t 0) and ending with the last one (denoted by the time variable t 9). Each shape vector is then computed as:  (1)    S   i   = {    x   i 0   t   0     ,   y   i 0   t   0     ,   x   i 1   t   0     ,   y   i 1   t   0     \u2026 ,   x   i ( n \u2212 1 )   t   0     ,   y   i ( n \u2212 1 )   t   0         \u2026 ,   x   i 0   t   9     ,   y   i 0   t   9     ,   x   i   1   9     ,   y   i 1   t   9     \u2026 ,   x   i ( n \u2212 1 )   t   9     ,   y   i ( n \u2212 1 )   t   9      }   \u22a4     where {    x     ijt   f     ,   y     ijt   f      } is the set of landmark coordinates; t  f ( f = 0 , 1 , \u2026 9 ) indicates a frame of the sequence; i = 1 , 2 , \u2026 , N indicates a spatiotemporal shape, n is the number of points for each frame of the sequence, and N is the number of sequences of the training set. The statistical model used in this work is referred to as Spatiotemporal Point Distribution Model (STPDM) [21] and its construction can be achieved with the approach described in [12,22,21], which will be shortly explained in this section.  The training set is firstly aligned. The Generalized Procrustes Analysis GPA [20] is very efficient for this task. A final mean shape   S   \u00af   is computed using the aligned shapes X  i :  (2)    S   \u00af   =   1   N      \u2211   i      X   i        Principal Component Analysis (PCA) must be performed in order to assemble the STPDM. The set of eigenvectors e  k corresponding to the highest eigenvalues \u03bb  k are obtained with the aim of coding the principal modes of variation for each landmark. Hence, the STPDM is computed as:  (3)  S =   S   \u00af   + Mb   where M is the eigenvectors matrix and b is the shape parameter. New shapes can be generated by varying the values of b. An appearance model must also be built for each landmark during training and is used to guide the STPDM in the segmentation process. In order to strengthen the edge-based adaptation of the algorithm, intensity and gradient profiles for each landmark are used. Once the statistical model and the appearance parameters have been calculated, new sequences can be segmented. With the STPDM we code the position of one landmark not only with respect to similar landmarks in the same frame, but also with respect to the rest of the landmarks of the other frames. The configuration of the spatiotemporal shape vector imposes an additional constraints in the deformation process. The algorithm followed in this work can be reviewed with more details in [22].  One of the main problems of ASM arises from the limited number of training samples used to build the statistical model. Ideally, the number of pre-segmented sequences needed to build a very efficient PDM must be at least the number of landmarks used to describe the shape sequence. The quantity of significant eigenvalues obtained with PCA depends on the number of shape samples (for N training samples, it is possible to obtain at least N \u2212 1 significant eigenvalues). This causes that small details of the analyzed object can not be segmented because the deformation capabilities of the STPDM are poor. Davatzikos et al. [23] proposed a hierarchical model to overcome the problem of lack of data in the training set. They used a wavelet representation of the shape vectors to build the statistical model at the level of sub-bands. Substantively, the number of training samples is increased by using this framework. Following with the same idea, Nain et al. [24] extended the method to 3D data by using spherical wavelets. Despite these approaches are efficient in managing the set of training data, the performance depends on the number of decomposition levels used for the model construction.  Instead of improving the ASM formulation, in this work we focused our effort in correcting the segmentation errors by using a simple but an effective method to find better local positions of the shape landmarks and making them to be deformed independently of the general shape parameters. We assume that the segmentation with the ASM algorithm has reached a stable condition, it means that the active search has converged to a final solution in which global characteristics of the object were found. Small details of the object have to be segmented with our correction method. In Fig. 2 we graphically outline the deformation process to be followed after the ASM stage. Three image parameters are taken into account for the final adaptation.  Our correction algorithm aims to adjust the discrete contour to the boundaries of the object of interest. From Fig. 2 we can see that there are several object boundaries in which the blue contour can be deformed, however the correct one has to be identified. Intensity and gradient information, as well as a binary pattern are used as image features to adjust each landmark. In order to maintain a smooth contour, these parameters are embedded into a parametric active contour functional. The computation of these parameters is explained below. Moreover, better positions for the landmarks are found along the normal direction. Because we characterize the left ventricle boundaries using local edge and gray level features, we applied a Gaussian filter to each input image of the complete sequence. It allows improving the process of feature extraction by describing the boundaries of the analyzed object.  The first parameter used for edge characterization is a binary pattern that codes local information around each landmark. The goal is to find the relationship between a point and its neighborhood. Intensity points are sampled and compared with the analyzed landmark. For landmark j of frame t  f , we define the binary pattern as:  (4)    BP   j ,   t   f     = {  Hd (    Q   j ,   t   f     (  m , \u03b2  ) \u2212   I   j ,   t   f      )  }   with 0 \u2264 (  Q , I  ) \u2264   G   max   ; m \u2208 R ; 0 \u2264 \u03b2 \u2264 2 \u03c0 . Here, Hd(y) is the Heaviside function, G  max is the maximum image intensity,   I   j , tf   is the intensity of the analyzed landmark, and   Q   j ,   t   f     ( m , \u03b2 ) is the intensity at a distance m and angle \u03b2 of the analyzed landmark. The pattern is therefore a set of binary elements obtained with a specific configuration given by the parameters m and \u03b2. Fig. 3 illustrates an example of a particular configuration used to obtain the binary pattern.  A reference binary pattern BP  r for each landmark is also needed. This must be previously trained. Because the objective is to find better positions for the landmarks, the BP is computed for several points in the normal direction and afterwards compared with the corresponding trained reference. A similarity metric designed for binary data is used for comparison purposes. We selected the Jaccard distance JD since it constitutes an efficient method to compare binary data [25]. Let BP  r and   BP     X   n     be two sets of binary patterns where each element corresponds to an individual outcome. The Jaccard distance between them is computed as:  (5)    JD     X   n     =   (  1 \u2212     DJ   11       DJ   01   +   DJ   10   +   DJ   11      )   j ,   t   j       where DJ 01 is the number of elements being 0 in BP  r and 1 in   BP     X   n     . DJ 10 is the number of elements being 1 in BP  r and 0 in   BP     X   n     . DJ 11 is the number of elements being 1 in BP  r and 1 in   BP     X   n     .  Here,   BP     X   n     is the binary pattern computed for a point X in the normal direction of the landmark ( j ,   t   f   ) . This metric ranges within the interval [ 0 , 1 ] , being 0 the value obtained when both patterns are equal. The binary pattern helps identify the side of the object which a particular landmark belongs to.  The intensity parameter corresponds to the second image feature used to characterize the boundaries of the analyzed object. Here, a local histogram LH is associated with each landmark. Similarly, we need to train a local histogram which is subsequently used as reference in the final deformation process. Then, for each point in the normal direction of the landmark ( j ,   t   f   ) we compute the local histogram   LH     X   n     and is compared with the reference LH  r . As metric of comparison we used a vector space distance [26] defined as:  (6)    HD     X   n     =   (      \u2211   i     LH     X   n     ( i )   LH   r   ( i )       \u2211   i     LH     X   n     ( i )       \u2211   i   LHr ( i )      )   j ,   t   f       where i indicates a bin of the histogram. When both histograms are very similar the distance HD approximates to 1. This parameter maintains the landmarks in the boundary of the left ventricle, preventing the deformation to other close boundaries.  Because the gradient is the standard operator to find edges inside an image, it is included as the third parameter in our segmentation correction algorithm. Therefore, the image gradient is locally computed and normalized for each landmark of the discrete contour. It is referred to as GI.  In order to provide a transparent way to deform the landmarks, we embedded the parameters as image energies into a parametric active contour functional. This also allows controlling the deformation through the internal energy of the active contour. We implemented a Greedy algorithm [27] which is more suitable for discrete approximations. The energy of the active contour is written as:  (7)  E (  X  ) = \u03bc   E   int   (  X  ) +   E   ima   (  X  ) = \u03bc   E   int   (  X  ) + \u03bb JD (  X  ) + \u03b1 (  1 \u2212 HD (  X  )  ) + \u03b2 (  1 \u2212 GI (  X  )  )   where \u03bc , \u03bb , \u03b1 and \u03b2 are weight values that control the contribution of the parameters; E  int and E  ima correspond to the contour and image energies respectively; X \u2208   R   2   .  The optical flow estimation is calculated in those situations where the displacement or correspondence of pixels between two images is required, e.g., image registration and reconstruction applications, video compression, motion\u2013based segmentation, and medical imaging.  The optical flow is frequently considered as the distribution of \u201capparent velocities\u201d that an object may experiment in an image sequence [28]. In most cases, the optical flow is computed by quantifying the changes of intensity of the objects in the scene. Besides, the representation of the optical flow is through a vector field that measures pixel displacements.  The classical differential optical flow methods assume that the intensity values of the objects keep unchanged in two consecutive frames of an image sequence L ( X , t ) . This assumption was introduced in [29] and is commonly known as the Constant Intensity Constraint:  (8)  L ( X + W , t + 1 ) \u2212 L ( X , t ) = 0   where X =   ( x , y , 1 )   \u22a4   is the position of the pixel, W \u2254   (  u , v , 1  )   \u22a4   represents the horizontal and vertical pixel displacements respectively between two images at instants t and ( t + 1 ) .  A Taylor expansion is used if small displacements are assumed. Then, the Optical Flow Constraint is calculated as:  (9)    uL   x   +   vL   y   +   L   t   = 0   where L  x , L  y , L  t are the derivatives of the intensity image L(X) w.r.t x, y directions and the time variable t.  It is not possible to determine the displacement components u and v if only the Constant Intensity Constraint is used. This is commonly known as the Aperture Problem where only the normal components of the motion can be obtained [29]. Therefore, we need other constraints to fully calculate the optical flow. Recent differential optical flow methods have proposed to incorporate other types of constraints to overcome the aperture problem and increase accuracy of the obtained displacements. Here, several strategies such as using multiresolution algorithms, considering spatial coherence and including local restrictions are among the most accepted solutions [30].  Horn and Schunck [29] proposed the Smoothness Constraint which considers that the flow is smooth. Thereby, the optical flow in this type of methods can be estimated through an iterative process that minimizes the following energy functional:  (10)    E   HS   ( W ) =   \u222b   \u03a9   (    W   \u22a4   (    \u2207   3   L   \u2207   3     L   \u22a4    ) W + \u03b1 | \u2207 W   |   2    )  dX   where   \u2207   3   L  \u2254    (    L   x   ,   L   y   ,   L   t    )   \u22a4   , \u03a9 is the image domain and \u03b1 is a smoothness parameter.  The main disadvantage of the uniform smoothness in Eq. (10) is that it excessively smoothes the edges in the flow. A flow-driven smoothing approach can be used to avoid this problem in texture images [31]:  (11)    E   IF   ( W ) =   \u222b   \u03a9   (    W   \u22a4   (    \u2207   3   L   \u2207   3     L   \u22a4    ) W + \u03b1 \u03a8 (  | \u2207 u   |   2   + | \u2207 v   |   2    )  )  dX   where \u03a8 (    s   2    ) is a smooth function convex in s. In most cases the constant intensity constraint and the small displacement assumption of Eqs. (8) and (9) are not satisfied, as in the case of CT image sequences. Therefore, an additional term independent to intensity changes is required, e.g., the image gradient. Nonetheless, multiresolution schemes can be adopted with the aim of processing large displacements.  A method (OF\u2013Warp) that takes into account the variability of intensities and the large displacements of the objects was presented in [32]. The technique is described with the following functional:  (12)    E   Warp   ( W ) =   \u222b   \u03a9 \u00d7 [ 0 , t ]   \u03a8 (  | L ( X + W ) \u2212 L ( X )   |   2   +   \u03b3 | \u2207 L ( X + W ) \u2212 \u2207 L ( X )   |   2    )  dX + \u03b1   \u222b   \u03a9 \u00d7 [ 0 , t ]   \u03a8 (  |   \u2207   3   u   |   2   + |   \u2207   3   v   |   2    )  dX   where \u2207 L ( X ) is the image gradient, \u03b3 is a weight parameter and \u03a8 (    s   2    ) is the modified \u2113   1   \u204e   \u2013norm [33,30]:  (13)  \u03a8 (    s   2    ) =   (   s   2   +   \u03f5   2   )     The values of \u03f5 are in the order of 1 \u00d7   10   \u2212 3   such that \u03a8 (    s   2    ) is differentiable in s=0 [32].  Another interesting approach to calculate the optical flow in a sequence considers the property of mass conservation [34,35]. Eq. (14) holds that the mass of a fluid per unit time with density \u03c1 that leaves a volume V with velocity v is equal to the mass of the surface that encloses the volume:  (14)    \u2202 \u03c1   \u2202 t   + div ( \u03c1 v ) = 0      In a 3D sequence, the density of fluid \u03c1 is related to the intensity value L ( x , y , z ) and the velocity v of the fluid to the displacement of the voxels ( u , v , w ) . The equation of mass-conservation optical flow is then written as:  (15)    \u2202 L   \u2202 t   + div ( uL + vL + wL ) = 0      From Eq. (15), if only displacement components u and v are considered, we obtain an extended version of the optical flow constraint equation (Eq. (9)), commonly known as the Extended Optical Flow Constraint which can be applied to areas that satisfy a total intensity invariance [36]. This method has been previously applied to cardiac PET volumes [35] with promising results.  The optical flow method described by Eq. (12) incorporates constant constraints based on local image features such as intensity and gradient. One of the purposes of this work is to find an efficient method to represent the image features. We have opted for a bio-inspired model based on the Hermite transform (HT), which can perform a polynomial decomposition using a multiresolution scheme [37,38]. The importance of this image model is that it can emulate the behavior of receptive fields of the human visual system [39,40]. The HT can be easily obtained by convolving the input image L ( x , y ) with the analysis filters   D   m , n \u2212 m    [40], and then subsampling at positions (   x   0   ,   y   0   ) . The HT is defined as:  (16)    L   m , n \u2212 m   (   x   0   ,   y   0   ) =   \u222b   \u2212 \u221e   \u221e     \u222b   \u2212 \u221e   \u221e   L ( x , y )   D   m , n \u2212 m   (   x   0   \u2212 x ,   y   0   \u2212 y )  dx  dy n = 0 , 1 , \u2026 , \u221e  m = 0 , 1 , \u2026 , n   where   L   m , n \u2212 m   ( x , y ) are the cartesian Hermite coefficients, m and ( n \u2212 m ) are the analysis order in the directions x and y, (   x   0   ,   y   0   ) represents an image position and   D   m , n \u2212 m   ( x , y ) =   G   m , n \u2212 m   ( \u2212 x , \u2212 y )   v   2   ( \u2212 x , \u2212 y ) . Here, v ( x , y ) =   1   \u03c3   \u03c0     exp (  \u2212   (    x   2   +   y   2    )   2   \u03c3   2      ) is a Gaussian window,   G   m , n \u2212 m   ( x , y ) =   1       2   n   m ! ( n \u2212 m ) !       H   m   (    x   \u03c3    )   H   n \u2212 m   (    y   \u03c3    ) represents the polynomials used for the decomposition and   H   n   (    x   \u03c3    ) corresponds to the generalized Hermite polynomials:  (17)    H   n   (    x   \u03c3    ) =   ( \u2212 1 )   n   exp (  \u2212     x   2       \u03c3   2      )     d   n       dx   n     exp (  \u2212     x   2       \u03c3   2      )      A steered version of the HT can be obtained by rotating the cartesian Hermite coefficients   L   m , n \u2212 m   ( x , y ) using the angular functions   g   m , n \u2212 m   ( \u03b8 ) :  (18)    l   m , n \u2212 m , \u03b8   (   x   0   ,   y   0   ) =   \u2211   k = 0   n   (    L   k , n \u2212 k   (   x   0   ,   y   0   )  ) (    g   k , n \u2212 k   ( \u03b8 )  )   where   g   m , n \u2212 m   ( \u03b8 ) is the directional selectivity of the filters [38]:  (19)    g   m , n \u2212 m   ( \u03b8 ) =   (    n   m    )   (    cos   m   (  \u03b8  )  ) (    sin   n \u2212 m   (  \u03b8  )  )      The steered Hermite coefficients   l   m , n \u2212 m , \u03b8   ( x , y ) allows adapting the analysis process to the local content of the image, e.g., using directional Gaussian derivatives filters [41].  The local orientation angle \u03b8 is estimated using the criterion of maximum energy. Once the cartesian Hermite coefficients are rotated, we obtain the steered Hermite transform (SHT).  In order to illustrate the steering property of the HT, Fig. 4 (b) shows the SHT obtained from the HT of Fig. 4(a).  In this work, we used the coefficients of SHT for the local constraints of the optical flow functional (see [8] for more details). The proposed functional includes in the data term a constant intensity constraint using the zero order coefficient   L   0 , 0   and the steered Hermite coefficients   l   n , \u03b8   up to order N as constant high order local constraints [32]. The last term allows dealing with intensity changes in the image sequence where the constant intensity constraint fails. For the smoothness term, which allows recovering the flow in homogeneous areas of the image, a flow-driven regularizer [31] was used. Thereby, a bio-inspired energy functional that uses the SHT to extract relevant perceptive features is defined as follows:  (20)    E   SHT   ( W ) =   \u222b   \u03a9   \u03a8 (    |    L   0   ( X + W ) \u2212   L   0   ( X )  |   2   +   \u03b3 (    \u2211   n = 1   N     |    l   n , \u03b8   ( X + W ) \u2212   l   n , \u03b8   ( X )  |   2    )  ) dX + \u03b1   \u222b   \u03a9   \u03a8 (  | \u2207 u   |   2   + | \u2207 v   |   2    )  dX   where \u03b3 determines the participation of the constant intensity and high order features constraints, N is the maximum order of the polynomial expansion, \u03a8 is the modified \u2113   1   \u204e   \u2013norm of Eq. (13) and \u03b1 is a smoothness weight which affects the flow smoothing given a smoother flow for large values.  The Euler\u2013Lagrange equations are obtained by minimizing Eq. (20). An outer fixed point iteration process and a successive over-relaxation (SOR) iteration approach are performed to compute the solution of the equations. The non-linear terms are solved by using a 1st order Taylor expansion after the minimization of the functional.  Finally, a multiresolution strategy is carried out in coarse levels to compute small displacements. Then, the solution is propagated to the finer levels using a Gaussian pyramid.   EXPERIMENTS AND RESULTS   In this section we present results of the segmentation stage. To carry out the experiments we configured the algorithms as follows. A total of 50 points were used to represent the left ventricle in each frame of the sequence. It means that the spatiotemporal shape was built with 500 landmarks. A maximum of 25 iterations were enough to reach a stable solution in the ASM stage. Similarly, 5 iterations were used for the correction algorithm. The algorithm was initialized using the mean spatiotemporal shape. It was manually put very close to the object of interest. The first frame of the sequence was taken as reference to initialize the algorithm. With the aim of maintaining a standard experiment, we used the same initialization for each proof. The STPDM was trained using 35 samples. The complete dataset was validated using the leave-one out method.  The correction algorithm is executed when the ASM algorithm has converged. It was applied to each frame separately. The segmentation correction algorithm uses several weight parameters that need to be configured. Energies of the correction scheme were normalized to [ 0 , 1 ] . Although the weight parameters are difficult to select and depends on the particular image sequence, we experimentally found that good segmentation results for our dataset are achieved with \u03bc = 0.3 , \u03bb = 0.3 , \u03b1 = 0.2 and \u03b2 = 0.2 .  One of the main advantages of statistical shape models is that they can perform efficient segmentations with noisy data. Since PDM can only deform in the range specified by the training set, it can achieve acceptable results even in the presence of noise. Nonetheless, the correction algorithm can be affected by noise in the image because it freely deforms the contour points without taking into account the shape of the object. In order to reduce the effect of the image noise we previously applied a Gaussian filter to the sequence of images.  Qualitative and quantitative analysis are exposed in this section. The assessment is addressed by comparing with the manual segmentation. With the aim of verifying the efficiency of the proposed approach, we compared the obtained results with the classical ASM [12] which was applied frame by frame.   Fig. 5 illustrates results of the segmentation obtained for 6 frames extracted from 2 different sequences of the dataset. For visualization purposes, we used linear interpolation to draw continuous contours. Images in Fig. 5(a), 5(b) and 5(c) were taken at 0%, 30% and 60% of the cardiac cycle respectively.  Red, green and blue contours correspond to manual annotation, segmentation with the proposed method and segmentation with the classical ASM method respectively. As can be seen, the best results were reached with our method. This behavior is similar for the rest of the sequences of our dataset.  Two metrics were used to provide quantitative results of the segmentation: the Dice Similarity Coefficient (DSC) and the average point-to-curve distance. These metrics were calculated for each frame of the sequences. Fig. 6 presents the DSC obtained for 16 sequences using our segmentation approach. Results for three frames of each sequence at different cardiac phases are visualized. The performance reached for the proposed segmentation scheme is over 90% in most cases. This behavior is repeated for the rest of the sequences. A maximum DSC of 0.9855 and a minimum of 0.8141 were obtained, which represent the best and worst result respectively. Fig. 7 visualizes the areas of the best and worst result obtained. These areas correspond to regions enclosed by the contours. In the binary images, the white region is the object of analysis (left ventricle) and the black part is the background. The error region obtained by comparing the segmentation of the proposed method against the manual one is shown as well. This is the result of computing the difference between both binary images:   I   err   = abs (   I   m   \u2212   I   a   ) , where I  m and I  a are the corresponding binary images obtained through with the manual segmentation and the proposed method respectively, I  err represents difference where the black part is the overlapped region and the white region is the error.  We are also interested in evaluating how the correction algorithm improves the results of the STPDM. We then compared both stages of the segmentation method. In Table 1 the point-to-curve distance values are reported for the proposed correction method, the STPDM and the classical ASM. Results are presented for all 10 frames of the spatiotemporal shape and averaged for all the sequences. It can be seen that the correction method improves the segmentation with respect to the STPDM in all cases.   Fig. 8 visualizes the final improvement carried out by the correction algorithm. Two images at different cardiac phases are evaluated. It can be seen that small details are subsequently segmented with our correction algorithm.   Fig. 9 shows the optical flow results for a frame of the Dimetrodon sequence to test the performance of the OF-SHT Method. This test sequence is available from the web site http://vision.middlebury.edu/flow/data/ and it is part of a database used for evaluation of current optical flow methods.  Because of the presence of high order features constraints in Eq. (20), we tested the performance of the proposed OF-SHT method in a first experiment using the Dimetrodon sequence. Zero mean Gaussian noise with different standard deviations (\u03c3  n ) has been added. We simulated the noisy image using a normal pseudorandom number generator which was subsequently added to the original image. For gray level images, \u03c3  n represents intensity values. In our experiment it was set to 0, 10, 20 and 40. In Table 2 we compared the average angular error (AAE) of the OF-SHT method for different noise levels using optimized parameters \u03b3, \u03b1 and N. We can see that the OF-SHT method presents good results in images with Gaussian noise with standard deviations smaller than 40.  The angular error (AE) was computed as in Barron et al. [42]:  (21)  AE = arccos (    u   \u2192   \u00b7   v   \u2192    )   where \u00b7 is the dot product,   u   \u2192   = (   u   0   ,   u   1   ) and   v   \u2192   = (   v   0   ,   v   1   ) denote the true flow and the estimated flow, respectively.  In the second experiment, we evaluated the robustness of the OF-SHT method w.r.t the parameter variations using the Dimetrodon sequence. We computed the AAE after varying the maximum order N of the Hermite expansion, the smoothness parameter \u03b1, and the weight parameter \u03b3.  In the solution of the energy functional, \u03b1 is the weight value of the smoothness term. It allows filling the areas in uniform regions using averages from structures with spatial high frequencies (i.e. edges). Large values of \u03b1 lead to a smoother field flow and small values of \u03b1 penalize the correct optical flow solution.  We computed the optical flow for several values of N, \u03b1 and \u03b3 to analyze the behavior of the AAE. We then used the following values: N = 4 , 5 , 6 , 7 , 8 , 9 , \u03b1 = 50 , 100 , 150 , 200 and \u03b3 = 300 , 600 , 900 , 1200 . Fig. 10 shows a 4D plot with N, \u03b1 and \u03b3 corresponding to x, y and z axis respectively. The AAE is coded using colored elements which represent different parameter combinations.  From Fig. 10 we can observe that the best results for the AAE were obtained for values of N = 5 , 6 , \u03b1 between 100 and 150 and values of \u03b3 from 600 to 900. The smallest value was obtained for N=5, \u03b1 = 100 and \u03b3 = 600 . In sequences of cardiac CT, the intensity of motion varies from patient to patient and it is also different for each time of the cardiac cycle. The maximum motion is reached in the systole with the contraction of atria and ventricles (0% to 30%). The minimum heart motion is observed at the end of the systole and at the mid-to-end of the diastole phase [43].  In this section, we also present the resulting optical flow estimation for two cardiac CT sequences (see Fig. 11 ). The first sequence was analyzed at 20% and 30% of the cardiac cycle (systole) to view the strongest cardiac movement. The second sequence was processed at 50% and 60% to view the movement of relaxation during diastole. In order to compare our algorithm, two optical flow results are shown. The first one was obtained by applying the method of Papenberg et al. [32] and the second using the proposed OF-SHT method (Eq. (20)).  In order to evaluate the optical flow estimation performance, we used an image reconstruction approach. Given an image and its vector field at time t, we compute the image at time t + 1 using a forward reconstruction algorithm [44]. Then, the Root Mean Squared (RMS) error for both methods was calculated using the original image at time t + 1 and the reconstructed image. The RMS is defined as:  (22)  RMS  error =       \u2211   x     \u2211   y     (  L ( x , y , t + 1 ) \u2212   L   ^   ( x , y , t + 1 )  )   2     M \u00d7 N       where L ( x , y , t + 1 ) and   L   ^   ( x , y , t + 1 ) are the original and reconstructed images of size M \u00d7 N at time t + 1 .  In Fig. 12 we show the forward reconstruction results at 20% and 30% of the cardiac cycle for one sequence, and at 50% and 60% for a second sequence respectively. The first row corresponds to the slices at 20%, 30%, 50% and 60% of the cardiac cycle, and the vector field representing the motion of the left ventricle. The second row shows the forward reconstruction using the two optical flow estimation methods. The third row shows the absolute error between the true second image and the reconstructed image using the displacement vectors of the second row.  For a deeper analysis, the RMS error throughout the cardiac cycle for 10 sequences was performed. The RMS error was calculated in a region near to the manual annotated left ventricle. In Fig. 13 we show a comparison of the reconstruction performance using both methods. Here, we note that the RMS error is smaller using the OF-SHT approach.  For the cardiac CT images we computed the absolute error between the reconstructed and reference images using the same parameter variations employed in the experiment depicted in Fig. 10 and we also obtained satisfactory results.  The objective of this work is to develop a method for the analysis of cardiac CT image sequences. This application can help physicians evaluate qualitatively several left ventricle parameters such as volume, myocardial deformation, ejection fraction and others [3]. Although the main effort is made on the left ventricle, the rest of cavities are also very important for the cardiac evaluation. In this application the segmentation is the first step and is used to isolate the left ventricle for further analysis. Optical flow vectors are only shown on the contour of the segmentation. This constitutes an efficient way to assist physicians to identify some failures of the cardiac function.   Fig. 14 illustrates the vector field for two sequences of the dataset. Four frames of each sequence are shown. The frames show the heart at 0%, 30%, 60% and 80% of the cardiac cycle. Vectors of the four frames were computed using images of the phases 0\u201310%, 30\u201340%, 60\u201370% and 80\u201390% respectively. The set of vectors in the first image pointing inwards the left ventricle indicates the beginning of the contraction or systolic cycle, meanwhile the last image outlines the end diastolic or relaxation period with the vector field pointing outwards. A complete visualization and a subsequent analysis of the whole cardiac cycle can be carried out by using this technique in the complete dataset. This method can then be used as a tool to assess the heart mechanical function.  Both algorithms, segmentation and optical flow estimation, were implemented in Matlab using a 2.1GHz machine composed of 12 processors. The machine has 16GB of memory. Each image sequence was selected from a 4D cardiac CT study with 10 volumes which describes the complete heart cycle. Sequences are then composed of 10 images with a size of 512\u00d7512 pixels.  The segmentation algorithm was configured to run until reaching 25 iterations for the ASM and 5 iterations for the correction stage. The run-time for each iteration in the segmentation algorithm was about 2.8s for the ASM stage and 15.5s for the correction method.  The proposed OF-SHT algorithm uses a convolution operator to compute the Hermite coefficients. The run-time was 40s using 10 levels of decompositions, 5 outer fixed point iterations and 10 SOR iterations. To improve performing time, a fast HT (FHT) can be used [38] as future work.   DISCUSSION AND CONCLUSIONS   We implemented a framework for the analysis of cardiac CT sequences using a shape extraction method and an optical flow estimation approach. The left ventricle was used as object of interest. We firstly performed the corresponding segmentation using a STPDM which consists of a trained statistical model that codes spatial and temporal information of the sequences. Errors of the segmentation were subsequently corrected using an algorithm that incorporates three image parameters for edge characterization. These parameters were embedded as image energies into an active contour model. Afterwards, an optical flow estimation method was calculated using a bio-inspired differential approach. Combining the boundaries of the segmented object and the displacements vector field obtained from the optical flow estimation technique enables physicians to carry out a better identification of mechanical problems. The proposed framework was validated with several sequences of cardiac CT images and compared with other techniques.  Results were individually evaluated for each frame of the sequence using several metrics. In general, the lowest performance achieved in our segmentation method was obtained for frames at half the cardiac cycle. These frames are acquired at the end of the contraction phase, i.e., when the heart is bombing flood to the body. The bar diagram (Fig. 6) with the DSC analysis and the metric distance reflect this interesting behavior. The poor definition of edges, the low contrast and the irregular shape of the left ventricle are causes for this result. Moreover, this can also be a consequence of the presence of the left atrium in the images at this cardiac phase when working with the original axial view of tomographic studies. The high irregularity of the structures found in this part of the cardiac cycle makes the segmentation task more complicated.  In Table 1 we present comparative results of the two stages of the segmentation: STPDM and correction algorithm. As can be seen, the segmentation is substantially improved with our correction scheme. In all reported cases, the segmentation error is reduced when applying the correction method. Because the correction method follows the segmentation of the statistical model, the level of correction naturally depends on the performance initially achieved with the STPDM. From Fig. 8 and Table 1, it can be noted that bigger corrections are reached at the contraction phase of the cardiac cycle. It is a logical finding because the performance of the STPDM is lower at this phase. Therefore, fine details of the object boundaries are efficiently segmented with the proposed correction scheme, reducing the segmentation errors previously obtained with STPDM. Selection of optimal weight parameters is a difficult task. Since each image sequence presents different characteristics of contrast and noise, values of the parameters may require a specific configuration for each example. In this work we set the weight parameters experimentally. However, finding automatic ways to select them could be an interesting future contribution. In cases when the contrast of the images is poor and the noise is very high, it is more convenient to set higher values to the parameter that attempts to preserve the shape, as well as to the local intensity parameter. In the correction segmentation algorithm, these weight parameters correspond to \u03bc and \u03b1 respectively. When edges and contrast are well defined, it is preferable to give more relevance to the energies that act upon the edge features directly (\u03bb and \u03b2).  The vector field was obtained using a differential approach incorporated into the HT domain. Several local restrictions based on the SHT, non-linear constraints and a multiresolution approach for large displacements were adopted. Quantitative analysis was used to evaluate the performance. The forward reconstruction error obtained for the frames of the sequences shows better general performance with the proposed method. From Fig. 13 is clear that the best results (lowest error) were achieved during the relaxation phase of the cardiac cycle. This part of the cardiac phase presents smaller and more regular changes of the left ventricle motion. The worst result was consequently obtained in frames at the beginning of the systolic cycle.  The vector field in the optical flow estimation method is computed using the steered Hermite coefficients. Since the coefficients have been steered using the direction of maximum energy, the image noise is automatically filtered with this operation. It means, the steering property of the HT is indirectly filtering the image noise.  The proposed application, in which the vector field is visualized on the contour that encloses the left ventricle, is a promising technique for mechanical assessment of cardiac structures. Even though this technique was applied to the left ventricle, in future works it can be extended to others objects and others anatomical axes.  Since heart is a volumetric organ whose natural movement occurs in a 3D space, the logical task should be performing 3D evaluations using both segmentation and motion analysis. In the case of the segmentation, volumetric analysis can be provided by running the proposed algorithm slice by slice on each cardiac volume and then building the 3D model from the segmented slices. In the case of motion estimation, the task is more complex since it implies to analyze more variables in order to achieve accurate 3D vector field estimations. On the other hand, even though the heart is a structure that moves in a 3D space, most physicians are still evaluating the heart mechanical function using image sequences. Nevertheless, the future trend aims at providing 3D cardiac motion analysis [3] which also implies training physicians to diagnose based on moving volume and surface models. As future work, we propose to extend this framework to provide 3D evaluations.  None declared.   ACKNOWLEDGMENTS   This work has been sponsored by the following UNAM Grant: PAPIIT IG100814. Leiner Barba-J thanks CONACYT\u2013245976 for financial support, as well as Colciencias. Ernesto Moya-Albor and Jorge Brieva would like to thank the Faculty of Engineering of Universidad Panamericana (UP) for all support in this work.   REFERENCES", "highlights": "Purpose: The left ventricle and the myocardium are two of the most important parts of the heart used for cardiac evaluation. In this work a novel framework that combines two methods to isolate and display functional characteristics of the heart using sequences of cardiac computed tomography (CT) is proposed. A shape extraction method, which includes a new segmentation correction scheme, is performed jointly with a motion estimation approach.  Methods: For the segmentation task we built a Spatiotemporal Point Distribution Model (STPDM) that encodes spatial and temporal variability of the heart structures. Intensity and gradient information guide the STPDM. We present a novel method to correct segmentation errors obtained with the STPDM. It consists of a deformable scheme that combines three types of image features: local histograms, gradients and binary patterns. A bio-inspired image representation model based on the Hermite transform is used for motion estimation. The segmentation allows isolating the structure of interest while the motion estimation can be used to characterize the movement of the complete heart muscle.  Results: The work is evaluated with several sequences of cardiac CT. The left ventricle was used for evaluation. Several metrics were used to validate the proposed framework. The efficiency of our method is also demonstrated by comparing with other techniques.  Conclusion: The implemented tool can enable physicians to better identify mechanical problems. The new correction scheme substantially improves the segmentation performance. Reported results demonstrate that this work is a promising technique for heart mechanical assessment."}