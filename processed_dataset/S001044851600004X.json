{"id": "S001044851600004X", "article": "MAIN-TITLE Reconstruction of B-spline curves and surfaces by adaptive group testing   HIGHLIGHTS          The B-spline by Adaptive Group testing Estimation (B-AGE) is proposed.      B-AGE derives a B-spline curve or surface estimation only from salient 3D points.      The salient points are found sequentially by means of group testing.      B-AGE finds a unique solution with a minimum Akaike Information Criteria (AIC) value.          KEYPHRASES   B-spline curve and surface fitting  Akaike Information Criterion  Salient points  Iterative approximation  Group testing   Since the world is 3D in nature, effective interaction with the surrounding environment can be achieved by utilization of a 3D sensor, such as Lidar, 3D laser scanner, Microsoft Kinect or stereo camera. The sensor measurements are represented by a 3D point cloud as initial environment representation. 3D mapping\u00a0 [1], approximate surface fitting\u00a0 [2], object classification\u00a0 [3], loop closure detection\u00a0 [4] and mobile robot navigation\u00a0 [5] are some applications of point clouds. In spite of having rich information content, storing and processing of 3D point clouds is time consuming and computationally expensive. In contrast to these discrete representations, B-spline surfaces are employed in geometric modeling\u00a0 [6] and terrain mapping\u00a0 [7]. Stable and parametric representation of 3D surfaces, local modeling capability and affine invariancy are some advantages of B-spline surfaces. The difficulty of B-spline surface fitting in real-time applications arises when a huge point cloud is captured from a 3D scanner. Since every measured 3D point is located on the scanned surface, too much information is available for either interpolation or approximation of a B-spline surface. Furthermore, a large scale data fitting may result in an ill-conditioned or singular matrix\u00a0 [8]. Therefore, state-of-the-art B-spline fitting methods are considered in seeking few control points for representation of acquired point data\u00a0 [9]. For instance, the B-spline curve and surface fitting method presented in\u00a0 [10], progressively increases the number of control points as needed.  Most of the conventional B-spline curve or surface fitting methods, either assume that the knot vector is known a-priori or generate a set of knot values and then find the final set of active knots iteratively. Various techniques are proposed for solving knot placement problem, such as adaptive methods\u00a0 [11], evolutionary approaches\u00a0 [12] and iterative techniques\u00a0 [10] as some representatives. In addition to specification of distribution of knots and their values, the control points shall be determined to approximate a B-spline curve or surface. Minimization of a quadratic function\u00a0 [13], iteration and optimization\u00a0 [14] and the widely used least-square optimization\u00a0 [15] are some state-of-the-art methods for approximation of control points.  Lack of an appropriate and computationally efficient knot placement technique, requiring an initial estimate and finding a locally optimum solution are some problems of the conventional B-spline curve or surface fitting methods. Furthermore, few methods are considered in processing just the informative captured data for curve or surface fitting\u00a0 [16,17]. In order to remedy these problems, a group testing based method is proposed for B-spline curve and surface fitting that approximates a model by processing few data points. This method can be employed without an initial estimation and finds both knot vector and control points simultaneously by finding the most informative or salient points.  In the emerging field of Group Testing (GT), it has been shown that few tests are required to identify defective items among a large number of elements\u00a0 [18]. Based on the GT theory, in this paper to the best knowledge of the authors, a B-spline curve and surface fitting algorithm is presented for the first time, where, an adaptive group testing technique is developed that considers a captured 3D point cloud as a set of elements with few defective (salient) ones. Based on the group testing theory, a test is designed that detects salient points for construction of either a B-spline curve or surface. In contrast to the state-of-the-art group testing techniques, the relation of group size to the complexity of tests, is also considered. At the final stage of the algorithm, a B-spline surface approximation is derived which can efficiently represent the captured point cloud. The experimental results on some point clouds proves the applicability and performance improvement of the proposed method.  The rest of the paper is as follows. In Section\u00a0 2, some related works are reviewed. In Section\u00a0 3, a brief introduction to B-spline curves and surfaces and group testing theory is presented. The proposed method is explained in Section\u00a0 4. Section\u00a0 5 is devoted to the result of experiments and comparison to some popular B-spline fitting algorithm. Finally the concluding remarks are presented in Section\u00a0 6.   RELATED WORKS   Representation of scanned points by B-spline curves and surfaces is widely used in various Computer Aided Design (CAD) and Computer Aided Engineering applications. Several mathematical techniques are used in problem of B-spline curve or surface fitting. One category of these methods are the optimization techniques, where the B-spline fitting is defined as an optimization problem. B-spline surface fitting as a least square estimation is presented in\u00a0 [19]. A base surface approximated from boundary information of measured points. Then the measured points are projected to the base surface. Using the parameter values of projected points as the parameters of measured points, a least square estimation of final B-spline surface model is achieved. Modeling the curve estimation as a least square minimization problem, Gauss\u2013Newton method is employed in\u00a0 [15] for approximation of a set of ordered points by a B-spline curve.  A global particle swarm optimization (PSO) method is employed in\u00a0 [20] in order to find knot vector required for estimation of a B-spline curve from noisy measured points. A combination of an optimization method and an iterative method is introduced in\u00a0 [14] for specification of a knot vector, weights and parametrization of measured unorganized points. Furthermore, a multi-objective genetic algorithm is employed in\u00a0 [12] for determination of knot values in the problem of B-spline curve fitting. An evolutionary optimization scheme is used for local minima avoidance in the knot placement problem. Due to the importance of data point parametrization, a new algorithm based on the centripetal method is developed in\u00a0 [21].  A neural network based B-spline surface construction has been proposed in\u00a0 [22] where an unstructured point set is projected into   R   2   by locally linear embedding (LLE) method in order to generate the parametrization. Then, a neural network is trained for mapping from the parameter space into the 3D space. Finally, the surface tessellation is performed by generation of a grid in the parameter space and using the trained network for mapping the parameter value to the 3D space coordinates. Since all of the captured points are not informative for either curve or surface fitting, a good approximation can be achieved from few dominant or salient points. However, few methods are introduced to fit a curve or surface from dominant points. Least squares based curve fitting from dominant points is presented in\u00a0 [16]. After selection of dominant points, the parametrization is performed by finding the parameter values of only dominant points. Finally, a least squares minimization is performed to achieve a curve approximation from an ordered list of points. Later, in\u00a0 [17] a surface fitting from dominant columns is also introduced. In this paper, an adaptive group testing based method is developed that finds salient points from the captured point cloud and seeks a B-spline curve or surface model using the Akaike Information Criterion (AIC)\u00a0 [23].  Representation of measured data by B-spline curves and surfaces is widely used in Computer Aided Design (CAD) and Computer Aided Engineering (CAE) applications. Local support property, accurate modeling of analytic curves and surfaces, flexibility and precision are some benefits of using B-spline models. In this section a brief introduction to B-spline curves and surfaces and the group testing theory is presented.  In order to have an efficient model derived from measured data, a metric for the goodness of model fitting is required. One of the widely used fitness functions which provides a trade off between fitting error and model complexity, is the Akaike Information Criterion (AIC) and defined as  (1)  A I C = N ln   1   N    (   \u2211   i = 1   N      ( y  (   x   i   )  \u2212   y   \u02c6    (   x   i   )  )    2   )  + 2 k   where N is the number of samples used for model fitting, y is the measured value in the parameter variable   x   i   ,   y   \u02c6   is the estimated function and k is the number of model parameters. Another similar measure is Bayesian Information criteria (BIC) and is defined as  (2)  B I C = N ln   1   N    (   \u2211   i = 1   N      ( y  (   x   i   )  \u2212   y   \u02c6    (   x   i   )  )    2   )  + k ln N .      Both AIC and BIC have been used as data fitting measures in the CAD applications such as spline fitting\u00a0 [20,24] or surface modeling\u00a0 [25]. For the case of B-spline data fitting a particle swarm optimization based method is proposed in\u00a0 [20] where AIC is used as the cost function. By minimizing AIC, an optimal B-spline curve is derived by considering the model complexity. A similar approach is proposed in\u00a0 [24] by using genetic algorithm as optimization method and BIC as cost function. In the field of naval construction, a surface modeling algorithm is presented in\u00a0 [25] by using AIC for selection of smoothing kernel bandwidth. Since both AIC and BIC provide similar results for smooth underlying functions\u00a0 [20], in this paper AIC is used as model fitting measure.  Variety of 3D objects and shapes may be represented by B-spline curves and surfaces, which is a parametric geometric modeling technique. Both analytic and freeform objects may be mathematically modeled by B-splines.  A B-spline curve is defined as:  (3)   c   ( u )  =   \u2211   i = 0   n     N   i , p    ( u )     p    i     while a B-spline surface is expressed by:  (4)   s   ( u , v )  =   \u2211   i = 0   n     \u2211   j = 0   m     N   i , p    ( u )    N   j , q    ( v )     p    i , j     where, the control points are expressed by  {    p    i   }  for curves and  {    p    i , j   }  for surfaces. A B-spline surface has m control points along u direction and n ones along v direction. The degrees of   N   i , p    ( u )  ,   N   j , q    ( v )  B-spline basis functions along parametric variables u , v is represented by p , q respectively. The basis functions are defined on the knot vectors   (5)   u  =  {     0 , \u2026 , 0  \ufe38    p + 1   ,   u   p + 1   , \u2026 ,   u   r \u2212 p \u2212 1   ,     1 , \u2026 , 1  \ufe38    p + 1   }     (6)   v  =  {     0 , \u2026 , 0  \ufe38    q + 1   ,   v   q + 1   , \u2026 ,   v   s \u2212 q \u2212 1   ,     1 , \u2026 , 1  \ufe38    q + 1   }     where, r = n + p + 1 and s = m + q + 1 . The B-spline basis functions by the de Boor formula is defined as:   (7)    N   i , 0    ( u )  =  {    1     u   i   \u2264 u <   u   i + 1       0   otherwise        (8)    N   i , p    ( u )  =   u \u2212   u   i       u   i + p   \u2212   u   i       N   i , p \u2212 1    ( u )  +     u   i + p + 1   \u2212 u     u   i + p + 1   \u2212   u   i + 1       N   i + 1 , p \u2212 1    ( u )  .       Various methods and algorithms are available in the literature for both B-spline surface interpolation and approximation from a point cloud\u00a0 [26,27,14,28].  In this paper a B-spline curve and surface approximation based on group testing is presented, in which few data points are used for either curve or surface construction. Basics of group testing is briefly reviewed in the next section.  During the World War II, the group testing theory was developed to reduce the required number of blood tests for detection of soldiers with Syphilis\u00a0 [29]. Where it was shown that, instead of individual testing, performing blood tests on a pool of blood samples, reduces the total number of tests considerably. The group testing has been used in several applications such as detection of defective objects in quality control of production lines\u00a0 [30], built-in self test (BIST) in digital logic systems\u00a0 [31] and sparse signal recovery [32,33]. In the group testing problem, it is assumed that in a set X of N elements some are defective, while the other elements are good. It is preferable to identify the defective items by minimum number of tests. The tests are performed on subsets called pools, where the test result is either positive in the case of contaminated set or negative for a pure set. The group testing problem is expressed by  ( d , N )  -problem to indicate that d items out of N are defective.  The group testing strategies can be divided into two probabilistic group testing (PGT) or combinatorial group testing (CGT). In the PGT, it is assumed that the test results obey a known probabilistic distribution, which is usually the binomial probability distribution\u00a0 [34]. In CGT, it is supposed that number of defective elements d or an upper bound on it, is known a priori\u00a0 [35]. Based on the testing strategy, a group testing algorithm is called adaptive\u00a0 [36], non-adaptive\u00a0 [37] or multi-stage\u00a0 [38]. In the adaptive scenario, the pool designs are accomplished based on the outcomes of previous tests. On the other hand, in the non-adaptive group testing algorithms, all pools can be determined without knowing the result of any test. The third type of group testing strategies is known as multistage or s  -stage methods. In each stage, the tests are performed in parallel such as the non-adaptive case. Finally, the result of each stage is fed into the next one for further testing and determination of remaining defective items. In basic group testing, the upper bound of tests for adaptive methods is O  ( d log n )  , while the upper bound of non-adaptive techniques is O  (   d   2   log n )  . A 2-stage technique finds d defects in not more than O  ( d log  (   n   d   )  )  test. The upper bound of algorithm complexities in basic group testing are derived by assuming that the cost of testing is independent of group size, which is in contrast to the considered case here.  In order to have a clear understanding of adaptive group testing, an example is provided here. A set of light bulbs with unknown number of defective ones as shown in Fig.\u00a01 is considered. The doubling technique\u00a0 [31] is employed as an adaptive group testing for determination of defective light bulbs in this example. In this technique, disjoint subsets of 1 , 2 , \u2026 ,   2   i   are tested until a contaminated subset is encountered. Therefore, by performing i + 1 tests, 1 + 2 + \u22ef +   2   i \u2212 1   good items and a contaminated subset are detected. In the next step, one defective item is detected by performing a binary search in the contaminated subset by means of i tests. This process is repeated until all defective items are determined.  In this example a set of 10 light bulbs with unknown number of defective items is considered. It is assumed that 2 items are defective and the remaining ones are good, as shown in Fig.\u00a02 . This information is not known a priori and the final answer is provided here so one can follow the process of group testing algorithm. In order to test items, a subset of light bulbs are connected in series and a voltage is applied to them. A good subset is indicated by lights being on. In case of a contaminated subset, the lights will be off.  In the first step, i = 0 and   2   i   = 1 item is selected from the set of light bulbs. The leftmost item is picked for testing as shown in Fig.\u00a03 (a). Since the tested light bulb is not defective, the test result is negative. In the next step, we have i = 1 and   2   i   = 2 items are selected for testing. Connecting the two light bulbs marked in Fig.\u00a03(b) by a bounding box, results in a negative test result as both light bulbs are good. In the next step, by setting i = 2 , a subset of   s   i   = 4 items are selected. This time, the test result is positive and all lights are off as depicted in Fig.\u00a03(c). This means that at least one defective item is present in this subset. By means of a binary search, one defective item is found in this subset. This set of four items is divided into two equal size subsets, and each are tested as shown in Fig.\u00a03(d) and (e) respectively. This process continues until all defective items are detected. In this example, two defective items are found among ten items by performing eight tests. In a set of large number of items, the group testing is very efficient and defective items are found by few group tests.  Equipped with the group testing techniques, a B-spline curve and surface reconstruction algorithm is developed in the next section that differs from basic group testing methods. In the proposed method, the cost of test evaluation depends on the pool size.   PROPOSED METHOD   In this section, a method is developed for determination of salient points in B-spline curve fitting problem, which is based on adaptive group testing (see Fig.\u00a04 ). Then, the idea is extended to the problem of B-spline surface fitting from salient points.  The measured points M =  {  (   y   i   ,   x   i   )  | i = 1 , \u2026 , N }  can be approximately represented by a B-spline curve.  (9)   c   ( u )  =   \u2211   i = 0   n     N   i , p    ( u )     p    i   + e  ( u )    where, u is the parametric variable,    p    i   are the control points and e  ( u )  is the error of estimation. The approximation of measured points is expressed by the continuous curve  c   ( u )  with the parametric variable u \u2208  [ 0 , 1 ]  .  The most popular B-spline curve estimation method is the least square estimation which is inefficient and unstable in the case of large number of measurements. Due to the increasing precision of available sensors, most of measured data are not much informative and a good approximation can be achieved from few salient points. This problem is rarely considered by authors in the CAD and CAE communities\u00a0 [16]. In other words, usually a few number of control points are sufficient for approximation of some measured points, which may be expressed by  (10)  n \u226a N .      Since the number of knots is related to the number of control points, discarding non-informative measured points results in few active knots and consequently few B-spline basis functions. Therefore, we are interested in finding only salient points required for construction of a B-spline model.  The Fourier transformation of a B-spline basis function defined on a uniform knot vector can be expressed as:  (11)  \u03a6  ( \u03c9 , \u03c4 , p )  =    (     e   i \u03c4 \u03c9   \u2212 1   i \u03c4 \u03c9   )    p + 1     where, \u03c9 is the frequency, p is a constant value representing the B-spline basis degree and \u03c4 is the maximum interval of the knot vector. The first zero of the power function is located at   1   \u03c4   frequency, assuming that the parametric variable u varies in the [0,1] range. The B-spline basis function may be considered as a low-pass filter\u00a0 [39,40] as the value of power function decays outside of the  [ \u2212   1   \u03c4   ,   1   \u03c4   ]  interval in the frequency domain.  Considering Eq. (9), the approximate representation of measured data may be expressed by  (12)   c   ( u )  \u2248   \u2211   i = 0   n     N   i , p    ( u )     p    i   .   Applying the Fourier transformation results in  (13)  \u03a8  ( \u03c9 , \u03c4 , p )  \u2248   \u2211   i = 0   n   \u03a6  ( \u03c9 ,   \u03c4   i   , p )     p    i     where, the Fourier transformation of measured data is represented by \u03a8  ( \u03c9 , \u03c4 , p )  . Here we define the normalized Fourier transform of a B-spline basis function as  (14)    \u03a6   n    ( \u03c9 , \u03c4 , p )  =   \u03a6  ( \u03c9 , \u03c4 , p )     | \u03a6  ( \u03c9 , \u03c4 , p )  |    .   Therefore, the convolution of a B-spline basis function with the observed data is readily computed by the multiplication of Fourier transform of measured signal \u03a8  ( \u03c9 , \u03c4 , p )  with the normalized B-spline basis function   \u03a6   n    ( \u03c9 , \u03c4 , p )  , where defined in (14) and shown in Fig.\u00a05 . Defining the bandwidth of B-spline basis function as   1     \u03c4   \u0304     , the result of filtering is a smoothed signal with frequencies lower than   1     \u03c4   \u0304     for a specific value of \u03c4 =   \u03c4   \u0304   .  (15)    \u03a8   f    ( \u03c9 , \u03c4 , p )    \u2223   \u03c4 =   \u03c4   \u0304     = \u03a8  ( \u03c9 , \u03c4 , p )    \u03a6   n    ( \u03c9 ,   \u03c4   \u0304   , p )  =   \u2211   i = 0   n   \u03a6  ( \u03c9 ,   \u03c4   i   , p )    \u03a6   n    ( \u03c9 ,   \u03c4   \u0304   , p )     p    i   \u2248   \u2211   i = 0   n   \u03a6  ( \u03c9 ,   \u03c4   i   , p )     p    i     \u2223     \u03c4   i   \u2265   \u03c4   \u0304     .   Varying the value of   \u03c4   \u0304   from the lowest possible frequency to the highest one, the salient points at each frequency level can be specified, due to the filtering property of B-spline basis. The B-spline basis function is defined on a uniform knot vector and is just employed for detection of salient points by means of convolution. The approximated B-spline curve is not restricted to uniform knot vector.  In order to represent a B-spline curve approximation of N data points, B-spline basis function of having frequencies from 1 up to N / 2 can be employed for construction of a knot vector, according to the Shannon sampling theorem. The number of B-spline basis functions and their bandwidth, are specified by the distribution of knot vector and the relative distance between knot values. Therefore, specification of salient data points and their relevant control points is equivalent to determination of proper knot values and required B-spline basis functions for approximation of measured data points by a B-spline curve. In other words, from salient points, the required control points can be derived. Where, it specifies proper knot values, and therefore, the set of B-spline basis functions.  The problem of finding salient points may be modeled as a combinatorial search in the set of B-spline basis functions, S =  { B  |  B = 1 , 2 , \u2026 ,   N   2   }  , where B is the total bandwidth of the basis function. This combinatorial search problem can be efficiently solved by a group testing method. This group testing problem is expressed by M  ( d , N )  in order to show that the minimum number of tests required to find d defects in a set of N items. As mentioned before, in the non-adaptive group testing, all tests are designed at the same time and can be applied in parallel. However, in the adaptive case each test is designed after the result of the previous one is achieved. In this paper, based on the adaptive group testing an algorithm is developed to determine the basis functions required for the construction of B-spline curve.  In the development process of a group testing method, the test function and a pooling design shall be determined. Therefore, we define the function V  (   \u03c4   \u0304   )  as  (16)  V  (   \u03c4   \u0304   )  =    \u2016   max   \u03c9    {   \u03a8   f    ( \u03c9 , \u03c4 , p )    |   \u03c4 =   \u03c4   \u0304     }  \u2016    2   ,    2   N   \u2264   \u03c4   \u0304   \u2264 1   where the max operator indicates maximum value which means that no optimization is performed here.  Since a low-pass filter provides a \u22123 dB gain attenuation at the cut-off frequency, samples of   \u03a8   f    ( \u03c9 , \u03c4 , p )  with gain values lower than 0.707 V  (   \u03c4   \u0304   )  are discarded which means that the frequencies lower than   1     \u03c4   \u0304     are not present in the measured signal. Remaining sample points are iteratively checked for saliency by the test function T which is defined as  (17)  T  (   P   i   )  =  {    A I   C   r   \u2265 A I   C   r \u2212 1      0     A I   C   r   < A I   C   r \u2212 1      1       where the i th sample point is shown by   P   i   , r indicates the iteration number and it is assumed that A I   C   0   = + \u221e . Therefore, a sample point is called salient, if and only if the following conditions are met  (18)    \u03a8   f    ( \u03c9 , \u03c4 , p )  \u2265 0.707 V  (   \u03c4   \u0304   )  A I   C   r   < A I   C   r \u2212 1   .      In order to apply the test function, a pool has to be constructed from the set of available items. Since in each test only frequencies lower than   1     \u03c4   \u0304     are evaluated, the sampling rate is defined as  (19)  s  (   \u03c4   \u0304   )  =   2     \u03c4   \u0304     .   Therefore, in each iteration of the proposed adaptive group testing algorithm, the sampling rate is computed and the corresponding pool is constructed by selecting items based on the sampling rate s  (   \u03c4   \u0304   )  . Also, in each test a B-spline basis function with bandwidth of   1     \u03c4   \u0304     is employed.  Almost every group testing method, is concerned in minimizing the number of tests to find a list of defective elements from a large set, which is a set of salient points in our case. In both the adaptive or non-adaptive group testing the complexity of tests are ignored. The original set of elements is divided into some subsets called pools without considering the complexity of performing test on each pool. In our case, the computational complexity of each test depends on the size of the pool. Therefore, a complexity function is defined here and it has been shown that the complexity of most popular algorithms is more than that of the proposed method. The computational complexity of a test is shown by   K   T    ( l )  which is equal to the algorithm complexity of performing a test on a pool of size l . Also the total computational complexity of the proposed adaptive group testing is represented by   K   A   and is derived from the following equation.  (20)    K   A   =   \u2211   i = 1     N   T       K   T    (   l   i   )    in which,   N   T   is the total number of tests required for finding all defective elements and   l   i   is the size of i th tested pool. The complexity of performing a test on a pool of size   l   i   is defined by  (21)    K   T    (   l   i   )  =   l   i   +   l   i   log   l   i   =   l   i   log 2   l   i     which is equal to the complexity of performing a convolution on two vectors of size   l   i   and finding its maximum value. Therefore, we are concerned in finding the minimum value of the algorithm complexity  (22)  min   K   A   = min   \u2211   i = 1     N   T       l   i   log 2   l   i   .   It is noteworthy that in (22), the minimum value of algorithm complexity is computed and no optimization is performed.                          The proposed approach for B-spline curve fitting, is shown in Algorithm 1. It is assumed that a set of samples are stored in M set and we have N =  | M |  . As the initialization stage, proper initial values are assigned to the sampling rate and the set of salient points. Then, in the main body of the algorithm, the process of finding salient points and updating the B-spline curve estimation is performed until the AIC is met or the upper bound of sampling rate is reached. At each iteration, the set of salient points related to the current B-spline basis function are found and stored in P . If at least one salient points is found, the set Q is updated and the B-spline curve is estimated from the set of new salient points.  The process of finding one salient point is performed in the SeekSalient function, which is shown in Algorithm 2. Initially, the set of new salient points,   P   l   is empty. Then in a loop, the sampling rate is doubled and s samples are uniformly derived from the sample set M and stored in S as the set of current samples. This process is inspired from the doubling technique\u00a0 [41] with the difference that in here, one salient point is specified at each positive test. In other words, additional information is provided at each positive test, which is one salient point. Then a test is performed on S as defined in (17). The test result would be either positive, in the case of A I   C   r   < A I   C   r \u2212 1   or negative in the case of A I   C   r   \u2265 A I   C   r \u2212 1   . For a negative test, it is implied that no salient point is found in relation to frequencies up to   1     \u03c4   \u0304     . One salient point is found when the test result is positive. Therefore, salient points are extracted by successive low-pass filtering having gain values of   \u03a8   f    ( \u03c9 , \u03c4 , p )  greater than 0.707 V  (   \u03c4   \u0304   )  in companion to a reduction in A I C value. While the process of finding salient points is performed in the frequency domain in this paper, similar idea has been already employed for sparse signal recovery in the time domain based on group testing\u00a0 [32,33].  In the case of a positive test, the BinarySearch function as defined in Algorithm 3, is employed in order to find the lowest possible sampling rate. Finally, after sampling with the derived sampling rate, salient points are detected by sequential testing until the sample set is pure. At the end of this function, all of the salient points in the current set are found and added to the   P   l   set. This set of salient points are sent to the main algorithm for updating the B-spline curve estimation. In the updating process of the B-spline curve estimation, accumulated chord length parametrization is used for construction of the knot vector and a least square approximation is derived from the new set of salient points.  In the following, the complexity of the proposed algorithm is derived and an upper bound to the required number of tests is provided. Furthermore, it will be shown that the algorithm has a unique solution as defined in the group testing literature. In order to provide the theoretical proofs, some definitions are required which will be given as follows. Here we employ a Lemma in order to prove the total number of required tests.    Lemma\u00a04.1  [18]     If  d =   d   \u2032   +   d   \u2033    and  n =   n   \u2032   +   n   \u2033    where    d   \u2032   \u2265 0  ,    d   \u2033   \u2265 0  and    n   \u2032   \u2265 0 ,   n   \u2033   \u2265 0  then we have   (23)    d   \u2032   log     n   \u2032       d   \u2032     +   d   \u2033   log     n   \u2033       d   \u2033     \u2264 d log   n   d   .      Now we are ready to prove the number of required tests for detecting salient points of a sample set.    Theorem\u00a04.1  Algorithm 1 Finds  d  Salient B-spline Basis Functions Uniquely in a Set  S  of  N  Points, In At Most   ( 2 d \u2212 1 )  log   N + 1   d \u2212 1    Tests.     Proof Starting from sampling rate s = 2 , groups of 2 , 4 , \u2026 ,   2   i \u2212 1   elements are constructed for sequential testing. The testing process continues until a contaminated set with   2   i   items is detected. Therefore, the algorithm finds one contaminated set of size   2   i   after i tests, while rejecting 2 + 4 + \u22ef +   2   i \u2212 1   =   2   i   \u2212 2 items. Then the binary search finds one salient item by i tests. Therefore, after 2 i tests,   2   i   \u2212 1 items are identified.  It can be proved by induction that the remaining items are determined by 2  ( d \u2212 1 )  log   N \u2212   2   i   + 1   d \u2212 1   tests. Total required tests are  (24)  2 log   2   i   + 2  ( d \u2212 1 )  log   N \u2212   2   i   + 1   d \u2212 1   \u2264  ( 2 d \u2212 1 )  log   N + 1   d \u2212 1     where this result may be directly concluded from Lemma\u00a04.1.  In order to prove the uniqueness property of Algorithm 1, it shall be considered that in each group test T  (   \u03c4   \u0304   )  , the existence of B-spline basis functions with frequencies lower than   1     \u03c4   \u0304     is determined. Since the set S is a discrete space with N points, it can be spanned by  \u230a   N   2   \u230b  B-spline basis functions. By choosing values of   1   2   ,   1   3   , \u2026 ,   2   N   for   \u03c4   \u0304   , the existence of only one frequency is checked in the T  (   \u03c4   \u0304   )  group test. Therefore, at the end of Algorithm 1, the set of d salient B-spline functions is constructed which is a subset of the set of all possible frequencies F =  { f | f = 2 , 3 , \u2026 ,  \u230a   N   2   \u230b  }  . The set of d salient B-spline functions is the unique solution of the  ( d ,  \u230a   N   2   \u230b  )  problem since the existence of all possible frequencies is checked from lower value to the highest one and Algorithm 1 finds the same solution, if applied to the same input data S .\u25a1  The complexity of some group testing algorithms are shown in Table\u00a01 . It is easy to show that the complexity of the proposed method is lower than two popular group testing algorithms. It is assumed that d elements are defective in a set of N elements and the complexity of one non-adaptive group testing and an adaptive group testing are compared to the complexity of the proposed method. In the next section, the proposed group testing method is extended to find salient points for B-spline surface fitting.  A 3D smooth surface is converted to a point cloud by a laser scanner, stereo camera or Kinect, as shown in Fig.\u00a06 . By this means a continuous space is represented by discrete measurements. Various B-spline surface fitting methods are employed in practice in order to achieve a continuous representation from point cloud data. Here, it is assumed that the observed point cloud is a discrete representation of a smooth B-spline surface. In other words, it is assumed that a 3D range is scanned by a sensor where a 3D observed point    p    o    (   x   o   ,   y   o   ,   z   o   )  satisfies the following conditions:  (25)    x   l   \u2264   x   o   \u2264   x   u     y   l   \u2264   y   o   \u2264   y   u     z   l   \u2264   z   o   \u2264   z   u     where,   x   l   ,   y   l   ,   z   l   are the lower bound of sensor measurements along x , y , z axes, respectively, and   x   u   ,   y   u   ,   z   u   are their corresponding upper bounds. Also, it is assumed that the sensor measurement is an organized point cloud with the width of W and the height of H , which results in a grid of W \u00d7 H 3D points. Projection of observed 3D points to the parametric plane u , v is performed by a linear projection operator:  (26)  L :   R   3   \u2192   R   2   ,  L  (    p    o   )  =  (   u   o   ,   v   o   )    in which, the parametric values are placed in the bounds of  (27)    u   l   \u2264 u \u2264   u   u     v   l   \u2264 v \u2264   v   u     with   u   l   ,   u   u   as the lower and upper bounds along u and   v   l   ,   v   u   as the lower and upper bounds along v axes. According to the problem assumptions, the measured points can be expressed by:  (28)   s   ( u , v )  =   \u2211   i = 0   n     \u2211   j = 0   l     N   i , p    ( u )    N   j , q    ( v )     p    i , j   +  e   ( u , v )    where,  e   ( u , v )  is the measurement error of the B-spline surface  s   ( u , v )  . It has been shown that B-spline surface fitting by the lofting method is equivalent to the simultaneous estimation of B-spline surface control points\u00a0 [42]. Therefore, we construct the cross sectional curves by fitting a B-spline curve to the salient points, and finally, derive the control points of B-spline surface by lofting method. Rewriting Eq. (28) one may achieve  (29)   s   ( u , v )  =   \u2211   i = 0   n     N   i , p    ( u )     f    i , d   +  e   ( u , v )   for d \u2208  { 1 , \u2026 , l }    with  (30)    \u2211   j = 0   l     N   j , q    ( v )     p    i , j   =    f    i , d     where,    f    i , d   are the control points of the iso-parametric curves  s   ( u , v = c o n s t )  on the surface. Each cross sectional curve    c    j    ( u )  =  s   ( u , v )    |   v = c o n s t   may be estimated by the adaptive group testing method presented in\u00a0 4.1. Having the estimated iso-curves along u in hand, we use Eq. (30) in order to estimate the control points of iso-curves along v using    f    i , d   as observation. The estimated control points    p    i , j   are the B-spline surface control points achieved by the lofting method. In the next section, the results of some experiments are presented in order to show the integrity and precision of the proposed method.   EXPERIMENTAL RESULTS   In this section the experimental results of proposed adaptive group testing technique are presented in both B-spline curve and surface estimation. In the first case, some 2D functions are chosen and the proposed method is employed for estimation of a B-spline curve from some measured points. In the second case, a smooth surface is observed and an organized point cloud is constructed by a sensor such as Lidar or laser scanner. The proposed method, derives the control points of an approximated B-spline surface from salient 3D points using the lofting method. Since the proposed method can be employed for both B-spline curve and surface estimation, it is abbreviated with B-spline by Adaptive Group testing Estimation (B-AGE).  The algorithm of B-AGE is implemented in C++ and all experiments are performed on a PC with eight Intel Core i7 CPUs and 16GB RAM. In all experiments a cubic B-spline is employed to have a fair comparison with other techniques. In order to compare the goodness of the fit, some metrics such as Mean Squared Error (MSE), Maximum Error (ME), Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) are reported. It is noteworthy that, in this paper AIC and BIC are used for evaluation of goodness of the fit as standard curve fitting metrics.  In this section, some 2D functions are chosen in order to analyze the applicability of developed method in approximation of B-spline curves from salient points. The functions and the number of samples are chosen the same as some state-of-the-art methods, in order to have a fair comparison. The AIC and BIC are computed for all methods and the goodness of fit is evaluated by having the lowest value of AIC and BIC.  In this section, the Titanium heat data\u00a0 [43] is used for the first curve fitting experiment. This challenging data is considered by several B-spline curve fitting methods such as\u00a0 [9,44\u201346]. In\u00a0 [9], initially the knot values are selected uniformly and a sparse optimization problem is solved to specify the active knots. The authors of\u00a0 [9] have used various number of knots and ranges for each experiment, which means that the sparse optimization based method depends on manual selection of number of knots and the knots range, as a priori. In addition, this method suffers from computational complexity as it has been denoted by the authors too.  The Titanium heat data has been used in another knot selection algorithm\u00a0 [46], where a set of pre-specified multi-resolution B-spline basis functions is employed for knot placement according to the curvature of an unknown function. In the first stage, some basis functions are chosen by a statistical variable selection, called Lasso. In the second stage, the locations of the knots are found by pruning. In this method, it is required to specify the uniformly spaced knot values and set the knot vector range manually. The number of internal knots and their values can be determined by optimization based techniques, simultaneously. Definition of B-spline curve fitting as a convex optimization is presented in\u00a0 [45] where both the number of required knots and their values are found automatically. By minimizing the   l   1   norm of the third order derivative of a cubic B-spline, a sparse set of active knots are found. In this algorithm, it is required to select active knots from a set of predefined knot values. Also, the range of knots shall be specified a priori. In addition to the mentioned methods, the experimental result of B-AGE on Titanium heat data is compared to two least squares based B-spline curve fitting\u00a0 [43,44]. In these methods, it is assumed that the number of knots are specified manually and the algorithm shall find the knot values, which is a very restricting requirement.  The results of experiments on the Titanium heat data are denoted in Table\u00a02 , where the internal knots and the residual error are reported. The residual error is defined in\u00a0 [44] as  (31)  \u03f5 =    (   1   n     \u2211   i = 0   n     w   i      ( c  (   u   i   )  \u2212   P   i   )    2   )      1   2       w   0   =   w   n   =   1   2   ,   w   i   = 1 , i = 1 , \u2026 , n \u2212 1 .      The residual error reported for the Jupp\u2019s algorithm\u00a0 [44] is 1.2270e\u20132 which indicates performance improvement in relation to the De Boor\u2019s technique. The De Boor\u2019s algorithm\u00a0 [43] is developed based on the fixed number of knots, which is 5 for this particular data. By means of sweeping in the parameter space, the optimal knots are found with a residual error of 1.3050e\u20132. In spite of good performance in the sense of residual error, the application of these two techniques is very limited due to the assumption of knowing the number of internal knots.  The B-AGE method is also applied to the Titanium heat data, where 6 internal knots and their values are both found by the proposed algorithm automatically. The residual error of 1.3231e\u20132 has been achieved without setting the number of internal knots a priori or performing extensive optimizations. The convex optimization technique presented in\u00a0 [45], has found 6 knot values resulting in a residual error of 1.4066e\u20132. The sparse optimization based method\u00a0 [9], has reported 5 internal knots with the residual error of 2.1629e\u20132. The SISL technique\u00a0 [47] which is a very fast knot placement technique has also found 7 internal knots but with a relatively high residual error of 2.1629e\u20132. Finally, the adaptive knot selection method\u00a0 [46], has found 6 internal knots with the residual error of 1.7695e\u20132. A set of basis functions are selected by Lasso technique for approximation of the underlying data, and later a pruning step is performed in order to reduce the number of internal knots.  The computational complexity of B-AGE is very low in relation to the optimization techniques as the process took 4 ms in this particular experiment. The timing of sparse optimization algorithm has been reported 40.22 s on a computer system with 4 Intel Core i5 CPUs. The timing of other optimization techniques has not reported but they use extensive optimizations. The convex optimization\u00a0 [45] has employed a re-weighting method and repeats the optimization until the approximation error is lower than a threshold.  While in most conventional research papers, the number of internal knots and the residual error are used for evaluation of the B-spline curve fitting quality, some authors presented curve fitting methods based on the AIC or BIC metrics. These standard model fitting metrics are used in this paper in order to perform a fair comparison between the mentioned methods. Both AIC and BIC are defined in order to find best approximating model to the observed data through a trade-off between approximation error and model complexity. The smaller the value of AIC or BIC, the better model has been found by the fitting algorithm. The values of AIC and BIC are reported in Table\u00a03 . The best fitting result has been achieved by the Jupp\u2019s algorithm with the lowest value of AIC and BIC. The next is the De Boor\u2019s method. While the fitting metrics has shown that these two methods are the best, but their practical application is very limited due to their dependence to the number of internal knots. The next algorithm is B-AGE which has found knots based on salient points. The goodness of fit for the B-AGE method is near to that of the De Boor and Jupp methods while having a low computational complexity in relation to the optimization based techniques. The sparse optimization and convex optimization methods are placed next, as they have lower AIC and BIC values in relation to the adaptive knot selection algorithm. The optimization based methods have found near optimal knot values with a relatively low residual error. Alongside the good quality of fitness achieved by these optimization based methods, their high computational complexity shall be considered too. The adaptive knot selection method is the last algorithm with acceptable AIC and BIC value, but with a high computational complexity similar to other optimization based techniques. The approximated curves by B-AGE algorithm is depicted in Fig.\u00a07 . The Titanium heat data is shown by circles and the approximated curve as dashed line in Fig.\u00a07(a). The salient points are also shown in Fig.\u00a07(a) by filled circles. These points are related to the maximum of convolution with B-spline basis functions with various scales. In Fig.\u00a07(b), the knot values are linearly scaled to the range of [0,75] and depicted by triangles for better visualization. The approximated curve shown in Fig.\u00a07(b) indicates the applicability of the B-AGE method in B-spline curve fitting by using only salient points.  In this section, some smooth functions are employed for approximation of B-spline curve by the B-AGE method. The experimental results are compared to that of some conventional methods, namely adaptive knot selection (AKS)\u00a0 [46] and adaptive free knot spline (AFKS)\u00a0 [48].  The smooth functions are defined as:   (32)    f   1    ( t )  = 2 sin  ( 4 \u03c0 t )  \u2212 6    | t \u2212 0.4 |    0.3   \u2212 0.5 s g n  ( 0.7 \u2212 t )  ,  t \u2208  [ 0 , 1 ]     (33)    f   2    ( t )  = sin  ( 4 t \u2212 2 )  + 2 exp  ( \u2212 30    ( 4 t \u2212 2 )    2   )  .    The number of samples are chosen as 1000 for   f   1    ( t )  and 101 for   f   2    ( t )  , similar to\u00a0 [48] and the B-AGE method, presented in Section\u00a0 4.1, is applied for estimation of a B-spline curve. The approximated B-spline curve by B-AGE is depicted in Fig.\u00a08 for   f   1    ( t )  . In Fig.\u00a08(a) the solid line curve indicates the original function and the dashed line represents the approximation result, where the salient points are shown by filled circles. In Fig.\u00a08(b), in addition to the original function and approximated curve, the knot values are linearly scaled to the range of [0,1] and depicted by triangles.  The fitting error and the relevant AIC and BIC values are presented in Table\u00a04 . As it can be seen, the B-AGE algorithm outperforms both AKS and AFKS methods in the sense of MSAE, AIC and BIC metrics. The B-AGE algorithm has achieved MSAE values of 8.58e\u20134 which results in a value of \u22126958.77 for AIC and \u22126708.48 for BIC. The AIC and BIC values related to AKS and AFKS are greater than that of B-AGE method which indicates that the B-AGE method has better performance in this experiment. The MSAE value 0f 0.00209 for the AFKS algorithm, results in values of \u22126112.59 and \u22125970.26 for AIC and BIC respectively. Based on the model fitting metrics, the AFKS has achieved slightly better results in relation to the AKS, while the B-AGE is superior to both of them.  Similarly, the approximated curve by B-AGE for   f   2    ( t )  is depicted in Fig.\u00a09 . The original function is shown by solid line in Fig.\u00a09(a), while the dashed line indicates the approximated B-spline curve by B-AGE. In addition to the approximated curve, the knot values are also shown in Fig.\u00a09(b) by triangles. The knot values are linearly scaled in the range of [0,1]. The results of model fitting for the seconds case are denoted in Table\u00a05 , which indicates that the proposed method significantly outperforms both AKFS and AKS methods in the sense of MSAE, AIC and BIC. The B-AGE method has achieved a MSAE value of 1.93e\u20134 which much lower than 0.0161 and 0.0245 as MSAE of AKS and AFKS respectively.  The B-AGE method, in each iteration finds a salient control point and adds a relevant knot value in the knot vector. Therefore, only salient control points are used for B-spline curve estimation and their relevant knot values are stored in the knot vector consequently. This makes the curve estimation more efficient as extra knot values are not stored in the knot vector and only salient control points are present in the B-spline model. The AKS method selects a subset of B-spline basis functions whose linear combination are definitely not B-spline, and tries to approximate the curve. The estimation result cannot be used in CAD/CAE applications as denoted in\u00a0 [46]. In addition, in the AKS method, a knot pruning step shall be performed to reduce the number of required knots. The AKFS method is developed based on the genetic algorithm and requires some parameter tuning in order to apply the curve estimation. Furthermore, this method cannot be employed in many applications, since it is computationally expensive due to the huge amount of least square fittings. In spite of the AKS and AKFS methods, the proposed B-AGE technique, can be employed for construction of a B-spline curve or surface model without extensive fitting processes and limited capabilities in B-spline representation. The approximation process can be performed without an initial estimation and locates the salient control points and their relevant knot values until the AIC is met.  Finally, the performance of the proposed B-AGE method is evaluated under noise. Considering   f   2    ( t )  , a zero mean Gaussian noise with variance \u03c3 = 0.05 is added to the same 101 sample points. It is assumed that the mean and variance of the noise are unknown and no information is given to the B-AGE algorithm. The results of this experiment are shown in Fig.\u00a010 , where it can be seen that the underlying curve is efficiently approximated by the B-AGE algorithm. The M S A E of curve approximation under noise is 6.049e\u20134 while the AIC and BIC have achieved values of \u2212710.45 and \u2212660.76 respectively. Comparing these results with the noise-less experiment where has been reported in Table\u00a05, it can be concluded that the B-AGE method can efficiently approximate underlying smooth functions even under noise.  In this section the experimental results of fitting B-spline surface model to organized point clouds is presented. It is assumed that the input data is captured by a 3D sensor and the B-AGE method as defined in Section\u00a0 4.2 is applied in order to construct a B-spline surface from salient points. The results of B-spline surface fitting from salient points of some organized point clouds are shown in Fig.\u00a011 . After grabbing a point cloud, the bounding box of the input point cloud is found and a B-spline plane is initialized. The B-spline plane is perpendicular to the z -axis and splits the bounding box in half. This step can be considered as setting the sampling rate s  (   \u03c4   \u0304   )    |     \u03c4   \u0304   = 1   = 2 and finding salient points for B-spline surface construction. This process is continued by increasing the sampling rate if the AIC is not met. The salient points are found iteratively by performing the group tests on each row of the organized point cloud. The ISO-parametric curves are constructed by salient points and the B-spline surface model is updated by the lofting technique. The AIC prevents the B-spline model construction process from overfitting by preferring models with lower number of parameters.  In the first experiment, the Shell surface is considered. The point cloud of this surface is generated by evaluating the following equations at 45\u00d755=2475 data points.  (34)  x =   1   5    ( 1 \u2212   v   2 \u03c0   )  cos  ( 2 v )   ( 1 + cos  ( u )  )  +   1   10   cos  ( 2 v )  y =   1   5    ( 1 \u2212   v   2 \u03c0   )  sin  ( 2 v )   ( 1 + cos  ( u )  )  +   1   10   sin  ( 2 v )  z =   v   2 \u03c0   +   1   5    ( 1 \u2212   v   2 \u03c0   )  sin  ( u )   u , v \u2208  [ 0 , 2 \u03c0 ]  .   The experimental result of B-spline surface fitting is shown in Table\u00a06 , comparing to that of\u00a0 [14]. The iteration and optimization technique presented in\u00a0 [14], requires to specify the number of control points manually, while the B-AGE method offers an automatic approach for B-spline surface fitting by proving a trade off between accuracy and model complexity. The approximated surface is shown in Fig.\u00a011(a).  The next experiment is performed on the crescent surface, defined as  (35)  x =  ( 2 + sin  ( 2 \u03c0 u )  sin  ( 2 \u03c0 v )  )  sin  ( 3 \u03c0 v )  y =  ( 2 + sin  ( 2 \u03c0 u )  sin  ( 2 \u03c0 v )  )  cos  ( 3 \u03c0 v )  z = cos  ( 2 \u03c0 u )  sin  ( 2 \u03c0 v )  + 4 v \u2212 2  u , v \u2208  [ 0 , 1 ]  .   The approximated surface is depicted in\u00a0 11(b) and the maximum approximation error is denoted in Table\u00a07 .  In the next experiment, the result of B-spline surface fitting, performed by the B-AGE method, is compared to that of two state-of-the-art methods\u00a0 [10,49]. The results of this experiment are shown in Table\u00a08 , where it can be seen that the proposed method achieves decently better accuracy with a fair number of control points. Furthermore, the final B-spline surface is shown in Fig.\u00a011(c). This experiment is challenging as the B-spline surface model is achieved without any initial surface estimation, while both LSPIA and EPIA algorithms start from a manually created initial surface. This property, makes the B-AGE method applicable in a wide range of CAD/CAE applications.  The final experiment is accomplished using an unorganized point cloud, known as Stanford Bunny. The B-spline surface result is shown in Fig.\u00a011(d). The input point cloud is uniformly sampled to achieve an organized point cloud and then it is treated as a regular organized point cloud. The final B-spline surface is also trimmed to have a better visualization result.   CONCLUSIONS   In this paper, an adaptive group testing based method is developed in order to find salient points of an organized point cloud and construct a B-spline curve or surface. This B-spline Adaptive Group testing Estimator, abbreviately called B-AGE, can be used in a wide variety of CAD/CAE applications. In contrast to most conventional B-spline fitting methods, instead of processing a huge amount of non-informative points, this method finds salient control points for curve or surface model fitting. In order to find the salient points, the input curve is convolved with B-splines of varying scales. The salient points are marked as maximum of convolution result. This is in contrast to widely used dominant points, which is related to points with high curvature. Exploiting distinctive properties of group testing, salient points are derived iteratively by performing group tests. A B-spline curve is derived by least square approximation from salient points. The B-spline model is updated until the AIC is met, which provides a trade off between accuracy and model complexity. It has been shown theoretically that the algorithm complexity of the B-AGE method is lower than some state-of-the-art group testing methods. Furthermore, the applicability of the proposed technique is shown by some experiments in both B-spline curve and surface approximation.   REFERENCES", "highlights": "Point clouds as measurements of 3D sensors have many applications in various fields such as object modeling, environment mapping and surface representation. Storage and processing of raw point clouds is time consuming and computationally expensive. In addition, their high dimensionality shall be considered, which results in the well known curse of dimensionality. Conventional methods either apply reduction or approximation to the captured point clouds in order to make the data processing tractable. B-spline curves and surfaces can effectively represent 2D data points and 3D point clouds for most applications. Since processing all available data for B-spline curve or surface fitting is not efficient, based on the Group Testing theory an algorithm is developed that finds salient points sequentially. The B-spline curve or surface models are updated by adding a new salient point to the fitting process iteratively until the Akaike Information Criterion (AIC) is met. Also, it has been proved that the proposed method finds a unique solution so as what is defined in the group testing theory. From the experimental results the applicability and performance improvement of the proposed method in relation to some state-of-the-art B-spline curve and surface fitting methods, may be concluded."}