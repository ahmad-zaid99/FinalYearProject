{"id": "S001044851500086X", "article": "MAIN-TITLE A gesture-free geometric approach for mid-air expression of design intent in 3D virtual pottery   HIGHLIGHTS          We introduce a geometric approach for mid-air virtual pottery design.      A user can design virtual pots without the need to remember gestures.      The shape of a pot gradually converges to the point-cloud of the user\u2019s hands.      Applications are shown with two depth sensors, Leap Motion and SoftKinetic DepthSense.      User evaluation demonstrates strengths and weaknesses of our approach.          KEYPHRASES   Hand-based shape modeling  Mid-air interactions  Virtual pottery  Gestures  Natural user interfaces  Mesh deformation   Mid-air interactions have received significant attention in the context of 3D shape conceptualization. These interaction approaches offer intuitive and direct manipulation of virtual shapes by using free hand movements. The core challenge in mid-air interactions for computer-aided design (CAD) is to map user input to virtual operations, such that the user can directly focus on the design task rather than spending time in learning the tool itself. Three-dimensional user input has been extensively studied, evaluated, and reviewed\u00a0 [1\u20134] in the context of 3D selection, manipulation\u00a0 [5], control, and navigation, in virtual environments. Mid-air interactions have found significant use in gaming\u00a0 [6] and art\u00a0 [7\u20139]. Within the context of 3D conceptual shape design, we find two broad classes of mechanisms that enable mid-air user input.  The first class comprises of instrumented controllers such as gloves\u00a0 [10\u201312], hand-held trackers\u00a0 [13,14], and haptics devices\u00a0 [15\u201317]. Special devices and setups\u00a0 [18\u201323] have also been demonstrated for 3D interactions. These hardware systems offer great control, feedback, and unambiguity to the user while interacting in mid-air. In these approaches, the user provides explicit commands via the hand-worn or hand-held controller to indicate design intent such as starting, stopping, or selecting a modeling operation when desired. However, such systems are not accessible to the common user outside a lab environment. Further, wearing or holding can be intrusive to the user during a focused modeling task.  The second class of mechanisms for mid-air user input are the so-called bare-hand gesture-based interactions\u00a0 [24\u201331]. With the recent commercialization of depth cameras, gesture-based interactions have become accessible to the common user. Creative applications for free-form shape modeling\u00a0 [32] in mid-air have gained significant popularity. The user input in these applications is represented as a combination of a hand posture (such as pointing with a finger) and the motion of a representative point (such as the palm or fingertip) on the hand. We call this the symbolic gesture approach. Here, converting user input into a meaningful shape modeling task involves (a) acquisition, segmentation, and processing of hand data, (b) extracting a virtual representation of the hand, (c) mapping the gestures to a shape modeling task, and (d) generating an appropriate response of the shape as intended by the user\u2019s input. Such approaches involve estimation of the skeletal structure of the hand\u00a0 [33\u201335] or classification of the hand\u2019s image as a pre-defined posture\u00a0 [36]. In this work, we aim to utilize the non-intrusiveness and accessibility of camera-based mid-air interactions for 3D shape deformation.  Both classes of mid-air interactions (instrumented controllers and bare-hand gestures) have one common characteristic, namely, there is a clear distinction between interaction and geometric modeling. In this work, we take a different approach; we pose mid-air interaction itself as a geometric problem. Our focus is the geometric investigation of spatial interactions in the specific context of shape deformation. Particularly, we address the problem of determining how the shape and motion of a user\u2019s hand and fingers geometrically relates to the user\u2019s intent of deforming a shape.   MOTIVATION   Consider a mid-air interaction scenario of selecting and displacing a mesh vertex for deforming the mesh. Unlike a controller-based approach, there is no explicit physical mechanism for triggering events. Here, gestures serve two fundamental purposes. First, they help define a beginning (e.g.\u00a0reaching and clutching some region of interest) and end (e.g.\u00a0de-clutching the region after required deformation) of an interaction\u00a0 [37,38]. Second, they help define the exact operation from a set of operations defined in the context of an application. For example, the type of deformation could be selected by using different gestures (e.g.\u00a0fist to pull, point to push, open palm to flatten). There are two issues with this approach. First, gesture-based interactions rely heavily on (a) the robustness of gesture recognition to hand occlusions and (b) stability of recognized gestures over time. In our previous work\u00a0 [30], we observed that even slight instability in the accuracy of gesture recognition can disrupt the modeling process leading to user frustration. Second, predefined gestures impose rigid constraints on users. Having to learn too many gestures is memory-intensive in a creative activity, but too few gestures can result in ambiguity while expressing design intent.  Hand and finger movements in real-world shaping processes (such as pottery or clay sculpting) are complex, iterative, and gradual. Such processes are essentially governed by the geometry of contact between hand and clay. Works by Sheng et\u00a0al.\u00a0 [19], Kry et\u00a0al.\u00a0 [20], and Pihuit et\u00a0al.\u00a0 [21] have leveraged finer finger level movements and grasping for 3D shape deformation by designing ingenious hardware systems. In their systems, users can actually grasp and deform virtual objects. However, for marker-less camera-based systems, the true expressive potential of finger movements remains underutilized despite advances in hand pose and skeleton estimation. We aim to determine user\u2019s intent from fine finger-level movements while retaining the non-intrusiveness and accessibility of depth cameras. In doing so, we demonstrate that it is unnecessary to prescribe shape modeling interactions with a predefined set of rules using classified hand gestures or full-scale hand skeletons.  There are two factors that demand critical attention while designing mid-air interactions, particularly for shape modeling. These are intent and controllability. The general term intent is literally defined as \u201cthe thing that you plan to do or achieve: an aim or purpose\u201d. In our case, intent (what one wants to achieve) can be described in terms of the context of shape deformation (what operations one can perform on the shape). On the other hand, controllability can be viewed as the quality of intent recognition and disambiguation as perceived by the user. In general, we find that the prior works in mid-air shape modeling primarily focus on the development of a feature-rich geometric modeling system. However, there is currently no literature that studies problems of intent and controllability in mid-air interactions for shaping operations such as deformation. Our broader aim in this paper is to study these critical aspects of mid-air shape deformation.  Considering intent and controllability as our central themes, we have two specific goals in this paper. First, we seek a concrete geometric method that takes a general representation of the user\u2019s hand (PCL) and allows the user to deform 3D geometry. Second, we want to investigate this geometric method in light of intent and controllability. Thus, our focus here is not to build a comprehensive and feature-rich 3D modeling system. Instead, we intend to investigate spatial interactions for 3D shape deformation with a raw representation of the hand.  Considering a full-fledged 3D modeling system makes it prohibitively complicated to rigorously study the aspects of the interaction. There are two basic components to our problem\u2014the representation of the deforming shape and that of the user\u2019s hand (PCL in our case). In a typical shape deformation scenario, an arbitrary triangle mesh is the ideal and generic shape representation. The use of an arbitrary mesh makes it prohibitively challenging to perform a controlled study of the geometry of interactions. There are two reasons for this. First, the hand PCL data obtained from a single depth sensor is partial (due to occlusions) and noisy. Second, we want the user to approach a 3D shape from any direction and grasp it in any way. In this case, the user\u2019s dynamic and complex finger motions further add complexity to the occlusions and noise. Subsequently, designing interaction tasks for a quantitative evaluation is difficult, particularly for users with no prior experience with mid-air interactions for free-form 3D modeling. Hence, it is essential to constrain the geometric representation of the object being modified.  To cater to our goal of investigating mid-air deformation, we chose the example of virtual pottery. Our choice of pottery offers a well-defined and intuitive relationship between the use of hands and the shaping of pots to a user. The simplicity of the geometric representation and deformation in pottery lends itself to quantitative measurement of the user\u2019s response to our system (Section\u00a0 6.3). Our concrete and practical implementation enabled us to study how hand and finger motions can allow users to deform a shape as they see fit (Section\u00a0 6.4.3). We note that virtual pottery using direct hand manipulations is a niche area within the hand-based modeling paradigm\u00a0 [10,17,22,39,25,28,29]. We do not aim at contributing towards pottery itself, but using pottery to reveal the research questions pertaining to the geometry of spatial interactions.  Our basic idea is to progressively conform the shape of a pot (represented as a 3D mesh) to that of the user\u2019s hand. This idea, dubbed proximal persistence, is a generalization of the notion of dwell-time used in 3D object selection\u00a0 [40]. Our algorithm is a combination of exponential smoothing and selective Laplacian smoothing (Fig.\u00a01 ). Here, each point in the hand\u2019s PCL attracts a local region on the pot, hence deforming the pot\u2019s section. The combination of many such local deformations, due to each point on the hand, amounts to a progressive convergence of the pot-profile to the shape of the user\u2019s hands. We found two approaches that appear similar to our method in terms of the representation of the hand and the idea of persistence-based deformation.  The first approach is Data miming \u00a0 [27] wherein the hand is modeled as a set of active voxels in a volumetric domain. Thus, this approach uses hands without explicit determination of gestures for recognizing user intent, as in our case. Our method, however, is inherently different from this approach in two ways. First, Data miming focuses on the specification existing objects through the user\u2019s hand motions rather than creating new shapes through shape deformation. Second, it differentiates the relevant voxels from the irrelevant ones by imposing a threshold on the number of times the user\u2019s hand visit each voxel. Our method does not require any threshold or statistic to distinguish intentional actions from unintentional ones. Instead, we use the rate of attraction as our parameter to determine when and how much to deform a surface (Section\u00a0 2.3). We also provide an explicit relationship between our parameters and the responsiveness of shape deformation (Section\u00a0 3). We determined appropriate parameter values of our algorithm through our pilot experiments. Such a study was not the focus of the Data miming approach.  The magnet tool demonstrated by Schkolne et\u00a0al.\u00a0 [11] captures the idea of persistence. It is a custom made hardware addendum that allows a user to change a region of surface locally by waving the hand close to the surface while holding the tool. This tool, as mentioned by the authors, enables an overdrawing metaphor for surface deformation. In our case, the input is dynamic and unstructured data (the PCL of the user\u2019s hand) and there is no explicit user expression (such as waving) that triggers the deformation of a shape. Further, our method is capable of both local and global changes to the shape depending on how the user makes contact with the surface of the shape.  We make two main contributions. First we demonstrate, with a practical implementation, that it is possible to achieve controllability in bare-hand mid-air shape deformation using unstructured PCL data of the user\u2019s hand. We describe a method that does not compute any finite set of gestures or hand skeleton. Instead, our method uses the actual shape of the user\u2019s hands for deforming the shape of a pot in 3D space. This directly allows a user to shape pots by using physical objects as tools.  Second, we show a detailed user evaluation to understand user behavior and perception in pottery design. Our evaluations help reveal two core aspects of mid-air interactions for shape deformation, namely, intent and controllability. We characterize user behavior in pottery design in terms of (a) common hand and finger movement patterns for creating common geometric features, (b) user perception of intent, and (c) engagement, utility, and ease of learning provided by our approach.  Proximal persistence can be described as a spatio-temporal model according to which a \u2018modifiable object\u2019 in space deforms when in close proximity to a \u2018modifying object\u2019. Deformation occurs over a length of time, until the shape of the modifiable object matches the profile of the modifying object. In our case, the modifiable object is the surface of a virtual pot, the modifying operation is deformation, and the modifying object is a point-sampled surface of a hand or a hand-held tool. Thus, the idea is to define the modeling process of a 3D shape as a time-series of its deformed states converging, so as to conform to the shape of the hand or the tool (Fig.\u00a01).  To provide a realistic and enjoyable experience of pottery, there are four considerations which drive our modeling technique. These are: (a) smooth appearance, (b) behavioral realism, (c) intuitive interactions, and (d) the possibility of using real-world and virtual objects as tools for pot creation. We will first define the required components of the technique and describe a general strategy for the deformation of pots. Our strategy is based on Laplacian smoothing which has been extensively used in the literature (see\u00a0 [41] for a detailed review).  We describe a pot   P   \u0303    ( h , r  ( h )  )  , as a simple homogeneous generalized cylinder (SHGC) containing a set of circular sections at heights   h   \u0303   \u2208  [   h   1   ,   h   2   ]    (   h   1   ,   h   2   \u2208 R )  whose radii are defined by a smooth function   r   \u0303   : R \u2192 R applied to the closed and connected interval  [   h   1   ,   h   2   ]  \u2208 R . Thus, the function   r   \u0303    (   h   \u0303   )  can also be interpreted as the profile curve of the pot. In a discrete setting, a pot is given by:  (1)    P   n , m   \u2254  {  (   h   i   ,   r   i   )  \u2223   r   i   = r  (   h   i   )  ,   h   1   < \u2026 <   h   n   \u2208 R }  .      The surface S  (   P   n , m   )  of the pot is defined as a vertical sequence of n circular sections   C   i   of radii   r   i   at heights   h   i   . In a discrete setting, a circular section is approximated by a closed regular polygon with m sides (2) thus allowing for a simple quad-mesh representation.   (2)    C   i   =    [    v    i , 1   , \u2026 ,    v    i , m   ]    T          v    i , j   =    [ \u2212   r   i   sin  (   2 j \u03c0   n   )  ,   h   i   , \u2212   r   i   cos  (   2 i \u03c0   n   )  ]    T   .       A manipulator is defined as a point denoted by \u03bc  ( t ,  p  )  , where t is the time stamp and  p  \u2208   R   3   is the position of the manipulator. The manipulating object (user\u2019s hand or a hand-held tool) can thus be represented as a point cloud (PCL) given by M  ( t )  =  { \u03bc  ( t ,  p  )  }  where each point is a manipulator. A handle,  q   ( t )  =    v    i , j   \u2208 V ( 1 \u2264 i \u2264 n and 1 \u2264 j \u2264 m ), is defined as the vertex on the pot which is closest to the manipulator in euclidean space. We define a convergence threshold    \u03b5   C   as the distance between a handle and its manipulator at which the handle is considered to be coincident with the manipulator. Finally, we define a proximity threshold as the maximum distance,   \u03b5   P   , at which a manipulator should be from a handle in order for a deformation to occur. Making use of the structured topology of the pot mesh, we compute the handle for a given hand by first computing the index of nearest section and subsequently the point closest to the hand on the nearest section. Thus, the handle  q  at an instance t , is given by:   (3)   q   ( t )  =    v    i , j       i =   arg min   i    (   h   i   \u2212   p   y    ( t )  )      j =   arg min   j    (  \u2016    v    i , j   \u2212  p   ( t )  \u2016  )  .    Here,  \u2016 \u22c5 \u2016  is the Euclidean distance defined in   R   3   . Further, i gives the index of the cross-section closest to the manipulator. It is clear that the relationship between a manipulator and its corresponding handle is that of proximity, the first component of proximal persistence.  In real world pottery, deformations due to the potter\u2019s hands are either local or global based on the extent of the profile region in contact with the potter\u2019s hands or the tools held in the hands. The smoothness of deformation is an essential constraint as well. Consider the hand as a set of points in 3D space. Each point in the PCL deformed a small local region on the pot using the proximal persistence approach. On the whole this amounts to a gradual and progressive convergence of the pot-profile to the shape of the user\u2019s hand. We achieve this convergence by using the idea of selective Laplacian smoothing. This method performs local or global deformation of the profile based on the distribution of the manipulators on the profile. For manipulators within a small region of the profile, the deformation is local. If the manipulators cover a broader span of the profile, the deformation is global.  Given the profile function r  ( h )  , the problem of deforming the surface of a pot is essentially transformed to that of deforming the profile curve. For a curve   \u03b3   \u0303    ( u )  \u2208   R   3     ( u \u2208  [ 0 , 1 ]  )  , deformation on   \u03b3   \u0303   can be defined as a curve   \u03b4   \u0303    ( u )  such that   \u03b4   \u0303   :   \u03b3   \u0303   \u2192  (   \u03b3   \u0303   +   \u03b4   \u0303   )   ( u )  . Our goal is to determine a deformation   \u03b4   \u0303    ( u )  which satisfies Laplace equation (   \u2207   2     \u03b4   \u0303   = 0 ).  With seed displacements defined on selected vertices of the profile, we compute a smooth deformation and apply it to the profile (see Fig.\u00a02 ). Let \u03b3 \u2254  {  (   h   i   ,   r   i   )  }  be the discrete profile curve as given in (1) and K \u2282  [ 1 , n ]  define a set of selected vertices in \u03b3 . Given a set of seed displacements on the vertices in K , our goal is to determine the displacement of all other vertices so as to preserve the smoothness of \u03b3 . To achieve this, we first initialize a seed displacement curve \u03b4 (such that   \u03b4   i   = 0  \u2200 i \u2209 K ) and iteratively apply discrete Laplacian smoothing, L  ( \u03b4 )  = 0 , (4) with Neumann boundary conditions. The deformed profile is then obtained by setting   r   i   \u2190   r   i   +   \u03b4   i   ,  \u2200 i . The derivatives at the boundary are set to zero, i.e., the radii at the boundary sections of the pot are the same as the radii at their neighboring sections. We use inverse edge weights to determine the non-diagonal elements of L  (5).   (4)    L   i , j   =  {    \u2212 1 ,   | i \u2212 j |  = 0     1 ,   | i \u2212 j |  = 0 ,  i \u2208  { 1 , n }        w   i , j   ,   | i \u2212 j |  = 1 ,  i \u2209  { 1 , n }      0 ,  otherwise        (5)    w   i , j   =     l   j       \u2211   k \u2208 K     l   k         K =  { k :  | i \u2212 k |  = 1 }  .       In order to deform the profile in a smooth manner, we begin by defining W to be a set of all contiguous subsets in  [ 1 , n ]  . Note that a single section i \u2208  [ 1 , n ]  and the whole set  [ 1 , n ]  trivially belong to W . Subsequently, we define a mapping \u03b1 : W \u2192 W as given in (6). Given a section i , it is clear that \u03b1  ( i )  determines the window of sections above and below the section i , which are subject to Laplacian smoothing (Fig.\u00a03 ).   (6)  \u03b1 :  { i \u2026 j }  \u21a6  { max  ( 1 , i \u2212 \u03b1 )  \u2026 min  ( n , j + \u03b1 )  }      \u03b1 \u2208 N     i , j \u2208  [ 1 , n ]  .       Thus, for a given seed displacement  \u03b4   ( t )  , the deformation of the profile can be controlled using parameters, namely the window operator \u03b1 and a parameter \u03b2 \u2208 N specifying the number of iterations for Laplacian smoothing. Note that a single point manipulator will instantiate a smooth but local deformation as should be expected in a typical real-world scenario\u2014a thin tool creates a thin impression. However, we aim to allow for both global and local deformations. In our case, note that a manipulating object is a point-sampled surface. Thus, global deformations naturally occur due to the combination of window operators for spatially proximal manipulators.  We define persistence as a continuous temporal response of the pot profile to the proximity of a given manipulator. The main step towards the definition of persistence is one involving initializing the seed displacement. For a discrete pot profile curve \u03b3 and a handle i , the idea is to attract a handle towards its corresponding manipulator by a fraction of distance between them (Fig.\u00a04 ). Our idea is inspired by exponential smoothing\u00a0 [42]. Given a parameter \u03bb \u2208  [ 0 , 1 ]  , we converge the handle towards the manipulator over time in a smooth manner (Fig.\u00a05 ). Note that this parameter, when constant, is analogous to the smoothing constant in single exponential smoothing. Similarly, a temporally varying parameter \u03bb = \u03bb  ( t )  \u2208  [ 0 , 1 ]  is analogous to adaptive exponential smoothing. We call \u03bb the persistence parameter.  Generally, a deformation to any given shape can either be inward (push) or outward (pull). The exact characterization of the deformation (shape, size, and location) is subject to the type of contact that is maintained on the deforming object. Along similar lines, our modeling technique has three general responses to a user input, namely push, pull, and no response. The goal is to recognize which of these represents the response to the actual intent of the user without asking the user to remember any prescribed rule (for instance, a button press or a static hand gesture). Note that the recognition of intent for \u201cno response\u201d is important, since it represents the robustness to accidental user input in cases when the user wishes to take rest or explore other features in a given modeling interface.  A push is characterized by an inward displacement i.e. when     \u03b4   \u02c6     i   H   < 0 . This is the simplest case wherein a user would typically approach the pot and subsequently recede away once the desired deformation has occurred. A pull is characterized by an outward displacement i.e.\u00a0when     \u03b4   \u02c6     i   H   > 0 . This is a non-trivial intent to recognize since a user would invariably approach the surface first and then recede to pull. The overall motion of the hand is similar to that of a push. However, unlike a push, a pulling action typically involves the articulation of hands so as to grasp the surface that is being deformed. In order to account for grasping actions in pulling tasks, we defined the persistence parameter as a smooth function given by   \u03bb   P     e   \u2212 A    (     \u03b4   \u02c6     i   N   )    2     (Fig.\u00a07). Here, A defines the rate of decrease of the function with respect to     \u03b4   \u02c6     i   H   and     \u03b4   \u02c6     i   N   is the normalized horizontal distance of a manipulator from a given section of the pot, given by:   (7)      \u03b4   \u02c6     i   N   =       \u03b4   \u02c6     i   H         \u03b4   \u02c6      max    H   \u2212     \u03b4   \u02c6      min    H         \u2200 i  such\u00a0that:     \u03b4   \u02c6     i   H   > 0 .       Our initial experiments showed that the normalization of     \u03b4   \u02c6     i   H   allowed us to standardize the design of bandwidth A . Also,   \u03bb   P   is the maximum rate of pulling (for     \u03b4   \u02c6     i   H   = 0 ).  Periods of rest, reflection, and accidental hand movements can sometimes lead to unintended deformations. We propose a temporal approach for avoiding accidental or unintended deformation of the pot by allowing for the pot to deform only when contact with the pot is maintained for a sufficient amount of time. We employ adaptive exponential smoothing to achieve this wherein we vary the persistence parameter \u03bb according to a monotonically increasing function of time with a bounded range, i.e.\u00a0a fixed duration of time T . Note that the same approach is also applicable to   \u03bb   P   . In this work, we implemented a linear function to determine \u03bb as follows:  (8)  \u03bb  ( t )  = max  (   t \u2212   T   0     T     \u03bb   \u0303   ,   \u03bb   \u0303   )  .      Here,   \u03bb   \u0303   and     \u03bb   \u0303     P   represent pre-defined maximum values of the persistence parameters for push and pull respectively; T represents a pre-defined duration of time taken for \u03bb to vary from 0 to   \u03bb   \u0303   from the starting time   T   0   . The idea is to reset \u03bb for every initial contact made with the pot and linearly increase it to a maximum prescribed value within a stipulated duration of time.  Given a handle   v   i , j   \u2208   C   i   and its corresponding manipulator \u03bc  ( t ,  p  )  , the application of persistence translates to defining the increase or decrease in the radius of   C   i   such that   v   i , j   converges to the \u03bc  ( t ,  p  )  (Fig.\u00a06 ).  The rate at which this convergence takes place is decided by the parameter \u03bb as represented by the following equation:   (9)    v   i , j   \u2190 \u03bb   v   i , j   +  ( 1 \u2212 \u03bb )   (     \u03b4   \u02c6     i   H      b    i , j   )          \u03b4   \u02c6     i   H   =  |  \u3008    b    i , j   ,  p  \u2212    v    i , j   \u3009  |         b    i , j   =    [ \u2212 sin  (   2 j \u03c0   n   )  , 0 , \u2212 cos  (   2 i \u03c0   n   )  ]    T   .       Using (9), the seed displacement and the corresponding section transformation are given by Eq. (10). Note that     \u03b4   \u02c6     i   H   is a signed displacement and can take both positive and negative values for outward (pull) and inward (push) displacements respectively.   (10)    C   i   \u2190  (     r   i   +   \u03b4   i   H       r   i     )    C   i         \u03b4   i   H   = \u03bb     \u03b4   \u02c6     i   H   .       The controllability of our deformation method is affected by two factors: (a) the disparity between what a user intends for the shape to be and what the shape actually becomes after the deformation, and (b) the responsiveness of the deformation. The goal is to minimize the disparity and optimize the responsiveness. Here we investigate parameters which affect the deformation behavior and responsiveness of the interaction as described below.  We can define proximal persistence by the set of parameters as P  (   \u03b5   C   ,   \u03b5   P   ,   \u03bb   \u0303   ,     \u03bb   \u0303     P   , A , \u03bb  ( t )  , T )  wherein the first two parameters characterize proximity and the last three parameters characterize persistence. Combined with \u03b1 and \u03b2 described in Section\u00a0 2.2, we define deformation parameters denoted as D  ( \u03b1 , \u03b2 )  .  From our deformation strategy, it follows that our approach is affected by the density of points in the manipulating object and the resolution of the pot mesh (defined by m and n ). Note that the maximum point density in the manipulating object is dependent on the resolution of the depth camera. Thus, we define the pot resolution such that the hand or tool PCL\u2019s are densely sampled in comparison to the pot. The rationale is that the sparsity of the hand or tool PCL will result in undesired effects when the user intends a global deformation.  The window operator defined by \u03b1 primarily decides how local the deformation will be for a single point manipulating object. Larger values of \u03b1 result in global deformation. This parameter is also a factor in producing global deformations for a manipulating object with several points. The parameter \u03b2 affects responsiveness. Recall that we apply Neumann boundary conditions for Laplacian smoothing of the deformation curve which is an open 1-manifold. Thus, applying the Laplace operator selectively near an internal section (i.e.\u00a0a section not at the profile boundary) for a reasonably large amount of time (i.e.\u00a0increasing \u03b2 sufficiently) would make the deformation converge to zero making the profile non-responsive to any deformation.  These parameters specifically affect the responsiveness of deformation. Assuming \u03bb  ( t )  to be a constant function, the persistence parameters   \u03bb   \u0303   and     \u03bb   \u0303     P   are directly proportional to responsiveness. The parameter A defines the bandwidth of the exponential function for pulling. Lower values of A will distribute the rate of pull along the profile while higher values will lead to localized pulling at the points of contact on the pot. Low values of the proximity threshold   \u03b5   P   require precision from the user while deforming the pot. Higher values require the user to recede from the pot at higher speed once a desired deformation has been achieved. The value for   \u03b5   P   is decided based on the geometric properties of the modeling scene, the size of the pot and size of the hand. Finally, the parameter T signifies the amount of time required for the pot deformation to vary from being completely non-responsive to optimally responsive. Higher values of T would require the user to maintain contact for a longer time, thus making the deformation under-responsive.   IMPLEMENTATION   We explore our approach with two depth sensors to obtain such an input, as described below.  Our system setup consists of a ThinkPad T530 laptop computer with Dual Core CPU 2.5\u00a0GHz and 8\u00a0GB RAM, running 64 bit Windows 7 Professional with a NVIDIA NVS 5400M graphics card, a depth sensor (such as a SoftKinetic DS325 sensor or a Leap Motion Controller). The placement of the depth sensor varies according to needs (Fig.\u00a08 ). Our applications were developed in C++\u00a0and openGL with the openGL Shading Language (GLSL). We implemented two instances of our pottery application using the two different depth sensors, namely Leap Motion controller and SoftKinetic DS325 sensor.  SoftKinetic DS325 is a close range (0.1\u00a0m\u20131.5\u00a0m) time-of-flight depth sensor that provides a live video stream of the color and depth image of the scene. Every pixel on a given depth image can be converted to a 3D point using the camera parameters. We use the DepthSense\u2122\u00a0SDK to obtain the depth-map of the scene. Our first step was to segment the hand from the scene based on a depth threshold. We then convert the segmented depth map to the PCL of the hand using the camera parameters. This is akin to using a pre-defined a volumetric workspace as the active region in front of the computer screen.  Since the main data provided by the sensor is a depth map, several image processing algorithms can be applied to extract skeletal and boundary points as we will demonstrate in future sections (see Fig.\u00a09 ). Leap Motion provides a skeletal representation of the hand comprised of the palm and fingers. We used this device to implement virtual tools, with each tool defined by a prescribed set of manipulators. We used the palm position and orientation, provided by the Leap SDK, for tool manipulation.  Our interface comprises of an integrated 3D scene with a rotating pottery wheel, a set of shaping tools overlaid on natural outdoor background. In our pottery application, we combine three spatial interactions, namely, (a) 3D environment navigation though interaction space partitioning and 3D camera transitions, (b) robust tool selection using cylindrical zoning, and (c) gesture-free shaping interactions using proximal persistence. The interfaces for the two depth sensors, are similar in appearance. However, we designed additional interactions for tool selection for our Leap motion version.  We partitioned the 3D scene into three distinct interaction spaces for unambiguous interactions (Fig.\u00a010 ). Each of these partitions, when active, map to the interaction space of the Leap Motion device. This allows for precise hand-motions in real space and constrains the user\u2019s focus to the active area. The user can freely transition between the spatial partitions by moving towards the right or left extremities of the Leap motion device. The potter\u2019s wheel partition is the main workspace wherein a user can shape the pot by modifying the lump of clay into a pot. The right and the left partitions represent the shaping and decoration tools respectively.  The interface for SoftKinetic is simpler in that we did not need to use any tool selection interactions. Thus, this interface consists of the whole 3D scene without any spatial partitions. The user sees only the potter\u2019s wheel and a PCL representation of their hands, or the tools held in their hands.   RESULTS   In this section, we will discuss and demonstrate three use cases for our approach, namely (a) hand, (b) physical tools, and (c) virtual tools. For the first two cases, we further explore multiple modes of sampling such as (i) full PCL, (ii) boundary PCL, and (iii) skeletal PCL. Based on the designed interaction space, we fixed the pot to be 0.6 units in length with radius in the range  [ 0.1875 , 0.3125 ]  . Further, we fixed the resolution of the pot by assigning m = 314 and n = 100 , i.e.\u00a0the difference in height between each section is set to 6\u00d710\u22124 units. After spatial mapping and PCL scaling, the average distance between two neighboring points in the PCL were observed to be 2 \u00d7 1   0   \u2212 3   , 4 \u00d7 1   0   \u2212 4   , and 1.5\u00d710\u22123 units along x , y , and z directions respectively. The deformation thresholds were set as   \u03b5   C   = 1   0   \u2212 8      \u03b5   P   = 0.1 . Our deformation parameters D  ( \u03b1 , \u03b2 )  were set to D  ( 5 , 50 )  . This is based on experiments we conducted for the chosen pot resolution.  The proximal persistence approach involves several parameters (Section\u00a0 3) which must be appropriately determined in order to design controllable interactions with our interface. Thus, our first step was to study the effect of persistence parameters (   \u03bb   \u0303   ,     \u03bb   \u0303     P   , A , and T ) on the intuitiveness and responsiveness of the pot deformation process. We note that effect of these parameters are not independent. Thus, an exhaustive study of all combinations is prohibitively difficult. We conducted an informal pilot study where participants used our system with six set of parameter combinations. Here, the ranges of parameters were:  \u2022   0.1 \u2264   \u03bb   \u0303   \u2264 0.4 .    0.1 \u2264     \u03bb   \u0303     P   \u2264 0.4 .    A \u2208  { 0.5 , 1.0 , 1.5 , 2.0 , 2.5 }  .    T \u2208  { 0.5 , 1.0 , 1.5 , 2.0 , 2.5 }  .  The general trend we observed is that     \u03bb   \u0303     P   >   \u03bb   \u0303   and A < 2.0 resulted in uncontrollable pulls. We also found that despite sufficient responsiveness, the deformations were unstable for T < 1.5   s  , in that they alternated between inward and outward directions. We believe this to be a consequence of the Laplacian smoothing parameter \u03b2 . Our final parameters provided by user\u2019s feedback were   \u03bb   \u0303   = 0.3 ,     \u03bb   \u0303     P   = 0.1 , A = 2.0 , and T \u2208 1.5 . These values worked well for boundary and skeletal PCL of the hand (Fig.\u00a011 ). Use of physical tools proved to be more stable in comparison to the hand (Fig.\u00a012 ). This, we believe, can be attributed to the highly articulated nature of hand-based manipulations in comparison to the relatively rigid PCL obtained from the tools.  Based on parameters determined from our experiments, we implemented virtual tools using the Leap Motion (Fig.\u00a013 ). In this case, we constrained the deformations to be purely inward. This was a design decision considering the typical use of tools in real world pottery. We implemented a smoothing tool wherein we did not associate any PCL with the tool. This tool simply applies the Laplace operator on the profile of the pot itself. The use of virtual tools lends itself to rapid conceptualization of several shapes. To demonstrate this, we created a virtual chess set (Fig.\u00a014 ) where each piece was created in less than 1\u00a0min, taking a total time of approximately 6\u00a0min to create all the pieces.  The main cause of computational bottleneck is the need to determine handles corresponding to each manipulator. This can be a major cause of disruption and dissatisfaction for users. For arbitrary meshes, the typical solutions in such a case would be to use spatial hashing or the GPU. In our case, however, the SHGC representation of the pot eliminates the need to use any such special method. For a pot mesh S  (   P   n , m   )  , the worst case complexity to determine handles for k manipulators is O  ( k  ( n + m )  )  . This is attributed to the fact that the computation of a handle    v    i , j   is sequentialized in first finding the closest section (i.e. i ) based on only the heights of the manipulators and sections, and then finding the closest vertex per section (i.e. j ). We experimented with different pot and hand PCL resolutions and found that the total time taken for a pot with 314\u00d7100 vertices deformed by a hand with 3524 manipulators was about 17\u00a0ms. Increasing the pot resolution to 470\u00d7150 vertices resulted in a total time of 29\u00a0ms for 3142 manipulators on the hand (see Table\u00a01 ). Given that the average frame-rate for SoftKinetic is 60\u00a0Hz, our computational efficiency is well within the required range for an interactive design application.  In this work, we intended to enable an interaction paradigm of: \u201cwhat you do is what you get\u201d. Thus, the main motivation behind our user evaluation was to understand the relationship between the design outcome (\u201cwhat users want in the end\u201d) and design process (\u201chow they want to get there\u201d). In order to understand how users perceive and perform mid-air shape deformations, we conducted a lab experiment with our hand PCL implementation using the SoftKinetic camera (Section\u00a0 5.1). Our primary goals in this evaluation were: (a) to observe common and uncommon user patterns during the shaping process in terms of hand grasp and (b) to get user\u2019s feedback on the effectiveness of controllability. To cater to these goals, we performed an observational and user perception analysis. In order to support our observations and findings, we first wanted to characterize how well and how fast users could create basic shape features using our proposed algorithm. To assess the quality of shapes created by the users in relation to the time taken for creating the shapes, we utilized an approach based on curvature cross-correlation. Below, we describe our evaluation in detail.  We recruited 15 (13 male, 2 female) science and engineering graduate students within the age range of 20\u201327 years. 5 participants had familiarity with mid-air gestures and full body interactions through games (Kinect, Wii), and 12 participants reported familiarity with 3D modeling and computer-aided design. 3 participants had amateur experience with ceramics and pottery.   PROCEDURE   The length of the study varied between 45 and 90\u00a0min. In the beginning of the study, each participant was given a verbal description of the setup, the purpose of the study, and functionality of the pottery application. We also recorded participants background regarding their familiarity with depth cameras, full-body games, and pottery. This was followed by a practical demonstration of how to use the application. The participants were then asked to perform the following tasks:   P   Practice: Each participant used our application for 3\u00a0min to get an overall familiarity with the interaction of their hands with the pot surface. During this phase, the participants were allowed to ask questions and were provided guidance when required.   Quiz: The participant was shown a pre-defined target shape and asked to shape a \u201cblank\u201d pot so as to roughly match the most noticeable feature of the pre-defined shape. A total of eight target shapes were shown in a random order (Fig.\u00a015 ). Each target shape corresponds to a specific size (thin, fat) and location of a set of main geometric features (convex, concave, flat, round). The participants were allowed to undo and redo a particular deformation at any time using keyboard shortcuts. The participant could also reset the current shape to the blank pot. Once the participant was satisfied with the result, they would move to the next pre-defined pot shape.   Questionnaire\u00a01: The participants were asked a series of questions regarding the intuitiveness, quality of intent recognition, responsiveness of the deformation and consistency of pushing and pulling during the quiz.   Composition: The participants were given a duration of 5\u00a0min during which they were asked to think of certain specific pot shapes and shape them using their hands. They were asked to describe what they intended to make before beginning their creation. Although the duration of time was fixed, the users were allowed to complete their last composition that was started before the end of the specified duration.   Questionnaire\u00a02: Finally, each participant was asked a series of questions regarding enjoyability, ease of use, and learning. We also recorded specific comments about what they liked and disliked about the application, interface, and interaction.  The main aspect that we sought from the Quiz was the quality of the final outcome across participants for a given quiz problem. We also wanted to understand what features were difficult for the users to create, i.e.\u00a0a comparison of the final outcomes across features. Thus, we sought to compare experimentally observed (user created) pot profiles with respect to the target shapes (quiz problems). The requirements for our metric were: (a) invariance to the shift between the features of the profiles along vertical and horizontal directions and (b) sensitivity to capture small local dissimilarities across users. Thus, we used curvature cross-correlation as a measure to compare the quality of user created profiles. We first compute the curvature signature of an observed profile wherein each point on the signature is the curvature of a point in the profile (Fig.\u00a016 (a)). Subsequently, we compute the normalized cross-correlation\u00a0 [43] between the curvature signatures of the observation with that of the ground truth (Fig.\u00a016(b)). The quality is then defined as the maximum value of the correlation (Fig.\u00a016(c)). Since the signatures are normalized before cross-correlation, the value of the measure of quality is in the range  [ 0 , 1 ]  . Here, higher values represent better quality (1 corresponding to perfect match and 0 no match).  Each user perceived and approached a given target shape; there was no observable correlation between the time taken by each user and the quality (curvature cross-correlation) of the final pot created by the user for any of the target shapes. Hence, we chose to represent the user performance as a bag-plot\u00a0 [44] (Fig.\u00a017 ), where the time taken and the response quality are considered as independent variables. Rousseeuw et\u00a0al.\u00a0 [44] state: Like the univariate boxplot, the bagplot also visualizes several characteristics of the data: its location (the depth median), spread (the size of the bag), correlation (the orientation of the bag), skewness (the shape of the bag and the loop), and tails (the points near the boundary of the loop and the outliers). In this section, we will identify notable aspects of user response by looking at the location, spread, and skewness of the bag-plots for each of the quiz questions. In the subsequent sections, our goal will be to report our visual observations of user behavior and usage patterns across the different quiz questions based on the bag-plot observations.  Users performed best for thin-concave and fat-convex targets with Tukey median values of  ( 3.80 , 0.71 )  and  ( 1.90 , 0.69 )  respectively. In particular, the fat-convex case shows a nearly vertical orientation indicating a strong correlation between the time taken and the quality of response. The average time taken by users was highest for round\u2013flat features with significant variation in the quality. As expected, the thin-convex target feature was difficult to shape. This is also shown by the large spread (1.223) and the Tukey median of  ( 0.60 , 3.69 )  . Contrary to our expectation, the top-flat\u2013bottom-round feature (Fig.\u00a015(f)) was most difficult for the users to create, as indicated by the maximum spread (1.573) and lowest Tukey median of  ( 0.42 , 5.17 )  . Similar difficulty was observed in the central flat feature (Fig.\u00a015(h)). The spread was consistently higher for all flat features (bottom row of Fig.\u00a017) indicating that the key problem the users faced was due to the lack of an explicit method for smoothing the surface of the pot. We found that the quality of responses in relation to the completion time are closely linked to how the users perceived correspondingly approached the shaping process. Below, we provide a detailed description of how the measurements of the response quality and time are related to the behavior and strategies of the users for approaching, grasping, and deforming the pots.  Users generally preferred small finger level movements for thin features. For fat and flat features, we observed that the users first formed a grasp according to the amount of deformation required and then moved the whole hand to achieve the feature as expected\u00a0 [45]. Pushing generally required smaller finger movements in comparison to whole hand movements. Most users spent time smoothing and refining the surface of the pot after the general shape had been obtained. The motion of the hand was performed vertically along the surface of the pot (Fig.\u00a018 ). This led to frustration, for two reasons. First, the accidental unintended deformations caused due to the contact of the hands with regions of the pot other than the parts which the users were attempting to refine. Second, although our algorithm allowed for smooth deformations, there was no explicit way for the users to smooth or straighten a region of the pot. Another interesting observation was that most users avoided using the key-board commands for undo, redo, and reset. Instead, they preferred using their hands for reversing an accidental deformation. In some cases, users had to be reminded of the undo, redo, and reset functionalities.  Generally, preferences towards grasping varied across users based on their expectation of the system and subsequent trial and error. However, we observed some common patterns for reaching, grasping, and deforming each target shape (Fig.\u00a018). Typically, while shaping thin-convex features, we observed that most users achieved a general convexity followed by pushing the top and bottom portions in the inward direction. We had assumed that users will create concave features in a single inward action. Interestingly, they first pulled the top and the bottom portions of the pot, and subsequently pushed the central region of the pot (Fig.\u00a019 (a)). Similar was the case with flat\u2013round features (Fig.\u00a019(b)). Many users first pulled out the round feature followed by straightening the flat regions of the pot. One of the most common hand pose that was observed for creating the thin concave feature, was the point pose. Due to the interference of the fingers other than the index finger, this pose limited the depth to which the users could push the surface inwards. Thus, most users resorted to using an open palm. For round features, the most common approach was cupping of the hands in conjunction with vertical movement of the hands.  Users frequently tried using two hands, particularly for round\u2013flat combinations. Some users also changed their manipulating hand from dominant to non-dominant due to arm fatigue as typically expected in focused mid-air interactions. This, however, was problem due to: (a) the limited volume of the workspace, and (b) difficulty of avoiding unintended deformation due to asynchronous motions of two hands. The tendency to approach the pot from the sides was common. Upon asking, the users typically answered\u201d \u201cmy own hand blocks the view of the pot\u201d. Due to difficulty in depth perception, many users inadvertently reached behind the pot\u2019s surface. This caused confusion due to unintended deformations when the user did not expect one, or the lack of response when it was expected.  On an average, users created 5 pots (max: 9, min: 3) within 5.75\u00a0min (std. dev.: 1.00 min). Most users felt that the control of the pot was significantly better during the composition phase. One user stated: \u201cI thought it was easier to learn the software when I was trying to make my own pot not a model one\u201d.  This was expected because of the learning and practice that the users had during the quiz. However, according to the users\u2019 comments, the cause of difficulty in the quiz turned out to be split attention between the target shape and the user\u2019s pot. There were two observations that were common across users. First, almost all users tried making a pot that they perceived to be the most difficult ones to make. Surprisingly, these were the round\u2013flat combinations (Fig.\u00a015(e), (f)), rather than the thin convex one (Fig.\u00a015(a)). Most of the users tried to make pots with large and straight stems, such as in a wine glass or chalice wherein most of their efforts went in smoothing and straightening long vertical regions of the pot. This, in conjunction with their difficulty in the Quiz, strongly indicated the need for an explicit method for recognizing the intent for smoothing or fairing the surface of the pot.   Intent and controllability: In general, users agreed that the pot behaved according to the way the users shaped their hands (Fig.\u00a020 (a)). About 50% of the users perceived the response to be slow while the remaining considered it balanced. In general, we also found a common agreement on the initialization time and robustness to accidental deformation. The most common and expected difficulty that users faced was that of: (a) pulling specific regions of the pot and (b) creating straight/flat features on the top portion of the pot. The key factor responsible was severe difficulty of depth perception. According to a user: \u201cPushing seems easier than pulling. Part of the reason I suspect is the visual feedback. It is easier to determine if my hand starts to touch the pot, while it is not as easy to determine if my hand is still attached with the pottery or leaving it.\u201d Experience: Despite the frustrations with pulling and smoothing, most users enjoyed the non-symbolic aspect of the interaction. According to a user: \u201cI enjoyed the lack of constraints in the design process; free-forming\u201d. Another user commented: \u201cThis is the first time I have seen something like this. The app is very sensitive so that way it gives the user a lot of freedom. i really loved that part\u201d. The main aspects that the users liked were (a) perceived realism of pottery, (b) ease of learning, and (c) the freedom of choosing how to deform the pot (Fig.\u00a020(b)).  In this study, we wanted to evaluate how well our method allows young users to rapidly conceptualize shapes through direct spatial interactions. In order to do so, we wanted to provide the users with a simpler and finite set of deformation tools for pottery. Thus, we used the virtual tools implemented using the Leap Motion controller (Section\u00a0 5.2).  This study was conducted as an informal workshop wherein we invited twelve young participants studying in fourth, fifth, and sixth grades. We introduced our application and demonstrated the interactions. Following this, all participants were asked to create as many pots as possible in a duration of 10\u00a0min as in the pot composition task. Fig.\u00a021 shows the pot concepts brainstormed by each participant during the pot composition task.   DISCUSSION   There is no limitation in the method which restricts a user from manipulating the pot from any direction, as demonstrated in our results. However, we observed that the use of 2D displays is a factor, due to which users tended to use side configurations. We believe that 3D visual feedback would encourage users to access the front and back faces. Further, hand skeleton tracking provided in the Leap API is not sufficiently robust to use in front configurations due to occlusions. Our PCL-based method works for hand configurations where gesture recognition and skeleton tracking will fail.   LIMITATIONS   We see four limitations with our current approach. First, severe occlusion resulting from camera position and hand orientation is a problem particularly for skeleton-based gesture recognition. We partly addressed this challenge using our PCL-based approach which can make use of partial data even when the full hand skeleton is intractable. However, occlusion is an inherent problem in any camera-based method. Investigation of optimal camera position and the use of multiple cameras at strategic locations is important. Second, we provided a method for temporally adaptive persistence. However, this does not take the structure of the hand or the geometry of the physical tool into consideration. For instance, the optimal persistence parameters for the palm may be different from those of the fingers because of the nature of hand articulation. Hence, spatially adaptive estimation of persistence parameters needs further attention. Third, in our current implementation, the definition of window operators is in terms of 2D profile topology, rather than actual distances in real space. Thus, our implementation is dependent on PCL sampling, relative to the mesh resolution of the pot. Independence from the sampling resolution may be achieved with an adaptive approach wherein new sections could be added according to manipulators, or old ones removed based on geometric properties of the pot profile such as curvature. Finally, we observed that our method gives plausible outcomes for different representations of manipulating objects such as full, boundary, and skeletal PCL. The performance and controllability in each of these modalities may differ according to the context and the user\u2019s intent. A method to determine the optimal modality for each modeling task requires further investigation.  Intent disambiguation, user experience, and computational efficiency are affected by the representation of shapes, the modeling technique, and hand representation. Our approach allows for the accommodation of different representations of the hand, ranging from discrete gesture-classes to kinematic hand models. A comparative investigation of different hand representations as well as traditional interactions would provide a comprehensive understanding of controllability of the shaping process. The augmentation of geometric information, such as normals to the PCL, may provide valuable insights on the articulation of hands and allow for determining parameter combinations adaptively based on the motion of the hands. Works by Rosman et\u00a0al.\u00a0 [46,47] provide frameworks for motion segmentation of point clouds and demonstrate specific examples related to hand segmentation were demonstrated. Augmentation of such frameworks with our technique could lead to several novel interaction mechanisms.   CONCLUSIONS   In this paper, we demonstrated that it is possible to tailor a geometric modeling method to suit the needs of controllable spatial interactions that use hands and finger motions for 3D shape modeling. This idea creates new pathways for further research, exploring hand-based shape modeling. It enables the augmentation of users\u2019 existing knowledge of real-world manipulations with new virtual modeling contexts in a \u201cwhat you do is what you get\u201d framework. At its core, proximal persistence is a general notion which can be instantiated in a variety of ways by combining different hand representations with different shape representations and modeling metaphors. It will be interesting to investigate methods which could automatically deduce appropriate hand representations for different modeling metaphors. With upcoming mid-air geometric design applications, achieving simultaneous efficiency, robustness, and controllability is a challenging problem towards enhancing the user\u2019s creative process and outcome. We believe that proximal persistence takes a fundamental step towards problem.   ACKNOWLEDGMENTS   We thank the reviewers for their valuable feedback and comments. This work was supported by the National Science Foundation-AIR Award No. 1312167, the National Science Foundation Award No. 1235232 from CMMI-EDI, the National Science Foundation Award No. 1329979 from CPS:Synergy, and the Donald W. Feddersen Chair Professorship at the School of Mechanical Engineering. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. We thank Dr. Raja Jasti (ZeroUI) for providing valuable suggestions and feedback on our work. We also thank Kevin Lee Jr. (ZeroUI) for the artwork of our pottery interface. Professor Ramani discloses that he is a co-founder of ZeroUI that has licensed related technology.  Supplementary material related to this article can be found online at http://dx.doi.org/10.1016/j.cad.2015.06.006.  The following is the Supplementary material related to this article.  Video S1  This is a narrated video summary comprising of four parts: (a) the basic idea of our approach \u2014 proximal persistence, (b) the algorithm for using proximal persistence for virtual pottery, (c) the description of our hardware setup with two depth cameras, and (d) the results obtained from the user evaluation of our approach.        REFERENCES", "highlights": "Graphical abstract"}