{"id": "S001044851300050X", "article": "MAIN-TITLE Collision free region determination by modified polygonal Boolean operations   HIGHLIGHTS          An algorithm to determine the collision free region is proposed.      The collision free region is a useful tool for cutting and packing problems with irregular items.      Degenerated elements (edges and vertexes) represent local compaction situations.      The collision free regions determines the presence of local compaction for the current item.          KEYPHRASES   Cutting and packing problems  Boolean operations   Cutting and packing problems involving irregular shapes arise in a wide variety of industries, including shipbuilding, garments, sheet metal cutting, plastics and shoe manufacturing. These problems usually consist in placing a number of irregular items into one or more containers in such way that the layout is the most efficient possible; all items are assigned and do not overlap. The two-dimensional stock cutting problem was shown to be NP-hard and is therefore intrinsically difficult to solve.  Bennell and Oliveira\u00a0 [1] showed that the manipulation of items and containers\u2019 geometry is a key point to determine whether a layout is feasible or not. Several approaches to ensure that, in the resulting layout, items do not overlap and fully fit inside the container have been proposed in the literature. Adamowicz and Albano\u00a0 [2] chose to nest items into simpler shapes in which the interference can be more easily calculated. Babu and Babu\u00a0 [3] approximated the container and the items by grid squares represented by a matrix. Lee et\u00a0al.\u00a0 [4] used direct trigonometry to determine the interference among items and the container. Recently, the nofit polygon (NFP) has been used by several researchers\u00a0 [5\u20139] to ensure feasible layouts.  The NFP is the set of feasible locations for one polygon with respect to another polygon, such that the polygons do not overlap. Feasible locations are required for most of the solutions to two-dimensional packing problems, and also for other problems such as robot motion planning. Different approaches to generate the NFP have been proposed in the literature. Minkowski sums were proposed by Ghosh\u00a0 [10], and were later applied to cutting and packing problems by Dean et\u00a0al.\u00a0 [11] and Bennell and Song\u00a0 [12]. Agarwal et\u00a0al.\u00a0 [13] compared different algorithms of convex subpolygon decomposition, such that the Minkowski sum can be directly determined for each convex subpolygon pair. Li and Milenkovic\u00a0 [14] decomposed the items into star-shaped polygons. Burke et\u00a0al.\u00a0 [15] proposed an orbiting algorithm in which the movable item slides along the fixed item.  When sequential placement of items is adopted, the placement heuristic must take into account previously placed items, as well as the container in order to obtain a feasible layout. The concept of collision free region emerges from this heuristic, and it represents the set of translations that, when applied to the movable item, places it in the interior of the container without colliding with the already placed items. The collision free region is determined by unifying the NFPs determined by the movable item in respect to the already placed items.  The NFPs union must be made through non regularized Boolean operations, in which degenerated edges and vertexes are considered. A degenerated edge represents a sliding fit (in which the item position is constrained in all but one direction) and a degenerated vertex represents an exact fit (in which the item position is fully constrained by its surroundings).  Gomes and Oliveira\u00a0 [16] evaluated the point intersections between NFPs and selected the intersection points that are not internal to any NFP and, simultaneously, internal to the inner fit polygon. Such an approach cannot classify the vertexes in conventional boundary, sliding fit and exact fit. The vertex classification can be made by analyzing the vertex neighborhood with appropriate rules. Martins and Tsuzuki\u00a0 [9] used regularized Boolean operations to determine the collision free region, thus ignoring exact and sliding fit configurations.  Here, an algorithm to determine the collision free region is proposed. The paper is structured as follows. The concepts of NFP and collision free region are defined in Section\u00a0 2. Section\u00a0 3 explains the importance of determining the collision free region degenerated elements, using specific non-regularized Boolean operations. Section\u00a0 4 shows the proposed algorithm. The proposed algorithm was implemented in two versions: serial and parallel. Finally, computational results are presented and conclusions are drawn.  In this section, the collision free region and its primitive components, the nofit and inner fit polygons, are defined.  The NFP represents a set of translations of an item and is mathematically represented by a set of vectors. For a better understanding of the NFPs properties, the set of translations of an item are represented by polygons in the plane. Every item has a reference point that can be internal or external to it. The NFP represents the set of forbidden translations that, when applied to the item, moves the reference point to the interior of the NFP, as shown in Fig.\u00a01 . For an item P , which is a closed data set, let i  ( P )  be its interior, \u2202 P be its boundary and c  ( P )  be its complement.    Definition\u00a02.1 The NFP induced by item   P   i   to item   P   j   , noted as \u03a5  (   P   i   ,   P   j   )  , is the set of translation vectors that, when applied to   P   j   , makes it collide with   P   i   . Thus,  (1)  \u03a5  (   P   i   ,   P   j   )  = i  (   P   i   )  \u2296 i  (   P   j   )  =  {    v   \u2192  | \u2203  a  \u2208 i  (   P   j   )  ,  a  +    v   \u2192  \u2208 i  (   P   i   )  }  .      Another way to define the NFP is\u00a0 [8]      (2)  \u03a5  (   P   i   ,   P   j   )  = i  (   P   i   )  \u2295  ( \u2212 i  (   P   j   )  )  =  {  (  v  \u2212  w  )  |  v  \u2208 i  (   P   j   )  ,  w  \u2208 i  (   P   i   )  }  .      The NFP can be obtained by the Minkowski sum algorithm\u00a0 [13], which can be calculated very efficiently for convex polygons. The Minkowski sum result of two convex polygons is a convex polygon built from the original polygon edges sorted in counterclockwise order. Non-convex polygons can be decomposed into convex polygons in a preprocessing step, as the transformations applied (rotations and translations) do not affect such decomposition.    Definition\u00a02.2 The Minkowski sum of two polygons   P   i   and   P   j   , noted   P   i   \u2295   P   j   , is defined as the set of points  {  O  +    v   \u2192  +    w   \u2192  |  O  +    v   \u2192  \u2208   P   i   ,  O  +    w   \u2192  \u2208   P   j   }  .    Definition\u00a02.3 The opposed polygon for a given polygon   P   j   , noted as \u2212   P   j   , is defined as the set of points \u2212   P   j   =  {  O  \u2212    w   \u2192  |  O  +    w   \u2192  \u2208   P   j   }  .  The opposed polygon is obtained by inverting the signal of all the coordinates of the original polygon. From the above definitions, one can see that     (3)  i  (   P   i   )  \u2296 i  (   P   j   )  = i  (   P   i   )  \u2295  ( \u2212 i  (   P   j   )  )    meaning that the NFP is produced by the Minkowski sum of the fixed item with the opposed item to be placed.  An important property is that i  ( \u03a5  (   P   i   ,   P   j   )  )  represents colliding placements. \u2202  ( \u03a5  (   P   i   ,   P   j   )  )  and c  ( \u03a5  (   P   i   ,   P   j   )  )  represent feasible placements.  The inner fit polygon is another important frequently used concept, which is derived from the NFP and represents a set of translations for the placement of items inside a container C . The inner fit polygon can be computed by sliding an item along the internal contour of the container\u00a0 [5] (see Fig.\u00a02 ).    Definition\u00a02.4 The inner fit polygon induced by container C to item   P   j   , noted as \u039b  ( C ,   P   j   )  , is the set of translation vectors applied to   P   j   that leaves it inside the container. Thus,  (4)  \u039b  ( C ,   P   i   )  = c  ( c  ( C )  \u2295  ( \u2212 i  (   P   i   )  )  )  =  {    v   \u2192  | \u2200   a  \u2208 i  (   P   i   )  ,  a  +    v   \u2192  \u2208 C }  .      An important property is that c  ( \u039b  ( C ,   P   i   )  )  represents invalid placements. \u2202  ( \u039b  ( C ,   P   i   )  )  and i  ( \u039b  ( C ,   P   i   )  )  represent feasible placements.  Consider a container C and a set of already placed items P =  {   P   1   , \u2026 ,   P   n   }  , as shown in Fig.\u00a03 . A new item   P   n + 1   , will be placed inside the container without colliding with the already placed items. The feasible set of translations for item   P   n + 1   is given by the collision free region. A similar concept was previously used in robot motion planning\u00a0 [17,\u00a0sec. 13.4], and it was originally applied to irregular packing by Martins and Tsuzuki\u00a0 [18].    Definition\u00a02.5 Collision free region is the set of all translations that, when applied to a specific item, places the specific item inside a container without colliding with the already placed items.  When the container is empty, the collision free region represents all the translations that place the item completely inside the container. In this particular case, the collision free region is the already defined inner fit polygon\u00a0 [5]. For any given item, the calculation of the inner fit polygon is the first step in the determination of the collision free region.  The collision free region for a specific item is determined by removing the NFPs generated by the already placed items, from the inner fit polygon.  (5)  \u03a0  ( C , P ,   P   m   )  = \u039b  ( C ,   P   m   )  \u229f   \u2a04     P   i   \u2208 P   i  (   P   i   )  \u2296 i  (   P   m   )    where \u229f and \u2a04 are specific Boolean operations to manipulate NFPs and inner fit polygons. It is worth noting that only the NFP interior must be removed from the inner fit polygon (interior and boundary). This is why specific non-regularized Boolean operations are necessary.  By analyzing expression (5), it is possible to define at least two possible algorithms to compute the collision free region. In the first algorithm, all the NFPs are removed from the inner fit polygon and, therefore, only difference operators are used. The difference operations considered result in collision free regions. In the second algorithm, the unions of all NFPs are calculated and then removed from the inner fit polygon. The unions of NFPs result in NFPs and, after the final difference operator is applied, the collision free region is obtained. The implementation of the specific non-regularized Boolean operations is not an easy task.  In Section\u00a0 3.1, it is explained that, in this work, to implement robust Boolean operations, the intersections between segments are calculated with finite precision. The difference between regularized and non-regularized Boolean operations is explained in Section\u00a0 3.2. Section\u00a0 3.3 shows an example in which the regularized union misses some degenerated edges. Section\u00a0 3.4 shows some necessary characteristics of the non-regularized union and difference Boolean operators. Section\u00a0 3.5 explains the data structure used.  Boolean operations over polygons have the problem of lacking robustness. They face numerical instability and theoretical difficulties during geometric computations. These difficulties occur in boundary evaluations involving ill-conditioned geometric intersections\u00a0 [19]. There is a great amount of research on robust geometrical representations and computations. In the context of floating point arithmetic, a threshold \u03f5 > 0 is used to compare two numbers. Hoffmann\u00a0 [19] presented the incidence asymmetry problem in which a vertex can be incident to another vertex but not vice versa, and the incidence intransitivity problem, which considers three vertexes,  a  ,  b  and  c  , where  a  =  b  since  |   a  \u2212  b  |  < \u03f5 ,  b  =  c  since  |   b  \u2212  c  |  < \u03f5 , but  a  \u2260  c  , since  |   a  \u2212  c  |  > \u03f5 .  Bentley and Ottmann\u00a0 [20] used finite precision to achieve robust algorithms for intersecting line segments. Agarwal et\u00a0al.\u00a0 [13] used CGAL to implement the Minkowski sum algorithm with exact rational numbers, and they reported execution times that range from a few seconds for shapes involving a small amount of concavities, and up to twenty minutes for highly irregular shapes. Hu et\u00a0al.\u00a0 [21] used interval arithmetics to ensure robustness. Wallner et\u00a0al.\u00a0 [22] showed that interval arithmetic is not geometric in the sense that it does not give exact error bounds. Several researchers used finite precision to implement Boolean operations over polygons\u00a0 [23,24], which was adopted in this work, too.  Conventional polygons are expected not to contain isolated points or lines. The regularization of a point set A , r  ( A )  , is defined by r  ( A )  = \u2202  ( i  ( A )  )  . Sets that satisfy r  ( A )  = A are said to be regular\u00a0 [25]. Some combinations of polygons do not quite satisfy the regularity concept. Consider, for instance, the case shown in Fig.\u00a04 . According to the ordinary definition of intersection, the intersection between the two polygons consists of a rectangular polygon plus a degenerated edge. The Boolean operation over conventional polygons needs to preserve the regularity property. The regularized intersection is defined as A   \u22c2   \u2217   B = \u2202  ( i  ( A \u22c2 B )  )  , where \u22c2 denotes the ordinary set operation. In the literature, several proposals to implement regularized Boolean operations were proposed [23,24,26\u201328].  The collision free region cannot be determined using regularized Boolean operations because it will miss eventual degenerated elements that represent local minima for the packing problem. Fig.\u00a05 (a) shows a critical example in which four rectangular items are already placed and a fifth rectangular item is to be placed. The reference is the central point of the movable rectangular item. This example shows the difference between regularized and non regularized unions. Fig.\u00a05(b) shows the union of the four NFPs, represented by a rectangle with two internal degenerated edges. In this case, the degenerated situation refers to a situation in which the item can slide within a segment. If regularized union is applied to the four NFPs, the two degenerated edges are lost (see Fig.\u00a05(c)).  This section explains how to modify regularized Boolean operations to correctly implement the specific non-regularized Boolean operations which can manipulate NFPs and collision free regions. Implementations of regularized Boolean operations over conventional polygons have the following steps\u00a0 [23,24,26\u201328]: intersection determination, classification of boundaries and collection of appropriate boundaries to compose the result.   Fig.\u00a06 shows two conventional polygons A and B with their boundary orientations. The intersections between the conventional polygons are determined and the edges are divided. The intersection determination is a common module in all types of Boolean operation implementations\u00a0 [23,24,26\u201328]. New vertexes are created at the intersecting positions and the intersecting edges are divided in both conventional polygons. Subsequently, vertexes and edges must be classified.  The vertexes of a conventional polygon are classified as internal, external and on boundary. The classification of edges must consider the case in which two polygons share an edge. The shared edge may be in opposed orientations on the original polygons or coincident orientations. Consequently, the edges of a conventional polygon can be classified according to four attributes: internal, external, coincident shared and opposite shared. Fig.\u00a07 shows the classifications of the all edges for the example described in Fig.\u00a06.  The collection of the appropriate edges occurs differently depending on the Boolean operation type: subtraction or union. This module is responsible for determining which edges from the original conventional polygons will be used and which will be discarded. The edges can be used to define a conventional boundary or to define a degenerated element. The rules to define a conventional boundary are the same as for regularized Boolean operations. New rules are defined to create degenerated elements from conventional polygons.  The union is exclusively used to combine NFPs, and the subtraction is exclusively used to combine a collision free region with NFP. Fig.\u00a08 shows both cases; on the left, the result of the union of two NFPs and, on the right, the difference between a collision free region and an NFP. The edges classified as shared play a very important role, creating degenerated placements in both results. In the union case, opposed shared edges generate internal degenerated edges. In the subtraction case, coincident shared edges generate external degenerated edges.  The NFP (represented in Fig.\u00a08 by A \u2a04 B ) and the collision free region (represented in Fig.\u00a08 by A \u229f B ) have two types of boundaries: conventional polygons, and degenerated edges and/or vertexes. Conventional polygons are represented by an oriented sequence of vertexes. In this work, the convention that the left side of the oriented edge is inside and the right is outside is adopted. Degenerated edges that are associated with sliding fits are represented by two vertexes without orientation. Degenerated vertexes that are associated with exact fits are represented by single vertexes. Degenerated boundaries are of special interest as they represent desirable placements that can produce local optima layouts. Degenerated elements are stored in a separated data structure. Thus, the placement solver is capable of accessing these elements whenever necessary.  As previously explained, NFPs and collision free region are generically represented by conventional polygons and degenerated elements. The implementation of the specific non-regularized Boolean operations over NFPs and collision free regions is executed in two steps (see Fig.\u00a09 ). The first step is based on regularized Boolean operations\u00a0 [23,24,26\u201328]. Initially, the intersection between conventional and degenerated boundaries are determined. Afterwards, conventional and degenerated boundaries are classified. Selected elements from the classified conventional boundary are selected to compose the result conventional boundary; and, selected elements from the classified degenerated boundary are selected to compose the result degenerated boundary. In the second step, new degenerated elements are created. New degenerated edges can be originated from the conventional boundary classification (see Fig.\u00a08), and new degenerated vertexes can be originated from special configurations. The main modules of the proposed algorithm are explained as follows.  As conventional polygons and degenerated elements might intersect each other, all boundaries are simultaneously processed and their intersections are determined. The intersection determination is based on the Bentley and Ottmann sweep line algorithm\u00a0 [20]. In this work, the sweep line algorithm is modified to simultaneously classify degenerated vertexes and isolated degenerated edges; i.e.,\u00a0determine if degenerated vertexes and edges are internal, external or boundary.  In the sweep line algorithm, an imaginary vertical sweep line moves from left to right across edges and vertexes, halting at event points. As the sweep line proceeds, the intersections restricted to the left of the sweep line are determined. There are four kinds of event points: left end points, right end points, crossings and isolated vertexes. The edges and vertexes that intersect the sweep line   s   1   are stored in a list S , which is ordered from bottom to top (see Fig.\u00a010 ). When a left end point event happens, the edge is inserted in S . In the example of Fig.\u00a010, edges   L   2   ,   L   5   and   L   6   were inserted in S . When a right end point is reached, the edge is removed from S . In the example of Fig.\u00a010, edges   L   1   ,   L   3   and   L   4   were removed from S . Adjacent edges are processed to verify if they intersect. If they intersect, the intersection point is determined and the intersecting edges are divided. In the example of Fig.\u00a010, edges   L   B   and   L   7   intersect and they will be divided. Fig.\u00a011 shows the types of intersections that causes edge division. The edges in S have the information to which polygon ( A or B ) and to which type of boundary (regular or degenerated) they belong. In the example,  {   L   1   ,   L   2   ,   L   3   ,   L   4   ,   L   5   ,   L   6   ,   L   7   }  are edges from polygon A with conventional boundaries, and  {   V   1   ,   L   A   ,   L   B   }  are elements from polygon B with conventional and degenerated boundaries.  One simple way of finding whether the degenerated vertex is inside or outside a conventional polygon is to test how many times a ray, starting from the degenerated vertex and going any fixed direction, intersects the edges of the conventional polygon. The vertical sweep line   s   2   plays the ray role, initially the degenerated vertex   V   1   from B is checked to lie on A \u2019s conventional boundary. If the degenerated vertex in question is not on the boundary, the number of intersections is even if the degenerated vertex is outside, and it is odd if inside (see Fig.\u00a010).  In the case of a right end point event occurring on a degenerated edge whose left and right end points are isolated, without any contacting edge, such right edge point is classified in similar way as a degenerated vertex. Thus, the intersection module also includes degenerate vertexes and isolated edges classification. Fig.\u00a012 shows an example in which all intersecting vertexes are determined.  Conventional and degenerated boundaries from polygon A are classified against polygon B conventional boundary, and vice versa. The edges from a conventional boundary can be classified as: internal, external, coincident shared and opposed shared. As degenerated boundaries do not have a direction, they can be classified as: external, internal and boundary.  The classification starts by analyzing intersecting vertexes with coincident coordinates, they are collected in a circular list D similar to the one proposed by Leonov and Nikitin\u00a0 [24]. Fig.\u00a013 shows an example in which vertexes   A   4   ,   B   9   and   B   12   have the same coordinates. The circular list D contains all the edges emanating from the coincident vertexes, and they are ordered according to their horizontal angle. If a vertex belongs to the regular boundary, then it has two edges in D ; otherwise, it has just one edge. The circular list D is used to determine counter clockwise and clockwise adjacency and to identify coincident edges.  Coincident edges have the same vertexes coordinates. For conventional polygon edges, based on both edges orientation, the edges are classified as coincident or opposed shared. For degenerated edges they are classified as boundary. Conventional boundaries have sectors in the circular list D . Edges that are internal to the sector are classified as internal. Special care needs to be taken, because one conventional boundary can have more than one sector in D . The edges that were not classified as internal are classified as external. Fig.\u00a012 shows an example in which all the possible intersections were determined and all the edges were classified as internal, external, coincident shared or opposite shared.  The boundary collection step is the one in which the result is finally obtained. It has to deal with two important problems: which edges should be collected and in which order. The first problem is solved by adopting a set of boundary collection rules, which determine the inclusion of edges in the final result. For conventional polygons, the rules were defined by Leonov and Nikitin\u00a0 [24] and are operation-specific. Consider an operation A  o p  B , in which o p can be the union or difference operator. A boundary collection rule specifies which label is applied to the edge and to which polygon it belongs ( A or B ). Also, boundary collection rules determine if the edge will be included with its original orientation or with inverted orientation. Collection rules are also defined for degenerated edges and are naturally equal to the rules of regular boundaries. The only difference is that, as degenerated edges have no orientation, inclusion orientation is not specified. Table\u00a01 shows the boundary collection rules for union and difference operators. It can be observed that orientation is not applicable to degenerated edges, so shared degenerated edges are classified as both coincident shared and opposite shared.   Fig.\u00a014 shows four degenerated edge collection cases for difference Boolean operation. In this case, A is a collision free region and B is a NFP. As previously explained, a degenerated edge can be classified as internal, external and boundary. The boundary classification can happen with conventional and degenerated boundaries (see Fig.\u00a014(c) and (d)). Situations in which a degenerated edge from A is internal to B , and where a degenerated edge from B is external to A do not create a degenerated edge in the result (see Fig.\u00a014(a) and (b)).   Fig.\u00a015 shows three degenerated edge collection cases for union Boolean operation. As A and B are NFPs, the vice-versa situation must be considered. The situation in which a degenerated edge from A is internal to B does not create a degenerated edge in the result. Fig.\u00a016 shows five degenerated vertex collection cases for the difference Boolean operation, where A is a collision free region and B is a NFP. Situations in which a degenerated vertex from A is internal to B , and in which a degenerated vertex from B is external to A do not create a degenerated vertex in the result (see Fig.\u00a016(a) and (b)). Fig.\u00a017 shows four degenerated vertex collection cases for union Boolean operation, where A and B are NFPs. The vice-versa situation must be considered. The situation where a degenerated vertex from A is internal to B does not create a degenerated vertex in the result.  The need to adopt a specific collection order in the conventional boundary is justified by the need of obtaining valid oriented contours in the result. If edges have been collected randomly, a new step should be added, in which edges are sorted for obtaining a valid oriented contour. By appropriately choosing connected edges, the final result is a valid connected oriented contour. This suggests that the collection should follow the oriented contour of one of the inputs, in which all the edges are connected and correctly oriented. When an intersection point is encountered, a decision has to be made in order to proceed to the correct contour. A new set of boundary collection rules is then defined, called jump rules\u00a0 [24]. According to these rules, when an intersection point is found, the next edge to be collected is the first in counter-clockwise order that follows the boundary collection rules. As mentioned, counter-clockwise adjacency can be determined by using circular list D (see Fig.\u00a013). Degenerated edges are also contained in this list, but they should be ignored in the jump rules, as a conventional boundary is being collected. The collection of the degenerated boundary is very straightforward. As there is no connection between degenerated edges or vertexes, they can be directly included in the result if they obey the boundary collection rules (see Figs.\u00a014\u201317).  Possibly the most significant difference between regularized and non-regularized Boolean operations algorithms is that, in the latter, additional checking must be performed to determine if new elements should be included in the result boundary. Such elements are always degenerated edges or vertexes. In regularized Boolean operations algorithms, boundary edges from the result are always found in the input boundaries. If degenerated boundaries are to be processed separately, the result of a non-regularized Boolean operations algorithm can have degenerated edges which were not contained in the input degenerated boundaries. Furthermore, degenerated vertexes can also only exist in the final result. To determine whether a new degenerated edge will be created, a rule similar to a boundary collection rule is checked. The edge is then included in the degenerated boundary (see Fig.\u00a018 ).  While the creation of degenerated edges follows the same procedure as the collection of the regular boundary, checking for new degenerated vertexes is a more complex task. Degenerated vertexes arise from the crossing of edges, more specifically, crossing where no edges follow boundary collection rules, including the one regarding the creation of degenerated edges. This is justified by the fact that all the intersecting vertexes are part of the final result. They are usually an endpoint of a collected edge or a degenerated edge and the only exception is when none of the edges that have the intersecting vertex as its endpoint are collected. Fig.\u00a019 (a) and (b) show two cases of vertex creation for the union Boolean operation and Fig.\u00a019(c) and (d) show two cases for the difference Boolean operation. Other possible cases can involve more or less crossing edges; however, the generation rule is the same, i.e.\u00a0no edges must follow the boundary collection rules. It is important to note that degenerated vertex creation should not be checked alongside jump rules, as the latter occurs on intersections in which one edge is already included. Table\u00a02 shows the creation rules for the union and difference operations.  Degenerated boundaries classification and collection are processed in a different module. Degenerated edge creation is only possible for conventional boundary coincident edges, and it is thus processed in the conventional boundary module. On the other hand, degenerated vertexes can be originated from any crossing vertex; hence, all the intersections must be checked and thus it does not fit in a single module. The resulting degenerated boundary is composed of degenerated edges collected from conventional boundary edges and degenerated vertexes and edges collected from input degenerated boundaries.  Collision free region determination is performed using a sequence of NFPs as input. Eq. (5) shows the necessary operations to be performed. In this work; the collision free region is calculated according to three different implementations. Considering that P is a queue and n is the number of items in the queue. The first implementation is shown in Algorithm 1; it only consists of difference operators, as the collision free region is determined by serially subtracting every NFP from the inner fit polygon (see Fig.\u00a020 ). The first implementation has no parallelization.          The second implementation is an algorithm in which all NFPs are serially united and then subtracted from the inner fit polygon, shown in Algorithm 2. Union and difference operators are used in this implementation, and there is no parallelization (see Fig.\u00a021 ). The union of all NFPs is defined as the obstructed region, as it represents all the forbidden translation for a given item, given a set of already placed items.          The third implementation is a parallel algorithm to calculate the obstructed region described in Algorithm 3. In this algorithm, union operations are processed in parallel. Initially, all NFPs are determined and pushed in queue R . Each thread pops two NFPs, the NFPs are united to define an obstructed region, and the obstructed region is pushed back at the end of the queue. Just one thread accesses the queue at a time. If the queue does not have two obstructed regions, the threads that finished the union operation are kept in an idle state until the queue has enough obstructed regions. The procedure is repeated n \u2212 1 times, where n represents the total number of NFPs, until the queue has just one obstructed region. At this moment, the threads are killed and the collision free region is determined by subtracting the obstructed region from the inner fit polygon. Fig.\u00a022 shows a example of parallel collision free region determination using the proposed algorithm. All horizontally aligned operations are performed in parallel. Finally, to obtain the collision free region, the obstructed region is subtracted from the inner fit polygon.           RESULTS   In order to demonstrate the speed of the proposed approach, generation statistics for 15 benchmark problems gathered from the literature are shown. These data sets can be found on the EURO Special Interest Group on Cutting and Packing (ESICUP) website. 1   1  http://www.fe.up.pt/esicup. For each problem, the time to generate 1000 times the collision free region for all items is reported. Placement order and position of items were randomly defined. The last item in the sequence is the item to be placed. Table\u00a03 displays the results obtained using exclusively the difference Boolean operation (see Fig.\u00a020). All the experiments were conducted on an i7 860 multi-core processor with 4 cores and 4 GB RAM. Sato et\u00a0al.\u00a0 [29] used this approach to determine the collision free region, and the Albano, Dagli, Jakobs and Marques solutions found by the proposed algorithm are the best results published in the literature.   Fig.\u00a023 shows an example of the determination of the collision free region for a single item. The final layout, current item P7 and the corresponding collision free region, represented by the hatch pattern filled polygons with degenerated edges and a degenerated vertex, are displayed in Fig.\u00a023(a). The inner fit polygon of item P7 can be observed in Fig.\u00a023(b). Fig.\u00a023(c)\u2013(h) represent the difference sequence, each relating to one Boolean operation. Both input polygons, the intermediate collision free region and the NFP, are shown on the left. The placed item used to generate the NFP is exhibited on the right and the result is displayed in the middle.  To compare processing times for the three implementations proposed, a new batch of tests was executed. A parallel version of the algorithm with the obstructed region is also included in the tests. Table\u00a04 shows execution times obtained for these evaluations. Three serial implementations were developed: DIFF, UNI and UD (serial). The minimum between the three is selected to create the graph shown in Fig.\u00a024 . Considering the same implementation, the main difference in time among the cases is related to the total number of edges. One might observe that Shapes0, Shapes1 and Trousers have a similar total number of edges (376), but the processing time for Trousers is almost three times the Shapes0 and Shapes1 time processing. As intermediary results of Shapes0 and Shapes1 are determined, the total number of edges is kept low. On the other hand, the intermediary results for Trousers have a high total number of edges. Considering that the same sequence of NFPs is used for all the implementations, for the same case there are differences in the time processing as NFPs are combined in different ways. The three serial implementations show different time processing as intermediary results have a different total number of edges. From Fig.\u00a024, it is possible to observe that the adoption of the obstructed region is only beneficial in puzzles with a high number of items. It can also be noted that Dighe1, Dighe2, Fu, Jakobs1, Mao, Marques and Shapes2 problems ran slower using the parallel algorithm when compared to its faster serial counterpart.   CONCLUSIONS   The collision free region concept is defined and non regularized Boolean operations are shown to be necessary to correctly determine it. Three different algorithms can be defined to determine the collision free region: one based exclusively on difference operations, and the other based on union and difference operations. One algorithm that uses union and difference operations can be parallelized (UD).  The collision free region has two types of boundaries: conventional boundary and degenerated vertexes and edges. A robust non regularized Boolean operation algorithm using finite precision is proposed in order to compute the union between NPFs and the difference between a collision free region and a NFP. The proposed algorithm robustly determines conventional boundaries, degenerated vertexes and degenerated edges.  The parallelized algorithm was implemented and tested. Execution times for serial and parallelized algorithms were measured and the advantage of the parallelized algorithm was only observed in problems with a larger number of items.   ACKNOWLEDGMENTS   Andr\u00e9 Kubagawa Sato was supported by CNPq and FAPESP (Grant 2010/19646-0). Thiago Castro Martins was supported by FAPESP (Grant 2009/14699\u20130). Marcos Sales Guerra Tsuzuki was partially supported by CNPq (Grants 304.258/2007\u20135 and 309.570/2010\u20137). Thiago de Castro Martins was partially supported by CNPq (Grant 06415/2012-7). This research was supported by FAPESP (Grants 2008/13127\u20132 and 2010/18913\u20134).   REFERENCES", "highlights": "Cutting and packing problems are found in numerous industries such as garment, wood and shipbuilding. The collision free region concept is presented, as it represents all the translations possible for an item to be inserted into a container with already placed items. The often adopted nofit polygon concept and its analogous concept inner fit polygon are used to determine the collision free region. Boolean operations involving nofit polygons and inner fit polygons are used to determine the collision free region. New robust non-regularized Boolean operations algorithm is proposed to determine the collision free region. The algorithm is capable of dealing with degenerated boundaries. This capability is important because degenerated boundaries often represent local optimal placements. A parallelized version of the algorithm is also proposed and tests are performed in order to determine the execution times of both the serial and parallel versions of the algorithm."}