{"id": "S001044851400178X", "article": "MAIN-TITLE Dynamic meshing for deformable image registration   HIGHLIGHTS          We study how the superimposed mesh structure would influence the Finite Element Method (FEM)-based image registration process.      We propose a mesh generation algorithm based on how the mesh will influence the registration process, using the discrete Centroidal Voronoi Tessellation idea.      We present a parallel algorithm to compute and update the mesh structure efficiently during image registration.          KEYPHRASES   Deformable image registration  Centroidal Voronoi Tessellation (CVT)  Dynamic meshing  GPU   Finite element method (FEM) is a widely used technique to solve deformable image registration problems in the computer graphics, computer vision and medical imaging community. By introducing a superimposed mesh structure in the image domain, the speed and accuracy of image registration significantly depends on the mesh structure.  The traditional meshing methods usually target at generating a high quality mesh whose boundary resembles the surface of the biological object in one image\u00a0 [1]. Usually when the node number is fixed, the requirement of better surfaces approximation always implies a deterioration of mesh quality. There are a lot of algorithms\u00a0 [2\u20138] proposed to strive for the trade-off between these two conflicting factors.  We believe meshing for deformable image registration should focus on the registration process instead of one image (source or target image). Since the registration process is a dynamic process, the mesh structure should be updated accordingly. Three steps are performed in our algorithm for the dynamic mesh generation. Firstly, a density field that measures the importance of a pixel/voxel\u2019s displacement to the registration process is computed. Secondly, an efficient contraction\u2013optimization scheme is applied to compute a discrete Centroidal Voronoi Tessellation (CVT) of the density field. Thirdly, the final mesh structure is constructed by its dual triangulation, with some post-processing to preserve the image boundary.  The main contribution of our work includes two aspects: on the one hand, we propose a mesh generation algorithm based on how the mesh will influence the registration process; on the other hand, we present a parallel algorithm to compute and update the mesh structure efficiently.   RELATED WORK   Deformable image registration is a challenging research problem in the fields of image processing and medical imaging. As described in the book of Modersitzki\u00a0 [9], given the source image  S  and the target image  T  , the goal of registration is to establish the transformation  W  that optimizes an objective function, which includes two terms: one is the image matching criteria (image similarity) D  (  T  ,  S  \u2218  W  )  , and the other is the weighted regularity of the transformation R  (  W  )  :  (1)  D  (  T  ,  S  \u2218  W  )  + \u03b2 R  (  W  )  ,   where \u03b2 is the weight to balance the image matching criteria and regularity.  The transformation  W  is a mapping function that relates the source and target images together. Usually, it can be considered as a backward mapping, i.e.\u00a0for every position  x  in the target domain, it is mapped to the corresponding location in the source image  S  through a displacement vector  u   (  x  )  :  (2)   W   (  x  )  =  x  +  u   (  x  )  .   In this way, the deformed source image  S  \u2218  W  is aligned in the target domain. The term \u201cdeformable\u201d in this paper is used to denote that the transformation  W  is non-rigid and spatially varying.  Many deformable image registration algorithms have been proposed in the past two decades. We refer the readers to a more complete survey by Aristeidis et\u00a0al.\u00a0 [10]. In general, the deformable image registration algorithms mainly have three components: (1) a deformation model, (2) an image matching criteria, and (3) an optimization method.  The deformation model captures the nature of the transformation  W  to be recovered, and it plays two important roles in the registration problem. Firstly, for image registration problem, there is no unique transformation  W  to align the deformed source image  S  \u2218  W  with the target image  T  . The deformation model determines the regularity term R  (  W  )  that penalizes unwanted transformations. Thus, along with the proposed image matching criteria D  (  T  ,  S  \u2218  W  )  , the image registration problem is converted to an optimization problem to obtain a physically-plausible solution. Secondly, the deformation model specifies the solution space of the transformation  W  . Usually Finite Element Method (FEM) is exploited\u00a0 [11\u201315] to achieve a balance between the efficiency of the optimization and the richness of the deformation model\u2019s description. By introducing a superimposed mesh structure on the image, FEM-based registration specifies the displacement vectors on the mesh nodes and the displacement field  u   (  x  )  over the image domain is interpolated by the shape function\u00a0 [16], usually predefined by mesh elements. Therefore, FEM restricts the solution space of the image registration problem with much fewer degrees of freedom and ensures the smoothness of the transformation  W  by interpolation.  Generally speaking, the previous mesh generation algorithms for deformable image registration mainly concern two aspects: fidelity and quality. Fidelity measures the accuracy of the mesh boundary in capturing the anatomical structure, e.g.,\u00a0a mesh having its boundary conforming to the surface of underlying biological object is considered a good mesh. Quality measures the shape of mesh elements, such as the minimum angle in triangular elements in 2D case\u00a0 [17] or minimum dihedral angle of the tetrahedral elements in 3D case\u00a0 [1].  Mesh generation methods can be mainly divided into two categories: surface meshing and volumetric meshing. For surface meshing methods, they usually recover an explicit representation of the object surface, or construct an implicit function to describe the object surface from the source image\u00a0 [2], and then use the Marching Cubes algorithm to extract the iso-surface from the image\u00a0 [18]. As for the volumetric meshing methods, there are some recent literature about generating high-quality meshes, such as regular tilings and adaptive elements by using the octree method\u00a0 [3,4]. Delaunay refinement method\u00a0 [19,6] is an incremental mesh construction approach, which has been successfully applied to many practical applications. There are also several works\u00a0 [5\u20137] discussing about producing the volumetric mesh while preserving the object boundary and surfaces.  In this paper, we are going to show that fidelity may not be an important factor for mesh generation in deformable image registration. Instead, a mesh guided by the potential deformation vector field will be more important in providing sufficient degrees of freedom to drive the deformation.  To generate high-quality meshes, Centroidal Voronoi Tessellation (CVT)\u00a0 [20] is an effective tool that has been widely used. Given a set of sites  X  =  {    x    i   | i = 0 \u2026 n \u2212 1 }  to sample the domain \u03a9 , CVT is a special type of Voronoi Diagram, where each site    x    i   coincides exactly with the centroid of its Voronoi cell. There are two main approaches to compute CVT: one is the Lloyd relaxation\u00a0 [21], and the other is a quasi-Newton energy optimization solver\u00a0 [22].  For surface meshing, Peyre et\u00a0al.\u00a0 [23] used a geodesic Voronoi Diagram over the surface to generalize CVT. However, the computations of geodesic Voronoi Diagram are very complicated, so Edelsbrunner and his co-authors computed the Restricted Voronoi Diagram (RVD) or Restricted Delaunay Triangulation (RDT)\u00a0 [24], instead of the geodesic Voronoi Diagram. A Restricted Centroidal Voronoi Tessellation is provided in\u00a0 [25], which requires all the sites to be constrained on the surface. Yan et\u00a0al.\u00a0 [17] computed the CVT in 3D space via the 3D Euclidean distance as an approximation, and then intersected it with the surface. An alternative approach is to compute the CVT in the 2D parametric domain of the surface \u00a0 [26\u201328].  For volume meshing, Du and Wang\u00a0 [29] discussed an algorithm for tetrahedral meshing based on CVT in a 3D domain. Yan et\u00a0al.\u00a0 [30] presented an efficient algorithm to compute the clipped Voronoi diagram with respect to a 3D volume and then generate its dual mesh. Alliez et\u00a0al.\u00a0 [31] proposed a variational isotropic tetrahedral meshing method which minimizes an Optimal Delaunay Triangulation (ODT) energy.  This paper uses a discrete CVT approach\u00a0 [32\u201334] to generate dynamic mesh in each iteration of deformable image registration. Since the image domain is typically discretized into pixels (2D) or voxels (3D), the discrete Voronoi diagram can be computed by classifying the pixels/voxels into clusters, according to their distances w.r.t. the sites. An \u201cenergy increase rule\u201d is proposed in this paper to efficiently swap pixels between neighboring clusters, in order to optimize the discrete CVT energy.  This paper mainly studies the problem of distributing degrees of freedom during image registration. Our dynamic meshing method is different from the topological control techniques\u00a0 [35] for viscoelastic fluid simulation, the content-aware framework\u00a0 [36] for image wrapping, or the coupled simulation method\u00a0 [37] for interactive simulation of the surgical needle.   Fig.\u00a01 illustrates a flow chart of the proposed deformable image registration framework based on dynamic meshing.  In this section, we present the general settings of the image registration algorithm in our implementation. We made two assumptions of the input images: first, the whole image region is the region of interest to solve the displacement vector field. Secondly, the two images should contain the same objects and the deformation is small enough w.r.t. the image size. Since we only focus on how the superimposed mesh structure influences the registration process, for the ease of presentation, we fix all other registration components, such as: the image matching criteria D , transformation regularity R , and optimization method. It should be noted that the proposed concepts and methods in the following sections can be extended to other regularizers and any differentiable image matching criteria (i.e.\u00a0the image matching criteria is   C   1   continuous).  We develop a multi-resolution sum of squared differences (MSSD) as image matching criteria. The main difference between MSSD and the traditional sum of squared differences (SSD) criteria is that MSSD uses an underlying multi-resolution scheme. Furthermore, in the traditional multi-resolution scheme, images are represented by pyramids. Image registration follows a multi-level approach: firstly, coarser levels are served to register the image and the result is considered as the initial guess of the finer levels. In order to avoid the inconsistency of the stopping conditions of different levels (i.e.\u00a0we optimize different objective functions in different levels), we sum the objective function in each pyramid level and register all image pyramids simultaneously:  (3)  D  (  T  ,  S  \u2218  W  )  =   \u2211   i     \u2211    x  \u2208    T     i         (    T     i     (  x  )  \u2212    S     i     (  W   (  x  )  )  )    2   ,   where i is the pyramid level,    T     i    and    S     i    are the target image pyramid and source image pyramid at the i th level, respectively.  In the above statement, we have demonstrated the objective function of our proposed image registration method. Now we will discuss how to compute the optimal transformation  W  in the following of this section.  We use the linear elastic potential\u00a0 [38] to model the transformation regularizer. For this particular choice, the Navier\u2013Lame equation\u00a0 [9] characterizes the force equilibrium between the stress of the elastic body and external force as:  (4)   ( \u03bb + \u03bc )  \u2207  (  div    u  )  + \u03bc  \u0394   u  =  f  ,   where \u03bb and \u03bc are Young\u2019s modulus and shear modulus of the elastic body, respectively.  u  is the vector of displacements at image pixels/voxels. \u2207  (  div    u  )  is the gradient of the divergence of  u  .  \u0394   u  is the Laplacian operator of  u  .  f  is the external force derived from the first-order derivative of the image matching criteria, in our case, i.e.:  (5)   f   (  x  )  =   \u2211   i   2  (    T     i     (  x  )  \u2212    S     i     (  W   (  x  )  )  )  \u2207    S     i     (  W   (  x  )  )  .      Following the general discretization approach with linear elements\u00a0 [16], a global equation describing the force equilibrium of mesh nodes can be written in a matrix form as:  (6)     K    \u02c6      u    \u02c6   =    f    \u02c6   ,   where    K    \u02c6   is the stiffness matrix,    u    \u02c6   is the displacement vector at mesh nodes, and    f    \u02c6   is the force vector at mesh nodes.  Note that we fix the boundary nodes of the mesh, i.e.,\u00a0we constrain the displacements of image boundary as zero throughout the registration process. In this way, the stiffness matrix    K    \u02c6   is guaranteed to be full-rank. We adopt the fixed-point iteration\u00a0 [9] to solve the nodes\u2019 displacement vectors      u    \u02c6      ( k )    at iteration k . Given    W     ( k )     (  x  )  as the transformation at the k th step, the mesh structure is dynamically updated (as described in Section\u00a0 4), leading to an updated stiffness matrix      K    \u02c6      (  k  )    . The force vector      f    \u02c6      ( k )    is reassembled using the nodes at the current transformation, and the nodes\u2019 displacement vector      u    \u02c6      ( k + 1 )    is solved by:  (7)       K    \u02c6      (  k  )         u    \u02c6      ( k + 1 )    =      f    \u02c6      ( k )    .      For updating the transformation    W     ( k + 1 )    iteratively, we first interpolate the displacement field    u     ( k + 1 )    over the image domain from the displacements on nodes      u    \u02c6      ( k + 1 )    . According to\u00a0 [39]: for a smooth vector field, the Jacobian matrix of its exponential map is positive definite everywhere. Thus to get a diffeomorphic spatial transformation, instead of treating    u     ( k + 1 )    as an additive deformation, its exponential map exp  (    u     ( k + 1 )    )  is computed by the diffeomorphic updating rule \u00a0 [39], the transformation    W     ( k + 1 )    is then updated through composition:  (8)     W     ( k + 1 )    =    W     ( k )    \u2218 exp  (    u     ( k + 1 )    )  .   Note that this diffeomorphic updating rule will guarantee that the resulting transformation    W     ( k + 1 )    is a diffeomorphism, i.e.,\u00a0there will be no flip-overs in the mapping.  In general, the superimposed mesh plays a dual role in the image registration process. On the one hand, the discretization of the Navier\u2013Lame equation (Eq. (4)) based on the mesh should guide the solution towards the physically meaningful solution that we are interested in. On the other hand, the registration process will be smooth by interpolating the displacement vector from the values solved on mesh nodes, even if the real deformation is complicated.  Targeting at producing high fidelity meshes, meshing algorithms usually try to resemble the surface of the biological object. However, they usually ignore the fact that deformation does not always happen on the surface, so that sampling much denser nodes on the surface of object is wasteful and inefficient. Meanwhile, large deformation can also occur inside the object. Thus, we propose the idea behind our algorithm: mesh generation should depend on the registration process, instead of only resembling the object in one static image (either the source or target image). Since the image registration is a dynamic process, the meshing should be dynamic throughout the registration as well.  Given a source image  S  and a target image  T  , in this section, we illustrate the dynamic mesh generation approach for deformable image registration. Fig.\u00a02 shows the partial results in each step of the proposed algorithm.  (1)  Density field generation (Fig.\u00a02(a)): a density field is computed to quantify the importance of each pixel/voxel in the current step of deformable registration. This is introduced in Section\u00a0 4.2.   Initial tessellation by contraction (Fig.\u00a02(b)): an efficient contraction\u2013optimization scheme is utilized to compute the initial tessellation based on the computed density field. The details are provided in Section\u00a0 4.4.   Tessellation optimization (Fig.\u00a02(c)): we optimize the tessellation by minimizing the objective function given in Section\u00a0 4.2. Details of the optimization are introduced in Section\u00a0 4.5.   Initial meshing (Fig.\u00a02(d)): an initial mesh can be computed according to the optimized tessellation (Section\u00a0 4.6).   Dynamic meshing (Fig.\u00a02(e)): in each iteration of the deformable image registration, we use the intermediate transformation    W    \u2032   to recalculate the density field with the warped source image  S  \u2218    W    \u2032   . The tessellation and the mesh will be updated according to the new density field. More details are discussed in Section\u00a0 4.7.  Since the goal of image registration is to find a physical plausible transformation  W  that optimizes the matching criteria D  (  T  ,  S  \u2218  W  )  , the first-order derivative of the image matching criteria in Eq. (5), which is a force vector field  f   (  x  )  for each pixel/voxel, is closely related to the registration process: for each pixel/voxel  x  , the direction of  f   (  x  )  points to the largest energy decreasing direction, and its   L   2   norm denotes to the rate of the energy decrement.  We quantify the   L   2   norm of  f   (  x  )  on each pixel/voxel as its importance for the registration process, in the sense of minimizing the matching criteria in Eq. (3). Thus, we define the density field for registration process as:  (9)  d  (  x  )  =    \u2016  f   (  x  )  \u2016    2   + \u03b1 ,   where \u03b1 is a constant base value for the importance of the registration. From Fig.\u00a02(d), we can obviously see that more degrees of freedom are desired at higher density regions.  The density field is used to drive the computation of discrete CVT for generating a density-guided mesh\u00a0 [20]. Let \u03a9 be a discrete domain represented by image pixels/voxels, given a density field d  (  x  )  defined on the domain \u03a9 with positions of the pixels/voxels  x  , our goal is to find the optimal tessellation    {    C    i   }    i = 1   n   (a tessellation is a number of clusters and   C   i   is the cluster i , with n being the number of clusters) and its corresponding optimal sites    {    z    i   }    i = 1   n   (    z    i   is the site corresponding to cluster i ), by minimizing the following energy function:  (10)    E    tess     (    {    C    i   }    i = 1   n   ,    {    z    i   }    i = 1   n   )  =   \u2211   i = 1   n     E   i    (    C    i   ,    z    i   )  =   \u2211   i = 1   n     \u2211    x  \u2208    C    i     d  (  x  )     \u2016  x  \u2212    z    i   \u2016    2   ,   where   E   i    (    C    i   ,    z    i   )  is the clustering energy of cluster i with site    z    i   .   E    tess     (    {    C    i   }    i = 1   n   ,    {    z    i   }    i = 1   n   )  is the total energy of the tessellation. The tessellation satisfies    C    i   \u2229    C    j   = 0\u0338 for i \u2260 j , and   \u222a   i      C    i   = \u03a9 .  For each cluster   C   i   , we define its mass   m   i   and its centroid    r    i   by:   (11)    m   i   =   \u2211    x  \u2208    C    i     d  (  x  )  ,    (12)     r    i   =     \u2211    x  \u2208    C    i      x  d  (  x  )      \u2211    x  \u2208    C    i     d  (  x  )    .       We point out the following two observations: first,   E   i    (    C    i   ,    z    i   )  is optimized when the site    z    i   coincides with the centroid    r    i   . Secondly, the energy change of   E   i    (    C    i   ,    z    i   )  due to the misalignment of the site    z    i   and the centroid    r    i   can be efficiently computed by a multiplication of the cluster mass   m   i   and the squared distance of the misaligned vector    \u2016  (    r    i   \u2212    z    i   )  \u2016    2   , instead of summing over the energy on each individual pixel/voxel. We denote the second observation as the energy increase rule. As shown in Sections\u00a0 4.4 and 4.5, this energy increase rule facilitates our optimization of Eq. (10). The remainder of the section is a simple proof of the two observations.  Consider the energy for cluster   C   i   :  (13)    E   i    (    C    i   ,    z    i   )  =   \u2211    x  \u2208    C    i     d  (  x  )     \u2016  (  x  \u2212    r    i   )  \u2016    2   +   \u2211    x  \u2208    C    i     d  (  x  )     \u2016  (    r    i   \u2212    z    i   )  \u2016    2   + 2   \u2211    x  \u2208    C    i     d  (  x  )    \u3008  x  \u2212    r    i   ,    r    i   \u2212    z    i   \u3009  .   Note that the third part of the above energy is essentially zero:  (14)    \u2211    x  \u2208    C    i     d  (  x  )    \u3008  x  \u2212    r    i   ,    r    i   \u2212    z    i   \u3009  =   \u2211    x  \u2208    C    i       \u3008 d  (  x  )   (  x  \u2212    r    i   )  ,    r    i   \u2212    z    i   \u3009  = 0 .   Thus the clustering energy   E   i    (    C    i   ,    z    i   )  consists of two parts: the first part is the compression energy A  (    C    i   )  , which measures the sum of weighted squared distances from the centroid    r    i   to individual pixel/voxel  x  :  (15)  A  (    C    i   )  =   \u2211   x \u2208    C    i     d  (  x  )     \u2016  (  x  \u2212    r    i   )  \u2016    2   .      The second part is the misalignment energy B  (   m   i   ,    r    i   ,    z    i   )  , which measures the energy increased due to the misalignment of the site    z    i   and the centroid    r    i   :  (16)  B  (   m   i   ,    r    i   ,    z    i   )  =   \u2211   x \u2208    C    i     d  ( x )     \u2016  (    r    i   \u2212    z    i   )  \u2016    2   =   m   i      \u2016  (    r    i   \u2212    z    i   )  \u2016    2   .      The misalignment energy achieves its minimum 0, if and only if the site    z    i   is located at the centroid    r    i   . Any misalignment will result in the energy increase by a multiplication of the cluster mass   m   i   and the squared distance of the misaligned vector    \u2016  (    r    i   \u2212    z    i   )  \u2016    2   .  Inspired by the surface simplification idea\u00a0 [40], we utilize a contraction operation to partition the pixels/voxels into n clusters, where n is a user specified number of the mesh nodes. The initial tessellation that conforms to the density distribution d  (  x  )  is achieved by successively applying the contraction operation.  At first, each pixel/voxel can be treated as a cluster, which may form pairs with its direct neighboring clusters. When a pair of clusters is contracted to a new cluster, a contraction cost is associated with this contraction operation. For a contraction operation  (    C    i   ,    C    j   )  \u2192    C    k   , the contraction cost is defined as:   E   k    (    C    k   ,    r    k   )  \u2212   E   i    (    C    i   ,    r    i   )  \u2212   E   j    (    C    j   ,    r    j   )  . All possible contraction operations, with the corresponding costs as the key factor, are inserted into a contraction heap, which records all the possible contractions in current tessellation.  Then, the total number of clusters is reduced to n by iteratively performing the least-cost contraction in the heap. Each time after the least-cost pair is selected, only a local update is needed to maintain the validity of the contraction heap: the remaining pairs of the two contracted clusters in the heap are deleted, and the potential contractions between the new cluster and its direct neighbors are inserted. This step is iteratively performed until the number of clusters is reduced to n .  The most time-consuming part in this step is the computation of the contraction cost. As shown in the Appendix, this cost can be calculated efficiently by using the energy increase rule as mentioned in Section\u00a0 4.3. In our implementation, to speed up the contraction process in 3D applications where there are huge number of voxels, each block of voxels is treated as a cluster at the beginning.  There is no surprise that the initial tessellation by greedily contracting the least-cost pair of clusters cannot minimize the objective function in Eq. (10). A pixel/voxel cannot freely decide which cluster it should reside in among the final n clusters. Each time a cluster pair is contracted, the pixels/voxels in the two clusters are bound to reside in the same cluster. Thus we relax the binding between pixels/voxels and clusters in the tessellation optimization.  Tessellation    {    C    i   }    i = 1   n   is updated according to the testing of the boundary pixels/voxels of each cluster. Here a boundary pixel/voxel of    C    i   is the one that has at least a neighboring pixel/voxel which does not belong to    C    i   . For a boundary pixel/voxel  x  \u2208    C    i   , we denote the set of clusters that the neighboring pixels/voxels of  x  reside in as    B     x    . We need to test whether changing its clustering to   C   j   \u2208    B     x    will decrease the energy in Eq. (10) or not. Actually, this energy change is a local operation, which only involves two clusters. To be more precise, as shown in the Appendix, the energy change can be efficiently computed by the energy increase rule as mentioned in Section\u00a0 4.3. If the energy change is less than 0, it means the pixel/voxel swap can decrease the energy of the objective function so as to optimize the tessellation. Otherwise, the current tessellation is best suitable for the tested pixel/voxel, and there is no further operation needed. If there is more than one cluster in    B     x    that can optimize the tessellation, we choose the one that can lead to the largest decrease of energy.  We propose a parallel algorithm for tessellation optimization in Algorithm 1. During each iteration, first we assign all the possible swaps for the boundary pixels/voxels in parallel by performing the swap testing. Note that the swap-testing operation for boundary pixels/voxels can be performed parallelly in each iteration. Then, we change the cluster ID for these pixels/voxels and update their mass and corresponding centroids for all clusters.  When there is no swap that can optimize the tessellation, the objective function in Eq. (10) reaches its local minimum. The corresponding tessellation is the locally-optimized CVT that conforms to the density field d  (  x  )  .          With the optimized tessellation computed in the previous step, we can place mesh nodes at the position of sites and connect mesh nodes using the adjacency information of the tessellation. The only challenge here is that the mesh does not cover the whole region of interest, particularly at the region of clusters on the boundary and corners of the image. This is because the sites always will be set at the positions of the centroids. This problem can be handled through a post-processing by using Constrained Delaunay triangulation (CDT). For the clusters on the boundary and corners of the image, we treat the mesh nodes differently: (1) for the sites of the boundary clusters, we set it as the centers of all boundary pixels/voxels (for instance: it is the middle point of an edge or a face); (2) for the corner clusters, usually each cluster only contains one corner of the image, the node is set exactly at the corner. Since the nodes have been moved, the connectivity defined by the adjacency of the original tessellation may not be a valid triangulation any more. We constrain the edges between the inner clusters using the adjacency information of the tessellation, while the edges associated with the nodes of the boundary or corners are re-triangled by CDT to maintain the \u201cDelaunay-like\u201d property.  During the image registration process, with the update of the transformation    W     ( k )    at each iteration of the registration, the importance field    \u2016  g   (  x  )  \u2016    2   characterizing the importance of each pixel/ voxel to minimize the matching criteria, changes in each step. So does the corresponding mesh.  During the registration process, we apply the iterative optimization algorithm to update the meshing. In each iteration with the current transformation    W    \u2032   , the density field can be re-computed by the warped source image  S  \u2218    W    \u2032   . We compute a new tessellation with the updated density field. The tessellation optimization can start from the CVT result of its earlier iteration. Finally, we can obtain the new dynamic mesh generated by CDT from the new optimized tessellation.  In order to apply the generated dynamic mesh in image registration, an additional step that computes the barycentric coordinate of each pixel/voxel is needed. We followed the parallel approach as\u00a0 [41] in our implementation.   EXPERIMENTS AND RESULTS   We adopt a hybrid implementation on both CPU and GPU. The initial tessellation step by contracting least-cost cluster pairs successively is implemented on CPU using C++, while the registration and the remainder of the dynamic meshing steps are implemented on GPU using CUDA 5.0.  For the hardware platform, the experiments are run on a desktop computer with Intel(R) Core i7-4770 CPU with 3.40\u00a0GHz, 32\u00a0GB DDR3 RAM, and NVIDIA GeForce GTX 660 GPU with 2\u00a0GB GDDR5 video memory.  In this subsection, we introduce the parameters that we choose in our experiments.  In the registration setting, for the MSSD image matching criteria in Eq. (3), we set the pyramid level as 3 in all the experiments. Since the weight \u03b2 balances the image matching criteria and the regularity of the transformation, and its value depends on the domain size, the number of mesh nodes, and the variation of the image intensity, we use an additional step to determine how much penalty should be employed, instead of using an absolute value. In the first iteration of registration, when the transformation    W     ( 1 )    is at hand, the image matching criteria term D  (  T  ,  S  \u2218    W     ( 1 )    )  and the regularity term R  (    W     ( 1 )    )  are computed, and \u03b2 is set to normalize the energy ratio   \u03b2 R  (    W     ( 1 )    )    D  (  T  ,  S  \u2218    W     ( 1 )    )    as 0.02, then it is fixed for the rest of the iterations.  In our dynamic meshing implementation, we first calculate the average value of the importance    \u2016  f   (  x  )  \u2016    2   . The constant base value \u03b1 is set as 0.1 times the average value. For the parameter \u03f5 in Algorithm 1 during tessellation optimization, we set it as 0 to get the exact local minimum of Eq. (10). Note that the computation time and the accuracy of this step can be balanced by the value of \u03f5 , e.g.,\u00a0setting \u03f5 = 0.0001 instead would accelerate the tessellation optimization step by allowing tessellation inaccuracy.   Table\u00a01 gives the computational statistics of the 2D and 3D image registration experiments by our proposed dynamic meshing method. It is clear that our method has high speed both in the registration and dynamic meshing steps.   Table\u00a02 gives the time performance with different number of nodes on the registration of 3D Lung Respiration with 100 iterations.  Our first 2D experiment illustrates the main feature of our dynamic meshing framework. We use a circle with radius of 60\u00a0pixels as source image, and the target image is a \u201cleaf\u201d shape, whose right half is the same semi-circle while the left half is a semi-ellipse with a semi-major axis of 600\u00a0pixels. We assign 100 nodes for the Circle to \u201cLeaf\u201d Shape registration experiment. In Fig.\u00a03 , we can clearly see that denser nodes are placed at the regions where local deformation is expected. In iteration 1, the right semi-circle only has the base value of the importance of the registration since the source image and the target image perfectly match at that region. As the registration goes on, once the boundary of the deformed image gets misaligned a little bit due to the interpolation from the displacement vector solved from mesh nodes, the density of the node in the misaligned region increases correspondingly. Thus more degrees of freedom will be generated automatically to \u201cdrive\u201d the boundary aligned. At the end of the registration, the nodes are distributed evenly at the boundary of the deformed circle.  In order to evaluate the usefulness of our proposed dynamic meshing method, we conduct a \u201cCircle to Epsilon\u201d experiment and compare our result with two widely used meshes: regular mesh and high fidelity mesh as shown in Fig.\u00a05(a) and (b). Regular mesh is widely used in spline-base free form of deformations (FFDS)\u00a0 [42,43], while high fidelity mesh is the desired mesh in the traditional image registration algorithms\u00a0 [1,8], which can well capture the boundary of the object structure. However, both these two kinds of meshes are static.  The source image is set as a circle with radius of 120\u00a0pixels, while the target image is an epsilon shape. The challenge here is we set the entrance into the epsilon shape to be 5\u00a0pixel width. We use 100 nodes in all the three kinds of meshes. The regular mesh is generated by the 10\u00d710 rectangular grid, while the high fidelity mesh is generated using the popular open source of the meshing software CGAL\u00a0 [44]. CGAL produces a mesh using the Delaunay refinement method. As it clearly shows in Figs.\u00a04 and 5 , regular mesh and high-fidelity mesh are trapped in the narrow entrance due to the limited degrees of freedom. However, our dynamic meshing approach is able to adjust its nodes to \u201cfit\u201d the extreme shape. Fig.\u00a04(d) shows our final result of transformation is physically plausible.   To illustrate the efficiency and usability of our method, we applied our dynamic meshing framework to 3D Lung Respiration volume data, which is a set of torso images acquired from a digital phantom, XCAT\u00a0 [45].  We compare our method with variational image meshing (VIM)\u00a0 [8], which preserves the boundary of the volume data. There are 3150 nodes used in their mesh, while 3000 nodes were used in ours. The noticeable difference is that our mesh is much denser at the bottom of the lung, which requires more degrees of freedom for the local deformation. Fig.\u00a06 shows our dynamic meshing strategy can facilitate the registration process and lead to a good registration result. Because it is difficult to visualize the difference between our dynamic mesh and VIM mesh in 3D case, we use the energy curves to compare. Fig.\u00a07 shows the energy curves of the dynamic meshing method and the VIM mesh method and we can see that our proposed dynamic meshing method has faster convergence speed.  The major limitation of our work is our mesh construction. As shown in Eq. (10), the meshing objective function we proposed only considers the optimal tessellation    {    C    i   }    i = 1   n   and the corresponding optimal sites    {    z    i   }    i = 1   n   . This strategy sets more degrees of freedom at regions where local deformation is expected. However, it does not take mesh element into account. The mesh elements are constructed directly by the dual graph and the CDT post-processing step described in Section\u00a0 4.6.  The dual triangulation of CVT usually generates well-shaped elements. In our implementation, when the degrees of freedom are not large enough, we observe bad-shaped elements. Mesh quality deteriorates when we apply the CDT post-processing to cover the whole region of interest, i.e. small angles ( < 15 \u00b0 ) in triangular elements and small dihedral angle ( < 10 \u00b0 ) of tetrahedral elements. However it should be noted that bad-shaped elements will not cause flip-over in our solved transformation since the diffeomorphic update rule described in Section\u00a0 3 always guarantees a diffeomorphic spatial transformation.  Investigating how the mesh elements can influence the registration process and integrating the mesh elements into the efficient optimization scheme is an interesting direction for our future work.   ACKNOWLEDGMENTS   The authors would like to thank the anonymous reviewers for their valuable comments and suggestions. This research work was partially supported by Cancer Prevention and Research Institute of Texas (CPRIT) under Grant No. RP110329, and National Science Foundation (NSF) under Grant Nos. IIS-1149737 and CNS-1012975.  In this appendix, we show how the energy increase rule mentioned in Section\u00a0 4.3 can be utilized to efficiently compute the cluster-pair contraction and cluster optimization.  If we contract a pair of clusters  (    C    i   ,    C    j   )  into    C    k   , the new clustering energy of    C    k   with its centroid    r    k   is:  (17)    E   k    (    C    k   ,    r    k   )  = A  (    C    k   )  =   \u2211    x  \u2208    C    k     d  (  x  )     \u2016  x  \u2212    r    k   \u2016    2   =   \u2211    x  \u2208    C    i     d  (  x  )     \u2016  x  \u2212    r    k   \u2016    2   +   \u2211    x  \u2208    C    j     d  (  x  )     \u2016  x  \u2212    r    k   \u2016    2   = A  (    C    i   )  + B  (   m   i   ,    r    i   ,    r    k   )  + A  (    C    j   )  + B  (   m   j   ,    r    j   ,    r    k   )  .      Therefore, the contraction cost is  (18)  A  (    C    k   )  \u2212  ( A  (    C    i   )  + A  (    C    j   )  )  = B  (   m   i   ,    r    i   ,    r    k   )  + B  (   m   j   ,    r    j   ,    r    k   )  =   m   i      \u2016  (    r    i   \u2212    r    k   )  \u2016    2   +   m   j      \u2016  (    r    j   \u2212    r    k   )  \u2016    2   .      As shown in Fig.\u00a08 , the contraction cost can be computed efficiently by keeping track of the mass and centroid of each cluster. It is simply the sum of two misalignment energy terms. After each contraction, the mass and centroid of the new cluster    C    k   can be updated by:   (19)    m   k   =   m   i   +   m   j   ,    (20)     r    k   =     m   i      r    i   +   m   j      r    j       m   i   +   m   j     .       Let us consider swapping a pixel    C    l   from    C    i   to    C    j   . Suppose after swapping,    C    i   becomes    C      i   \u2032     and    C    j   becomes    C      j   \u2032     , i.e.,    C    i   =    C      i   \u2032     \u222a    C    l   , and    C      j   \u2032     =    C    j   \u222a    C    l   , as shown in Fig.\u00a09 .  From Eq. (17), the clustering energy of    C    i   and    C    j   are:   (21)  A  (    C    i   )  = A  (    C      i   \u2032     )  + B  (   m     i   \u2032     ,    r      i   \u2032     ,    r    i   )  + A  (    C    l   )  + B  (   m   l   ,    r    l   ,    r    i   )  .    (22)  A  (    C      j   \u2032     )  = A  (    C    j   )  + B  (   m   j   ,    r    j   ,    r      j   \u2032     )  + A  (    C    l   )  + B  (   m   l   ,    r    l   ,    r      j   \u2032     )  .       The change of the energy after swapping depends only on the masses and centroids:  (23)  A  (    C      i   \u2032     )  + A  (    C      j   \u2032     )  \u2212 A  (    C    i   )  \u2212 A  (    C    j   )  = B  (   m   j   ,    r    j   ,    r      j   \u2032     )  + B  (   m   l   ,    r    l   ,    r      j   \u2032     )  \u2212 B  (   m     i   \u2032     ,    r      i   \u2032     ,    r    i   )  \u2212 B  (   m   l   ,    r    l   ,    r    i   )  =   m   j      \u2016    r    j   \u2212    r      j   \u2032     \u2016    2   \u2212   m     i   \u2032        \u2016    r    i   \u2212    r      i   \u2032     \u2016    2   +   m   l    (    \u2016    r    l   \u2212    r      j   \u2032     \u2016    2   \u2212    \u2016    r    l   \u2212    r    i   \u2016    2   )  .      The swapping is accepted only if the change of energy is less than zero. The masses and centroids for the corresponding new clusters can be updated by:   (24)    m     i   \u2032     =   m   i   \u2212   m   l   ,    (25)    m     j   \u2032     =   m   j   +   m   l   ,    (26)     r      i   \u2032     =     m   i      r    i   \u2212   m   l      r    l       m   i   \u2212   m   l     ,    (27)     r      j   \u2032     =     m   j      r    j   +   m   l      r    l       m   j   +   m   l     .        REFERENCES", "highlights": "Finite element method (FEM) is commonly used for deformable image registration. However, there is no existing literature studying how the superimposed mesh structure would influence the image registration process. We study this problem in this paper, and propose a dynamic meshing strategy to generate mesh structure for image registration. To construct such a dynamic mesh during image registration, three steps are performed. Firstly, a density field that measures the importance of a pixel/voxel\u2019s displacement to the registration process is computed. Secondly, an efficient contraction\u2013optimization scheme is applied to compute a discrete Centroidal Voronoi Tessellation of the density field. Thirdly, the final mesh structure is constructed by its dual triangulation, with some post-processing to preserve the image boundary. In each iteration of the deformable image registration, the mesh structure is efficiently updated with GPU-based parallel implementation. We conduct experiments of the new dynamic mesh-guided registration framework on both synthetic and real medical images, and compare our results with the other state-of-the-art FEM-based image registration methods."}