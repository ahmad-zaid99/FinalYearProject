{"id": "S001044851300119X", "article": "MAIN-TITLE Statistical tolerance analysis of over-constrained mechanisms with gaps using system reliability methods   HIGHLIGHTS          Gaps cannot be considered as random variables.      The tolerance analysis issue is formulated thanks to the quantifier notion.      Two defect probabilities are defined: functionality defect probability and assembly defect probability.      Defect probabilities are computed using a system reliability method: FORM system.          KEYPHRASES   Tolerance analysis  Over-constrained mechanisms  Gaps  FORM system  Monte Carlo  Reliability   In very competitive industrial fields such as the automotive industry, more and more interest is being paid to the quality level of manufactured mechanisms. It is very important to avoid warranty returns and manage the rate of out-of-tolerance products in production, which can lead to assembly line stoppages and/or wastage of out-of-tolerance mechanisms. The quality level of a mechanism can be evaluated by the number of faulty parts in production or by the number of warranty returns per year. However, these two methods of product quality evaluation remain a posteriori. Tolerance analysis is a more interesting way to evaluate a predicted quality level at the design stage. Scholtz\u00a0 [1] proposes a detailed review of classical methods whose goal is to predict functional characteristic variations based on component tolerances. Moreover, statistical tolerance analysis enables the definition of the probability that the functional requirement will be respected or not, as does the well-known RSS (Root Sum of Squares) method.  Advanced statistical tolerance analysis methods allow the defect probability of an existing design to be computed, knowing the dimension tolerances and functional requirements. These are called probabilistic approaches and this paper focuses mainly on them. Various assumptions about the statistical distributions of component dimensions can be made, based on their tolerances and capability levels. For example, the APTA (Advanced Probability-based Tolerance Analysis of products) method proposed by Gayton et\u00a0al.\u00a0 [2] enables random mean deviations and standard deviations of components\u2019 statistical distributions to be considered during the whole manufacturing phase. Defect probability, noted   P   D   in the following, is expressed in ppm (parts per million). It represents the probability that a functional requirement will not be satisfied in mass production. In a mechanism comprising several parts,   P   D   is usually computed based on a classic analytical chain of dimensions. Nigam and Turner\u00a0 [3] list most of classic methods which enable   P   D   to be computed. In addition, several methods from the structural reliability field can be used\u00a0 [4].  In some over-constrained mechanisms, gaps are present, allowing part displacements. Thus, depending on the gap situations, different dimension chains are required to control one functional characteristic. The formulation and computation of   P   D   for such mechanisms are not straightforward, and classic methods which deal with chains of dimensions cannot be used. Over-constrained mechanisms can be faulty because they cannot be assembled, or because they are not functional. Thus, two defect probabilities are defined: the assembly defect probability   P   D a   and the functionality defect probability   P   D f   .  The present paper focuses mainly on the functional requirement issue, because of its greater complexity compared to that of assembly. Nevertheless, the assembly issue is mentioned in the sections concerned. Section\u00a0 2 is devoted to presenting existing methods capable of dealing with these issues and details one in particular. It has already been used\u00a0 [5] and is based on an optimization algorithm and Monte Carlo (MC) simulations. Only MC simulations are required to compute   P   D a   . This methodology is very precise in general but requires a large number of runs (optimization runs for the functionality issue). The main contribution of this article is an innovative methodology detailed in Section\u00a0 3 and inspired by the work of Ballu et\u00a0al.\u00a0 [6]. It greatly decreases the computational effort. Both assembly and functionality defects are expressed as dependent event intersections.   P   D f   and   P   D a   are then computed thanks to system reliability methods, using the n -dimensional multivariate normal cumulative distribution function   \u03a6   n   . Both approaches are compared for two industrial mechanisms: one inspired by a coaxial connector supplier (Fig.\u00a01 ) and one prismatic joint (Fig.\u00a02 ). The results are given and commented in Sections\u00a0 4 and 5. The proposed method can be adapted to other over-constrained mechanisms featuring gaps.  In the literature, gaps are often neglected, mainly because only iso-constrained mechanisms are studied. In over-constrained mechanisms, they have to be taken into account\u00a0 [6\u20138]. To study such mechanisms, all mobilities between parts, arising from the presence of gaps, have to be considered. For this purpose, a new formulation of the tolerance analysis issue based on the quantifier notion was developed by Dantan and Qureshi\u00a0 [9] and Qureshi et\u00a0al. [5]:  \u2022 The mathematical expression of tolerance analysis for the assembly requirement is: For all acceptable deviations (deviations which are inside tolerances), there exists a gap situation such that the assembly requirements are verified.  The mathematical expression of tolerance analysis for the functional requirement is: For all acceptable deviations (deviations which are within tolerances), and for all admissible gap situations, the functional requirements are verified.  In the manufacturing phase, several deviations appear due to manufacturing processes. These are called manufacturing deviations. Many imperfections types are identified in a geometrically toleranced mechanism. With a view to simplicity in this paper, only dimensional deviations are considered. As it is commonly agreed in the literature\u00a0 [6,3,1], deviations  D   ( \u03c9 )  are modeled by random variables where \u03c9 is the hazard. Their means are the nominal values, while their standard deviations depend on the process characteristics. The authors are currently investigating applications involving positional (location and orientation) deviations. These new deviations are also modeled as random variables. The number of concerned variables increases but the whole resolution methodology is the same. Nevertheless, considering positional deviations in a 3-dimensional context could lead to highly non-linear functions which then have to be piecewise linearized. These developments will be covered in further publications. According to the literature\u00a0 [10], form deviations are negligible compared to positional ones. Thus, they will be omitted in the presented study and the following ones. To take gaps into account, part positions are modeled by deterministic free variables  P  . These variables are not considered as random, since part displacements cannot be controlled, but only limited by part dimensions. In 3 dimensions, a part has 6 degrees of freedom (3 translations and 3 rotations) which involve 6 displacement variables  P  per mobile part.  As a preliminary step, it is useful to determine whether the mechanism, composed of several parts, can be assembled. As Dantan and Qureshi\u00a0 [9] express it, one gap situation has to be found such that the assembly requirements are verified. Assembly is possible if all assembly constraints are respected:  (   \u22c2   i = 1     N   m       m   i    (  D  ,  P  )  \u2264 0 )  , where   N   m   is the number of   m   i    (  D  ,  P  )  \u2264 0 assembly constraints. The general purpose of tolerance analysis is to compute the following assembly defect probability:  (1)    P   D a   = Prob  ( \u2200  P  , \u2203 i ,   m   i    (  D  ,  P  )  > 0 )  .   As gaps are involved, this defect probability computation is potentially complex. For practical purposes, it can often be simplified so that assembly constraints no longer depend on gaps:  (2)    P   D a   = Prob  (   \u22c3   i = 1     N   m       m   i    (  D  )  > 0 )  = 1 \u2212 Prob  (   \u22c2   i = 1     N   m       m   i    (  D  )  \u2264 0 )  .      Once the mechanism is assembled, its functionality is verified through at least one identified functional characteristic, dependent on deviation  D  and position  P  variables:  (3)    F   c   = f  (  D  ,  P  )  .   For functionality issues on mechanisms with gaps, where parts are mobile, the functional requirement must be respected for all admitted positions  P  of parts. Due to these displacements,   N   c   non-interference constraints   g   i    (  D  ,  P  )  \u2264 0 , corresponding to   N   c   potential contact points, are defined. These prevent parts from coming into collision with each other. They can be established thanks to different methods: small displacement torsor\u00a0 [11], matrices\u00a0 [12], T-Map\u00a0 [8], or directly by considering each potential contact point. They constitute the non-interference domain \u03a9  (  D  )  representing the admitted positions  P  of parts such that they do not collide with each other. The system is functional if    \u2200  P  \u2208 \u03a9  (  D  )  ,    F   c    (  D  ,  P  )  \u2208  [   F     c    min      ;   F     c    max      ]     (4)  \u03a9  (  D  )  :  P  /   \u22c2   j = 1     N   c       g   j    (  D  ,  P  )  \u2264 0 .       Finally, the goal is to compute the   P   D f   probability that functional requirements are not respected. It is defined as  (5)    P   D f   = Prob  ( \u2203  P  \u2208 \u03a9  (  D  )  ,   F   c    (  D  ,  P  )  \u2209  [   F     c    min      ,   F     c    max      ]  )  = Prob  ( \u2203  P  \u2208 \u03a9  (  D  )  ,   F   c    (  D  ,  P  )  <   F     c    min      )  + Prob  ( \u2203  P  \u2208 \u03a9  (  D  )  ,   F   c    (  D  ,  P  )  >   F     c    max      )  .      Remarks:  \u2022 In the next sections, as the two probability terms can be treated similarly, the lower bound   F     c    min      is not considered.  The functionality notion makes sense only if the mechanism can be assembled. Thus, the functionality defect probability   P   D f   is the probability that the mechanism can be assembled (thanks to the non-interference domain \u03a9  (  D  )  ) but being non-functional. It should be noted that non-interference equations   g   i    (  D  ,  P  )  can be close to assembly equations   m   i    (  D  ,  P  )  but are significantly different.  The defect probabilities defined above can be computed thanks to the well-known Monte Carlo (MC) simulation method\u00a0 [5]. Due to the presence of gaps, the functionality formulation requires all the admitted part positions to be taken into consideration. To ensure this, an optimization algorithm is called for each sample of random variables  D  to find the worst functional characteristic value max  (   F   c   )  with respect to the associated functional requirement   F     c    max      . For a given value of  D  ,   F   c    (  D  ,  P  )  is maximized under   N   c   non-interference constraints:   g   j    (  D  ,  P  )  \u2264 0 , j = 1 to   N   c   . The functionality defect probability is written as follows:  (6)    P   D f   = Prob  (   max    P  \u2208 \u03a9  (  D  )     [   F   c    (  D  ,  P  )  >   F     c    max      ]  )  .      The algorithm is composed of four steps. The first three steps are repeated   N   l   times: k = 1 to   N   l   , where   N   l   is the number of MC simulations.  1. A set of dimensions    D     ( k )    is randomly decided.  Once the non-interference domain \u03a9  (    D     ( k )    )  is constituted,   max    P  \u2208 \u03a9  (    D     ( k )    )     [   F   c    (    D     ( k )    ,  P  )  ]  is computed using an optimization algorithm.  The indicator   I   D f    ( k )    is introduced:  (7)    I   D f    ( k )    =  {    1   if   max    P  \u2208 \u03a9  (    D     ( k )    )     [   F   c    (    D     ( k )    ,  P  )  ]  >   F     c    max          0   else.          Finally,   P   D f   =  E   [    I    D f   ]     For the assembly issue, the solution is simpler: the second step is skipped and the indicator is defined as  (8)    I   D a    ( k )    =  {    1   if   max   i = 1     N   a      [   m   i    (  D  )  ]  > 0     0   else.       Finally,   P   D a   = E  [    I    D a   ]  .  MC defect probabilities are estimators. Thus, the 95% confidence interval of   P   D   can be computed to evaluate the accuracy of the result (see\u00a0 [4] for more details):  (9)    P   D   \u2212 1.96   \u03c3     P   D     \u2264   P   D   \u2264   P   D   + 1.96   \u03c3     P   D       where   \u03c3     P   D     is the defect probability standard deviation, dependent on the number of MC simulations   N   l   , defined as  (10)    \u03c3     P   D     =       P   D    ( 1 \u2212   P   D   )      N   l       .      This methodology can be very precise but requires millions of runs to reach low   P   D   values (optimization runs for   P   D f   ), so an alternative methodology is proposed to reduce computation time. It will be presented in the next section.  The first presented methodology uses MC simulations, but it requires millions of optimization runs. The objective of this new approach is to reduce that computation time.  As previously stated, to deal with the functionality issue, all the part position situations have to be taken into consideration. The first methodology is global, since it considers all the contact points at once (i.e.\u00a0the   N   c   non-interference constraints). In fact, it is possible to decompose the global defect event into several identified ones, each one relative to a contact point situation. This is the aim of the proposed methodology. This approach is called \u201csystem\u201d since the problem is composed of a system of events. The advantage of this approach is that the position variables disappear in Eq. (12) for a given contact point situation.  P  variables are replaced by      P    \u02c6     i   : the part coordinates in the i -th contact point situation. It is then much easier to verify that the functional requirements are respected. A contact point situation is defined such that all degrees of freedom are removed; thus 6 non-interference constraints are equal to 0:   g   i    (  D  ,  P  )  = 0 , i = 1 to 6. These constraints are linearized thanks to a Taylor expansion around a pertinent point in  P  space, depending on the application. Since part position variations are very small in the tolerance analysis problem, the linearized equations     g   \u0303     i    (  D  ,  P  )  = 0 are very close to the original ones, which enables the problem to be addressed much more easily. The negligible impact of this linearization phase on the results will be demonstrated in the following applications (Sections\u00a0 4 and 5). For each of the   N   s   =   C     N   c     6   contact point situations, it is possible to solve the i -th ( i = 1 to   N   s   ) linear problem:     g   \u0303        s    j    ( i )       (  D  ,  P  )  = 0 , j = 1 to 6 whose solution is      P    \u02c6     i   , where    s    j    ( i )    is the j -th term of the    s     ( i )    vector. This vector contains the identification number combinations (i.e.\u00a06 numbers from 1 to   N   c   ) of the non-interference constraints concerned in the i -th contact point situation. If      P    \u02c6     i   exists, it means that the first six non-interference constraints are respected. Then the other ones, making up the non-interference domain, have to be checked (i.e.\u00a0the   N   c   \u2212 6 others). As constraints are linear and therefore monotonous, the extreme   F   c   value is given by obtaining the maximum functional characteristic from among all the individual situations:  (11)    max    P  \u2208 \u03a9  (  D  )     (   F   c    (  D  ,  P  )  )  =   max   i = 1     N   s      [   F   c    (  D  ,      P    \u02c6     i   )  ,   \u22c2   j = 1     N   c   \u2212 6     g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 ]    where      s    \u0304     j    ( i )    is the vector containing the identification numbers of the non-interference constraints which are not involved in the i -th contact point situation. Thus, according to structural systems reliability theory\u00a0 [13], the original defect probability is transformed as follows; hence Eq. (6) becomes  (12)    P   D f   = Prob  (   F     c    max      \u2212   max   i = 1     N   s      [   F   c    (  D  ,      P    \u02c6     i   )  ,   \u22c2   j = 1     N   c   \u2212 6     g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 ]  < 0 )  = Prob  (   min   i = 1     N   s      [   L   i    (  D  )  ,   \u22c2   j = 1     N   c   \u2212 6     g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 ]  < 0 )  = Prob  (   \u22c3   i = 1     N   s      [  (   L   i    (  D  )  < 0 )    \u22c2   j = 1     N   c   \u2212 6    (   g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 )  ]  )    where the performance functions are   L   i    (  D  )  =   F     c    max      \u2212   F   c    (  D  ,      P    \u02c6     i   )  . The problem is thus reduced to a system problem of   N   s   unions of   N   c   \u2212 6 intersections of dependent events. However, the computation of   P   D f   is still not trivial. It can be simplified in two ways: firstly, the number   N   s   of considered situations can be reduced; secondly, unions of intersections can be transformed.  For practical reasons, only a few of the   N   s   contact point situations are realistic in the dimension variation domain. Some of them are mechanically unfeasible, extremely rare or redundant with others. For all these reasons, an identification phase is recommended to ascertain the dominant situations. Ballu et\u00a0al.\u00a0 [6] do this by knowledge and expertise, but it is not always possible. Another possibility is to run the optimization used in the first methodology a small number of times ( 1   0     N   r     ) in the dimension variation domain. For each set of dimensions, the optimization algorithm finds max  (   F   c   )  while saturating some constraints. These saturated constraints represent the identified contact point situations which cover defect probabilities. This method, which is not obligatory, enables a significant reduction in the number   N   s   of considered events for most mechanisms. Indeed, taking into consideration non-dominant situations would increase the mathematical complexity of the defect probability expression. The computing time would also increase slightly. 1   0     N   r     runs ensure that the appearance probability of non-identified situations is less than 1   0     N   r   \u2212 6   ppm. The number of dominant contact point situations is noted   N   d s   .  The second simplification step consists of transforming the   P   D f   formulation thanks to the Poincar\u00e9 formula:  (13)    P   D f   =   \u2211   i = 1     N   d s     Prob  [  (   L   i    (  D  )  < 0 )    \u22c2   j = 1     N   c   \u2212 6    (   g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 )  ]  \u2212   \u2211   i < k   Prob  [  (   L   i    (  D  )  < 0 )    \u22c2   j = 1     N   c   \u2212 6    (   g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 )  \u22c2  (   L   k    (  D  )  < 0 )    \u22c2   j = 1     N   c   \u2212 6    (   g        s    \u0304     j    ( k )       (  D  ,      P    \u02c6     k   )  \u2264 0 )  ]  + \u22ef +    ( \u2212 1 )      N   d s   \u2212 1   Prob  (   \u22c2   i = 1     N   d s      [  (   L   i    (  D  )  < 0 )    \u22c2   j = 1     N   c   \u2212 6    (   g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 )  ]  )  .      This formula transforms unions of event intersections into simple event intersections. It allows   P   D f   to be computed more easily.  Several methods, such as FORM (First Order Reliability Method), can deal with this kind of system problem very efficiently\u00a0 [4]. Each event (   L   i    (  D  )  < 0 for example) is considered individually by the classic FORM method. The preliminary task is to transform physical variables  D  into standard ones  U  (i.e.\u00a0Gaussian variables with means and variances respectively equal to 0 and 1). In the case of uncorrelated Gaussian variables, the transformation is direct:   U   i   =  (   D   i   \u2212   \u03bc   i   )  /   \u03c3   i   where   \u03bc   i   and   \u03c3   i   are respectively the mean and standard deviation of the random variable   D   i   . In other cases (non-Gaussian distributions for example), it can be more complicated, but methods exist and are understood (see\u00a0 [4] for details). In the new  U  space, a function   G   i    (  D  )  becomes   H   i    (  U  )  . Each function   H   i    (  U  )  , called performance function, is linearized at the most probable failure point    U     ( i )  \u2217   . This gives rise to hyper-planes (straight lines in 2 dimensions) whose equation are     H   \u0303     i    (  U  )  = 0 .    U     ( i )  \u2217   is the closest point to the origin which respects the constraint   H   i    (  U  )  = 0 . Its distance from the origin is noted   \u03b2   i   and called the reliability index. The FORM method also provides direction cosines:    \u03b1    i   = \u2207   H   i    (    U     ( i )  \u2217   )  /  \u2016 \u2207   H   i    (    U     ( i )  \u2217   )  \u2016  . Once all performance functions ( n ) are treated separately, the second stage consists of considering unions or intersections of events, which is the system phase. Let F be the following defect domain:  (14)  F =  {  D  /   \u22c2   i = 1   n     G   i    (  D  )  < 0 }  =  {  U  /   \u22c2   i = 1   n     H   i    (  U  )  < 0 }  \u2248  {  U  /   \u22c2   i = 1   n       H   \u0303     i    (  U  )  < 0 }  .       Fig.\u00a03 illustrates the FORM concepts in a 2-dimensional standard  U  space. The F domain is grayed out. The dependency of different events, i.e.\u00a0the orientation of hyper-planes, is taken into account through a covariance matrix defined using direction cosines. The  ( i , j )  -th term of  [  \u03c1  ]  is   \u03c1   i j   =  \u3008    \u03b1     ( i )    ,    \u03b1     ( j )    \u3009  , where  \u3008 \u2022 , \u2022 \u3009  is the scalar product. Finally, the defect probability associated with the F domain is estimated using the n -dimensional multivariate normal cumulative distribution function   \u03a6   n   :  (15)    P   D   = Prob  (   \u22c2   i = 1   n     G   i    (  D  )  < 0 )  \u2248 Prob  (   \u22c2   i = 1   n       H   \u0303     i    (  U  )  < 0 )  =   \u03a6   n    ( \u2212  \u03b2  ,  [  \u03c1  ]  )  .      In the case illustrated in Fig.\u00a03, the defect probability is expressed as follows:  (16)    P   D   =   \u03a6   3    (  { \u2212   \u03b2   1   , \u2212   \u03b2   2   , \u2212   \u03b2   3   }  ,  [  \u03c1  ]  )  .          \u03a6   n   is computed thanks to the Genz method\u00a0 [14], which evaluates the n -dimensional multivariate normal cumulative distribution function almost instantaneously. As limit-state functions are replaced by hyper-planes, the method gives only an approximation of   P   D   , but it also provides its confidence interval. Again, due to low part dimension variations in a tolerance analysis context, this linearization is often very accurate. This method can easily be applied to compute both defect probabilities   P   D f   and   P   D a   given respectively by Eqs. (13) and (2), composed only of event intersections.  In this section, a case study is presented, based on an industrial problem. It is a 2D representation of an electric coaxial connector designed and manufactured by RADIALL SA, comprising 2 cylindrical parts (see Fig.\u00a04 ). Due to the presence of gaps in the mechanism, part 1 is mobile while part 2 is fixed. The position of part 1 is located in 2D space thanks to the displacement variable vector:  P  =  { X , Y , \u03b1 }  . Rotational symmetry is taken into account by constraining \u03b1 positive. Dimensions  D  are modeled by Gaussian variables and their characteristics are noted in Table\u00a01 .  This coaxial connector can be assembled if the dimensions of part 1 are lower than the corresponding dimensions of part 2, if the following assembly constraints are verified:      m   1    (  D  )  =   D   3   \u2212   D   4   \u2264 0    (17)    m   2    (  D  )  =   D   1   \u2212   D   2   \u2264 0       m   3    (  D  )  =   D   6   \u2212   D   5   \u2264 0 .    The assembly defect probability can be computed thanks to the FORM system method described in Section\u00a0 4:  (18)    P   D a   = 1 \u2212 Prob  (  (   m   1    (  D  )  \u2264 0 )  \u22c2  (   m   2    (  D  )  \u2264 0 )  \u22c2  (   m   3    (  D  )  \u2264 0 )  )  = 1 \u2212   \u03a6   3    ( \u2212   \u03b2   1   , \u2212   \u03b2   2   , \u2212   \u03b2   3   ,  [ \u03c1 ]  )  .   As the functions are independent, the covariance matrix  [ \u03c1 ]  is equal to the identity matrix. Thus,   \u03a6   3    ( \u2212   \u03b2   1   , \u2212   \u03b2   2   , \u2212   \u03b2   3   ,  [ \u03c1 ]  )  = \u03a6  ( \u2212   \u03b2   1   )  \u03a6  ( \u2212   \u03b2   2   )  \u03a6  ( \u2212   \u03b2   3   )  , with      \u03b2   1   =     \u03bc     D   3     \u2212   \u03bc     D   4           \u03c3     D   4     2   +   \u03c3     D   3     2       = \u2212 2.357    (19)    \u03b2   2   =     \u03bc     D   1     \u2212   \u03bc     D   2           \u03c3     D   2     2   +   \u03c3     D   1     2       = \u2212 2.357       \u03b2   3   =     \u03bc     D   6     \u2212   \u03bc     D   5           \u03c3     D   5     2   +   \u03c3     D   6     2       = \u2212 2.357 .    Finally,  (20)    P   D a   = 1 \u2212 \u03a6  ( 2.357 )  \u03a6  ( 2.357 )  \u03a6  ( 2.357 )  = 27  380  ppm\u00a0.    Table\u00a02 shows   P   D a   results computed by MC simulations and by the FORM system. Both computation methods give comparable results in a very short time because this assembly issue is trivial. However, it is interesting to note that the FORM system methodology provides the exact probability result instantaneously while MC simulations provide a confidence interval on the result.  Concerning the functionality issue, the non-interference domain \u03a9  (  D  )  is determined by considering each potential contact point. This depends on the mechanism dimensions and defines the admitted positions and orientation  P  of part 1:      g   1    (  D  ,  P  )  =     D   6     2   sin  ( \u03b1 )  +     D   3     2   cos  ( \u03b1 )  \u2212     D   4     2   + X \u2264 0       g   2    (  D  ,  P  )  =   D   7   tan  ( \u03b1 )  +     D   1     2 cos  ( \u03b1 )    +  (     D   5     2   \u2212 Y )  tan  ( \u03b1 )  \u2212 X \u2212     D   2     2   \u2264 0       g   3    (  D  ,  P  )  =     D   3     2   sin  ( \u03b1 )  +     D   6     2   cos  ( \u03b1 )  \u2212     D   5     2   + Y \u2264 0    (21)    g   4    (  D  ,  P  )  =     D   6     2   sin  ( \u03b1 )  +     D   3     2   cos  ( \u03b1 )  \u2212     D   4     2   \u2212 X \u2264 0       g   5    (  D  ,  P  )  =     D   1     2 cos  ( \u03b1 )    +  (     D   5     2   \u2212 Y )  tan  ( \u03b1 )  + X \u2212     D   2     2   \u2264 0       g   6    (  D  ,  P  )  =     D   3     2   sin  ( \u03b1 )  +     D   6     2   cos  ( \u03b1 )  \u2212     D   5     2   \u2212 Y \u2264 0     \u03a9  (  D  )  :  P  /   \u22c2   i = 1   6     g   i    (  D  ,  P  )  \u2264 0 .       The functional characteristic is   F   c   =   \u03b1    max    . To achieve an adequate electrical connection,   \u03b1    max    , which represents the largest \u03b1 angle admitted by the mechanism, must not exceed a given threshold   F     c    max      = 0.01  rad . The functional requirement is  (22)    \u03b1    max     (  D  )  =   max    P  \u2208 \u03a9  (  D  )     ( \u03b1 )  \u2264   F     c    max      .      To compute   P   D f   with the proposed method, the preliminary task is to linearize the initial non-interference constraints g  (  D  ,  P  )  in Eq. (21) with respect to the displacement space  P  by using a Taylor expansion around a particular point:  ( X = 0 , Y = 0 , \u03b1 =   F     c    max      )  (to not be confused with the most probable failure point). This point is very pertinent because   F     c    max      is the angle at which the functional characteristic value is critical. Then the important contact point situations are identified. In 2D space, such a situation has three contact points among the six potential ones (   N   c   = 6 ). As a consequence, there exist   N   s   =   C   6   3   = 20 potential contact point situations. Five of these are identified thanks to their contact point identification, defined in Fig.\u00a04 in this particular case:    s     ( 1 )    =  { 1 , 2 , 3 }  ,    s     ( 2 )    =  { 1 , 3 , 4 }  ,    s     ( 3 )    =  { 2 , 3 , 6 }  ,    s     ( 4 )    =  { 1 , 3 , 6 }  and    s     ( 5 )    =  { 2 , 3 , 5 }  as dominant situations. They are obtained using 100 optimization runs. For each of them, a linear problem is solved in order to obtain the  P  -coordinates    P    \u02c6   of these extreme situations. For example, the first one is defined as follows:  (23)       P    \u02c6     1    (  D  )  =  P  /  {        g   \u0303     1    (  D  ,  P  )  = 0         g   \u0303     2    (  D  ,  P  )  = 0         g   \u0303     3    (  D  ,  P  )  = 0 .          Based on these coordinates, 5 performance functions are defined:  (24)    L   i    (  D  )  =   F     c    max      \u2212   F   c    (  D  ,      P    \u02c6     i    (  D  )  )  ,  i = 1 \u2013 5 .   These functions, although resulting from a linear system, are not linear with regard to  D  space. Thus, the FORM method transforms them into hyper-planes at the most probable failure point. The intersection of events is treated by the FORM system method and   P   D f   is computed thanks to the multi-dimensional Gaussian cumulative distributive function   \u03a6   n   . The following equation enables the computation of the defect probability presented Eq. (13):  (25)    P   D f   \u2248   \u2211   i = 1   5     \u03a6   4    ( \u2212    \u03b2     ( i )    ,    [  \u03c1  ]     ( i )    )  \u2212   \u2211   i < j     \u03a6   8    ( \u2212    \u03b2     ( i j )    ,    [  \u03c1  ]     ( i j )    )  + \u22ef +    ( \u2212 1 )      N   d s   \u2212 1     \u03a6   20    ( \u2212    \u03b2     ( i j \u2026   N   d s   )    ,    [  \u03c1  ]     ( i j \u2026   N   d s   )    )    where    \u03b2     ( i )    ,    \u03b2     ( i j )    ,    \u03b2     ( i j \u2026   N   d s   )    ,    [  \u03c1  ]     ( i )    ,    [  \u03c1  ]     ( i j )    and    [  \u03c1  ]     ( i j \u2026   N   d s   )    are the reliability index vectors and the covariance matrices associated respectively with the i -th contact point situation, the i -th and j -th situations and the   N   d s   situations together. For example, the first term of Eq. (25) uses   \u03a6   4   because there is an intersection of   N   c   \u2212 3 + 1 = 6 \u2212 3 + 1 = 4 events in the first term of Eq. (13) (   N   c   \u2212 6 + 1 in 3 dimensions but   N   c   \u2212 3 + 1 in this particular plane model). Thus,    \u03b2     ( i )    and    [  \u03c1  ]     ( i )    are respectively a 4-dimensional vector and square matrix.  For a better comprehension, Fig.\u00a05 shows the defect area as regards the first identified situation in  (   U   1   ,   U   2   )  space while  (   U   3   ,   U   4   ,   U   5   ,   U   6   ,   U   7   )  are fixed. Fig.\u00a06 shows the whole defect area in the same space. The complete defect area is the union of individual defect areas relative to each contact point situation. Some lines cannot be displayed since they are outside the frame. Some lines are also merged with others. It is interesting to note that most defect areas have common limits and are disjoint. Nevertheless, the third and fourth ones have a common intersection. This figure helps to understand the necessity of using the Poincar\u00e9 formula to compute   P   D f   (Eq. (13)).  The goal of this application is to show that tolerance analysis can be conducted at a very low computing cost using the FORM system methodology for simple over-constrained mechanisms with gaps. Different solution methods are proposed based on the two presented methodologies, using both linear and non-linear non-interference constraints. Results in ppm are listed in Table\u00a03 with their 95% confidence intervals (C.I.).   N   l   =   10   7   runs were used for MC, so the 95% C.I. width of   P   D f   is approximately equal to 300 ppm. The FORM system results have also a 95% C.I. due to the Genz method. The low difference between the two MC results shows that non-interference constraint linearization has no measurable impact on   P   D f   . Also, as the FORM system results are very close to those of MC (Table\u00a03), it shows that the FORM linearization phase has no measurable impact either. This argues that the FORM system methodology can deal with this kind of problem with a very low computing cost (10\u00a0min as opposed to 10\u00a0h).  To give an idea of the weight of each dominant contact point situation, the individual defect probabilities associated with each situation were computed as   (26)    P   D f    ( i )    = Prob  [  (   L   i    (  D  )  < 0 )    \u22c2   j = 1   3    (     g   \u0303     j    (  D  ,      P    \u02c6     i   )  \u2264 0 )  ]        P   D f    ( 1 )    = 30  527  ( 65 )   ppm\u00a0,    P   D f    ( 2 )    = 1861  ( 12 )   ppm\u00a0,    P   D f    ( 3 )    = 13  770  ( 27 )   ppm    (27)    P   D f    ( 4 )    = 14  781  ( 32 )   ppm\u00a0,    P   D f    ( 5 )    = 1  ( 0.01 )   ppm\u00a0.       This shows that different situations play a significant role in the defect scenario. Based on these individual situation results, it is possible to compute a   P   D f   upper bound, which is simpler and faster to obtain, but quite distant from the actual value in this case:  (28)    P   D f   \u2264   \u2211   i = 1     N   d s       P   D f    ( i )    = 60  940  ( 136 )   ppm\u00a0.      Now let us consider a second industrial case study, already presented by Ballu et\u00a0al.\u00a0 [6] and Wu et\u00a0al.\u00a0 [15]. The new proposed methodology is applied to compute defect probabilities for this mechanism. It is a prismatic joint composed of 2 shafts {3, 4}, one bearing {1} and one other part {2} (see Fig.\u00a07 ). The axles slide in part {1} and are attached to part {2} by hooping. Part {1} is fixed, while parts {2, 3, 4} are positioned in the vertical direction thanks to displacement variables  P  =  {   Y   K   , \u03b1 }  (see Fig.\u00a07). Parts {2, 3, 4} are designed to move mainly in the horizontal direction, but this study will investigate only vertical displacements, and horizontal movements are not considered here.   l   1   ,   l   2   and   l   3   define the horizontal positions of parts which are fixed. They are modeled by deterministic variables. Due to manufacturing defects, the shafts are not parallel, their borings are not coaxial with them and their dimensions are not at their nominal values. Thus, gaps are introduced between shafts and borings, allowing displacements. Dimensions  D  characterize relevant manufacturing deviations.   D   1   to   D   8   are the distances between the real axes of the borings and the shafts at part {1} plane level.   D   9   to   D   12   are the diameters of the shafts and borings (see Fig.\u00a08 ). They are modeled by Gaussian variables.  D  and  l  characteristics are noted in Table\u00a04 .  The assembly constraints of this mechanism, obtained geometrically, are as follows:      m   1    (  D  )  = 2   D   1   \u2212   2  (   l   1   +   l   2   +   l   3   )      l   3       D   5   \u2212  ( 2 \u2212   2  (   l   1   +   l   2   +   l   3   )      l   3     )    D   6   +   D   9   \u2212   D   11   \u2212 2   D   3   +   2  (   l   1   +   l   2   +   l   3   )      l   3       D   7   +  ( 2 \u2212   2  (   l   1   +   l   2   +   l   3   )      l   3     )    D   8   +   D   10   \u2212   D   12   \u2264 0       m   2    (  D  )  = \u2212 2   D   1   +   2  (   l   1   +   l   2   +   l   3   )      l   3       D   5   +  ( 2 \u2212   2  (   l   1   +   l   2   +   l   3   )      l   3     )    D   6   +   D   9   \u2212   D   11   + 2   D   3   \u2212   2  (   l   1   +   l   2   +   l   3   )      l   3       D   7   \u2212  ( 2 \u2212   2  (   l   1   +   l   2   +   l   3   )      l   3     )    D   8   +   D   10   \u2212   D   12   \u2264 0    (29)    m   3    (  D  )  = 2   D   2   \u2212   2  (   l   2   +   l   3   )      l   3       D   5   \u2212  ( 2 \u2212   2  (   l   2   +   l   3   )      l   3     )    D   6   +   D   9   \u2212   D   11   \u2212 2   D   4   +   2  (   l   2   +   l   3   )      l   3       D   7   +  ( 2 \u2212   2  (   l   2   +   l   3   )      l   3     )    D   8   +   D   10   \u2212   D   12   \u2264 0       m   4    (  D  )  = \u2212 2   D   2   +   2  (   l   2   +   l   3   )      l   3       D   5   +  ( 2 \u2212   2  (   l   2   +   l   3   )      l   3     )    D   6   +   D   9   \u2212   D   11   + 2   D   4   \u2212   2  (   l   2   +   l   3   )      l   3       D   7   \u2212  ( 2 \u2212   2  (   l   2   +   l   3   )      l   3     )    D   8   +   D   10   \u2212   D   12   \u2264 0       m   5    (  D  )  =   D   9   \u2212   D   11   \u2264 0       m   6    (  D  )  =   D   10   \u2212   D   12   \u2264 0 .    These constraints enable the shafts to penetrate part 1 without stress or deformation. To compute   P   D a   , once again both MC simulations and the FORM system can be used, since the defects do not depend on part positions. The reliability indexes of the FORM system method are computed analytically, since the constraints are linear. Table\u00a05 shows the assembly defect results for this case study.  The mechanism\u2019s functionality depends on the lower position min  (   Y   K   )  of point K , belonging to part {2}, in the vertical direction (see Fig.\u00a07). The functional requirement is that this position be greater than 0.94\u00a0mm below its nominal position: min  (   Y   K   )  \u2265   Y     K    min      = \u2212 0.94 . To compute   P   D f   , the preliminary task is to establish non-interference constraints. There are 4 potential contact points represented in Fig.\u00a07. Each one involves a linearized constraint:        g   \u0303     1    (  D  ,  P  )  =   Y   K   +  (   l   1   +   l   2   +   l   3   )  \u03b1 +   D   6   +     D   9     2   \u2212     D   6   \u2212   D   5       l   3      (   l   3   +   l   2   +   l   1   )  \u2212   D   1   \u2212     D   11     2   \u2264 0         g   \u0303     2    (  D  ,  P  )  = \u2212   Y   K   \u2212  (   l   2   +   l   3   )  \u03b1 \u2212   D   6   +     D   9     2   +     D   6   \u2212   D   5       l   3      (   l   3   +   l   2   )  +   D   2   \u2212     D   11     2   \u2264 0    (30)      g   \u0303     3    (  D  ,  P  )  =   Y   K   +  (   l   1   +   l   2   +   l   3   )  \u03b1 +   D   8   +     D   10     2   \u2212     D   8   \u2212   D   7       l   3      (   l   3   +   l   2   +   l   1   )  \u2212   D   3   \u2212     D   12     2   \u2264 0         g   \u0303     4    (  D  ,  P  )  = \u2212   Y   K   \u2212  (   l   2   +   l   3   )  \u03b1 \u2212   D   8   +     D   10     2   +     D   8   \u2212   D   7       l   3      (   l   3   +   l   2   )  +   D   4   \u2212     D   12     2   \u2264 0     \u03a9  (  D  )  :  P  /   \u22c2   i = 1   4       g   \u0303     i    (  D  ,  P  )  \u2264 0 .    As the displacements are very small, functions are linearized. The defect probability   P   D f   is defined as  (31)    P   D f   = Prob  (   min    P  \u2208 \u03a9  (  D  )     (   Y   K    (  D  ,  P  )  )  \u2212   Y     K    min      < 0 )  .   This probability can be computed by the first methodology, and by the second one if the contact point situations are well defined. As Ballu et\u00a0al.\u00a0 [6] did, it is simple to identify them using the identification numbers defined in Fig.\u00a07:    s     ( 1 )    =  { 1 , 2 }  ,    s     ( 2 )    =  { 3 , 4 }  ,    s     ( 3 )    =  { 1 , 4 }  and    s     ( 4 )    =  { 2 , 3 }  . In this case,   N   d s   =   N   s   = 4 ,   N   c   = 4 . Thus, the second methodology   P   D f   formulation is as follows:  (32)    P   D f   = Prob  (   \u22c3   i = 1   4    [  (   L   i    (  D  )  < 0 )    \u22c2   j = 1   2    (   g        s    \u0304     j    ( i )       (  D  ,      P    \u02c6     i   )  \u2264 0 )  ]  )    where   L   i    (  D  )  =   Y   K    (  D  ,      P    \u02c6     i    (  D  )  )  \u2212   Y     K    min      . Functionality defect probability results are given in Table\u00a06 . As in the previous application, both methodologies give comparable results, but the computation cost of the MC method is significantly higher than that of the FORM system. This application confirms the ability of the FORM system method to deal with functionality issues very efficiently. The defect probability of individual situations   P   D f    ( i )    , i = 1 to 4, can be computed, and their sum gives a   P   D   upper bound, which is very close to the actual result:      P   D f    ( 1 )    = 148  ( 1 )  ,    P   D f    ( 2 )    = 131  ( 1 )  ,    P   D f    ( 3 )    = 148  ( 1 )  ,    P   D f    ( 4 )    = 131  ( 1 )     (33)    P   D f   \u2248   \u2211   i = 1   4     P   D f    ( i )    = 558  ( 4 )   ppm\u00a0.    This shows that individual defect events are independent in this case.   CONCLUSION   Statistical tolerance analysis is a key step in the design phase for industrial products. Probabilistic approaches provide very useful tools for tolerance analysis. The goal is to compute defect probabilities of over-constrained mechanisms containing gaps; the latter represent the main difficulty here, since they cannot be modeled as random variables. In fact they are free and have to be considered as deterministic variables. This point greatly complicates the solution process. In addition, these kinds of mechanisms are specific, because their non-conformance is caused either by assembly defects or by functionality defects. This paper shows that assembly issues are often trivial, whereas functionality issues are complex due to the presence of gaps.  Concerning functionality issues, the paper proposes an innovative methodology from the structural reliability domain. The authors propose to compute   P   D f   defect probability using the FORM system method. Several contact point situations are treated separately as dependent events. Their intersection is taken into consideration thanks to the multi-dimensional Gaussian cumulative distributive function   \u03a6   n   , computed by the Genz method. The proposed methodology is compared with another existing method based on MC simulations and optimizations. The two industrial applications show that both presented methodologies give equivalent results. The proposed method enables the computation of defect probabilities for mechanisms containing gaps at a very low computing cost (a few minutes compared to several hours). The FORM system methodology is remarkably accurate and can be applied to other mechanisms containing gaps on which several contact point situations can be identified to respect functional requirements. Its efficiency is also linked to the linearity of non-penetration constraints to ensure that extreme functional characteristic values are obtained at the contact points.  In the case of more complex mechanisms with gaps whose behavior is governed by highly non-linear functions, the constraint linearization phase could lead to errors in defect probabilities. In future work, it would be interesting to deal with this kind of system.   ACKNOWLEDGMENTS   The authors would like to thank RADIALL SA, and particularly Laurent Gauvrit, for their cooperation concerning the presented coaxial connector case study. The Auvergne regional council is also gratefully acknowledged for its financial contribution to this work.   REFERENCES", "highlights": "One of the aims of statistical tolerance analysis is to evaluate a predicted quality level at the design stage. One method consists of computing the defect probability   P   D   expressed in parts per million (ppm). It represents the probability that a functional requirement will not be satisfied in mass production. This paper focuses on the statistical tolerance analysis of over-constrained mechanisms containing gaps. In this case, the values of the functional characteristics depend on the gap situations and are not explicitly formulated with respect to part deviations. To compute   P   D   , an innovative methodology using system reliability methods is presented. This new approach is compared with an existing one based on an optimization algorithm and Monte Carlo simulations. The whole approach is illustrated using two industrial mechanisms: one inspired by a producer of coaxial connectors and one prismatic pair. Its major advantage is to considerably reduce computation time.   Defect probability of the mechanism  Assembly defect probability of the mechanism  Functionality defect probability of the mechanism    n -dimensional multivariate normal cumulative distribution function  Vector of part deviations    i -th part deviation  Vector of part positions    i -th part position    i -th assembly constraint  Number of assembly constraints    i -th non-interference constraint  Number of non-interference constraints  Non-interference domain  Linearized function  Number of contact point situations     P  coordinates relative to the i -th contact point situation  Performance function associated with the i -th contact point situation  Number of dominant contact point situations"}